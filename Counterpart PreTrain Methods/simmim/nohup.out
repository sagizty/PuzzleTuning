/root/miniconda3/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
=> merge config from ./configs/vit_base__test/simmim_pretrain__vit_base__img224__100ep.yaml
RANK and WORLD_SIZE in environ: 2/4
=> merge config from ./configs/vit_base__test/simmim_pretrain__vit_base__img224__100ep.yaml
RANK and WORLD_SIZE in environ: 3/4
=> merge config from ./configs/vit_base__test/simmim_pretrain__vit_base__img224__100ep.yaml
RANK and WORLD_SIZE in environ: 0/4
=> merge config from ./configs/vit_base__test/simmim_pretrain__vit_base__img224__100ep.yaml
RANK and WORLD_SIZE in environ: 1/4
[2023-10-10 03:03:53 simmim_pretrain](main_simmim.py 278): INFO Full config saved to /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/config.json
[2023-10-10 03:03:53 simmim_pretrain](main_simmim.py 281): INFO AMP_OPT_LEVEL: O1
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  DATASET: imagenet
  DATA_PATH: /root/autodl-tmp/datasets/All
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 8
  PIN_MEMORY: true
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: simmim_pretrain
  NUM_CLASSES: 1000
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: vit
  VIT:
    DEPTH: 12
    EMBED_DIM: 768
    INIT_VALUES: null
    IN_CHANS: 3
    MLP_RATIO: 4
    NUM_HEADS: 12
    PATCH_SIZE: 16
    QKV_BIAS: true
    USE_APE: true
    USE_MEAN_POOLING: false
    USE_RPB: false
    USE_SHARED_RPB: true
OUTPUT: /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim
PRETRAINED: ''
PRINT_FREQ: 500
SAVE_FREQ: 20
SEED: 0
TAG: vit_simmim
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.0002
  CLIP_GRAD: 5.0
  EPOCHS: 200
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS:
    - 700
    NAME: multistep
  MIN_LR: 5.0e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.0e-06
  WEIGHT_DECAY: 0.05

[2023-10-10 03:03:53 simmim_pretrain](data_simmim.py 96): INFO Pre-train data transform:
<data.data_simmim.SimMIMTransform object at 0x7ff5f38517f0>
[2023-10-10 03:04:01 simmim_pretrain](data_simmim.py 99): INFO Build dataset: train images = 3475344
[2023-10-10 03:04:01 simmim_pretrain](main_simmim.py 103): INFO Creating model:vit/simmim_pretrain
Ignored all config about ViT!
Ignored all config about ViT!
Ignored all config about ViT!
Ignored all config about ViT!
loaded from pretrained weight
loaded from pretrained weight
loaded from pretrained weight
loaded from pretrained weight
[2023-10-10 03:04:02 simmim_pretrain](main_simmim.py 106): INFO SimMIM(
  (encoder): VisionTransformerForSimMIM(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): FFN(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): Sequential(
    (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
    (1): PixelShuffle(upscale_factor=16)
  )
)
[2023-10-10 03:04:02 simmim_pretrain](optimizer.py 22): INFO >>>>>>>>>> Build Optimizer for Pre-training Stage
[2023-10-10 03:04:02 simmim_pretrain](optimizer.py 27): INFO No weight decay: {}
[2023-10-10 03:04:02 simmim_pretrain](optimizer.py 30): INFO No weight decay keywords: {}
[2023-10-10 03:04:02 simmim_pretrain](optimizer.py 63): INFO No decay params: ['encoder.patch_embed.proj.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.fc1.bias', 'encoder.blocks.0.mlp.fc2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.fc1.bias', 'encoder.blocks.1.mlp.fc2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.fc1.bias', 'encoder.blocks.2.mlp.fc2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.fc1.bias', 'encoder.blocks.3.mlp.fc2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.fc1.bias', 'encoder.blocks.4.mlp.fc2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.fc1.bias', 'encoder.blocks.5.mlp.fc2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.fc1.bias', 'encoder.blocks.6.mlp.fc2.bias', 'encoder.blocks.7.norm1.weight', 'encoder.blocks.7.norm1.bias', 'encoder.blocks.7.attn.qkv.bias', 'encoder.blocks.7.attn.proj.bias', 'encoder.blocks.7.norm2.weight', 'encoder.blocks.7.norm2.bias', 'encoder.blocks.7.mlp.fc1.bias', 'encoder.blocks.7.mlp.fc2.bias', 'encoder.blocks.8.norm1.weight', 'encoder.blocks.8.norm1.bias', 'encoder.blocks.8.attn.qkv.bias', 'encoder.blocks.8.attn.proj.bias', 'encoder.blocks.8.norm2.weight', 'encoder.blocks.8.norm2.bias', 'encoder.blocks.8.mlp.fc1.bias', 'encoder.blocks.8.mlp.fc2.bias', 'encoder.blocks.9.norm1.weight', 'encoder.blocks.9.norm1.bias', 'encoder.blocks.9.attn.qkv.bias', 'encoder.blocks.9.attn.proj.bias', 'encoder.blocks.9.norm2.weight', 'encoder.blocks.9.norm2.bias', 'encoder.blocks.9.mlp.fc1.bias', 'encoder.blocks.9.mlp.fc2.bias', 'encoder.blocks.10.norm1.weight', 'encoder.blocks.10.norm1.bias', 'encoder.blocks.10.attn.qkv.bias', 'encoder.blocks.10.attn.proj.bias', 'encoder.blocks.10.norm2.weight', 'encoder.blocks.10.norm2.bias', 'encoder.blocks.10.mlp.fc1.bias', 'encoder.blocks.10.mlp.fc2.bias', 'encoder.blocks.11.norm1.weight', 'encoder.blocks.11.norm1.bias', 'encoder.blocks.11.attn.qkv.bias', 'encoder.blocks.11.attn.proj.bias', 'encoder.blocks.11.norm2.weight', 'encoder.blocks.11.norm2.bias', 'encoder.blocks.11.mlp.fc1.bias', 'encoder.blocks.11.mlp.fc2.bias', 'encoder.norm.weight', 'encoder.norm.bias', 'decoder.0.bias']
[2023-10-10 03:04:02 simmim_pretrain](optimizer.py 64): INFO Has decay params: ['encoder.cls_token', 'encoder.pos_embed', 'encoder.mask_token', 'encoder.patch_embed.proj.weight', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.mlp.fc1.weight', 'encoder.blocks.0.mlp.fc2.weight', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.mlp.fc1.weight', 'encoder.blocks.1.mlp.fc2.weight', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.mlp.fc1.weight', 'encoder.blocks.2.mlp.fc2.weight', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.mlp.fc1.weight', 'encoder.blocks.3.mlp.fc2.weight', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.mlp.fc1.weight', 'encoder.blocks.4.mlp.fc2.weight', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.mlp.fc1.weight', 'encoder.blocks.5.mlp.fc2.weight', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.mlp.fc1.weight', 'encoder.blocks.6.mlp.fc2.weight', 'encoder.blocks.7.attn.qkv.weight', 'encoder.blocks.7.attn.proj.weight', 'encoder.blocks.7.mlp.fc1.weight', 'encoder.blocks.7.mlp.fc2.weight', 'encoder.blocks.8.attn.qkv.weight', 'encoder.blocks.8.attn.proj.weight', 'encoder.blocks.8.mlp.fc1.weight', 'encoder.blocks.8.mlp.fc2.weight', 'encoder.blocks.9.attn.qkv.weight', 'encoder.blocks.9.attn.proj.weight', 'encoder.blocks.9.mlp.fc1.weight', 'encoder.blocks.9.mlp.fc2.weight', 'encoder.blocks.10.attn.qkv.weight', 'encoder.blocks.10.attn.proj.weight', 'encoder.blocks.10.mlp.fc1.weight', 'encoder.blocks.10.mlp.fc2.weight', 'encoder.blocks.11.attn.qkv.weight', 'encoder.blocks.11.attn.proj.weight', 'encoder.blocks.11.mlp.fc1.weight', 'encoder.blocks.11.mlp.fc2.weight', 'decoder.0.weight']
[2023-10-10 03:04:02 simmim_pretrain](optimizer.py 43): INFO AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.05

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
[2023-10-10 03:04:02 simmim_pretrain](main_simmim.py 120): INFO number of params: 86390016
[2023-10-10 03:04:02 simmim_pretrain](utils.py 83): INFO All checkpoints founded in /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim: []
[2023-10-10 03:04:02 simmim_pretrain](main_simmim.py 137): INFO no checkpoint found in /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim, ignoring auto resume
[2023-10-10 03:04:02 simmim_pretrain](main_simmim.py 145): INFO Start training
/root/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [768, 768, 1, 1], strides() = [768, 1, 768, 768]
bucket_view.sizes() = [768, 768, 1, 1], strides() = [768, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [768, 768, 1, 1], strides() = [768, 1, 768, 768]
bucket_view.sizes() = [768, 768, 1, 1], strides() = [768, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [768, 768, 1, 1], strides() = [768, 1, 768, 768]
bucket_view.sizes() = [768, 768, 1, 1], strides() = [768, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [768, 768, 1, 1], strides() = [768, 1, 768, 768]
bucket_view.sizes() = [768, 768, 1, 1], strides() = [768, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[2023-10-10 03:04:07 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][0/6787]	eta 8:30:41 lr 0.000001	time 4.5148 (4.5148)	loss 1.7152 (1.7152)	grad_norm 553505.6250 (553505.6250)	mem 13533MB
[2023-10-10 03:06:09 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][500/6787]	eta 0:26:26 lr 0.000002	time 0.2444 (0.2523)	loss 0.6251 (0.8950)	grad_norm 25038.8047 (100184.2969)	mem 14543MB
[2023-10-10 03:08:12 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][1000/6787]	eta 0:24:04 lr 0.000002	time 0.2562 (0.2497)	loss 0.5471 (0.7294)	grad_norm 23971.2754 (64596.7500)	mem 14543MB
[2023-10-10 03:10:17 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][1500/6787]	eta 0:22:00 lr 0.000003	time 0.2493 (0.2498)	loss 0.5397 (0.6632)	grad_norm 59519.0664 (58565.0820)	mem 14543MB
[2023-10-10 03:12:22 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][2000/6787]	eta 0:19:56 lr 0.000004	time 0.2587 (0.2500)	loss 0.5102 (0.6263)	grad_norm 240317.0781 (71993.7969)	mem 14543MB
[2023-10-10 03:14:28 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][2500/6787]	eta 0:17:52 lr 0.000005	time 0.2461 (0.2501)	loss 0.4838 (0.6021)	grad_norm 154843.9688 (98793.8047)	mem 14543MB
[2023-10-10 03:16:33 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][3000/6787]	eta 0:15:47 lr 0.000005	time 0.2448 (0.2501)	loss 0.5123 (0.5849)	grad_norm 541804.3750 (134192.4844)	mem 14543MB
[2023-10-10 03:18:38 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][3500/6787]	eta 0:13:42 lr 0.000006	time 0.2503 (0.2502)	loss 0.5012 (0.5723)	grad_norm 501434.0938 (172352.0156)	mem 14543MB
[2023-10-10 03:20:44 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][4000/6787]	eta 0:11:37 lr 0.000007	time 0.2492 (0.2503)	loss 0.4889 (0.5626)	grad_norm 609606.8750 (195628.6562)	mem 14543MB
[2023-10-10 03:22:50 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][4500/6787]	eta 0:09:32 lr 0.000008	time 0.2598 (0.2504)	loss 0.4657 (0.5546)	grad_norm 821053.7500 (206329.3281)	mem 14543MB
[2023-10-10 03:24:59 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][5000/6787]	eta 0:07:29 lr 0.000008	time 0.2599 (0.2513)	loss 0.4856 (0.5479)	grad_norm 359824.9688 (230155.2344)	mem 14543MB
[2023-10-10 03:27:05 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][5500/6787]	eta 0:05:23 lr 0.000009	time 0.2514 (0.2514)	loss 0.4633 (0.5422)	grad_norm 816823.6875 (253836.1719)	mem 14543MB
[2023-10-10 03:29:10 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][6000/6787]	eta 0:03:17 lr 0.000010	time 0.2589 (0.2513)	loss 0.4895 (0.5374)	grad_norm 809127.5625 (266184.0938)	mem 14543MB
[2023-10-10 03:31:16 simmim_pretrain](main_simmim.py 218): INFO Train: [0/200][6500/6787]	eta 0:01:12 lr 0.000011	time 0.2519 (0.2513)	loss 0.5012 (0.5330)	grad_norm 980117.6875 (inf)	mem 14543MB
[2023-10-10 03:32:28 simmim_pretrain](main_simmim.py 228): INFO EPOCH 0 training takes 0:28:26
[2023-10-10 03:32:28 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_0.pth saving......
[2023-10-10 03:32:29 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_0.pth saved !!!
[2023-10-10 03:32:30 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][0/6787]	eta 2:32:49 lr 0.000011	time 1.3511 (1.3511)	loss 0.4772 (0.4772)	grad_norm 144767.9062 (144767.9062)	mem 14543MB
[2023-10-10 03:34:36 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][500/6787]	eta 0:26:27 lr 0.000012	time 0.2545 (0.2525)	loss 0.4586 (0.4690)	grad_norm 535874.0625 (665340.0625)	mem 14543MB
[2023-10-10 03:36:41 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][1000/6787]	eta 0:24:17 lr 0.000012	time 0.2483 (0.2518)	loss 0.4475 (0.4653)	grad_norm 960475.7500 (644721.1875)	mem 14543MB
[2023-10-10 03:38:46 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][1500/6787]	eta 0:22:09 lr 0.000013	time 0.2486 (0.2514)	loss 0.4601 (0.4622)	grad_norm 539256.4375 (648973.9375)	mem 14543MB
[2023-10-10 03:40:52 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][2000/6787]	eta 0:20:02 lr 0.000014	time 0.2541 (0.2511)	loss 0.4288 (0.4594)	grad_norm 710371.8750 (712513.4375)	mem 14543MB
[2023-10-10 03:42:57 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][2500/6787]	eta 0:17:56 lr 0.000015	time 0.2554 (0.2510)	loss 0.4711 (0.4572)	grad_norm 764299.3125 (719295.8750)	mem 14543MB
[2023-10-10 03:45:02 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][3000/6787]	eta 0:15:50 lr 0.000015	time 0.2468 (0.2509)	loss 0.4599 (0.4552)	grad_norm 511418.3125 (765126.8125)	mem 14543MB
[2023-10-10 03:47:07 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][3500/6787]	eta 0:13:44 lr 0.000016	time 0.2505 (0.2509)	loss 0.4501 (0.4535)	grad_norm 1814348.5000 (inf)	mem 14543MB
[2023-10-10 03:49:13 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][4000/6787]	eta 0:11:39 lr 0.000017	time 0.2503 (0.2508)	loss 0.4399 (0.4522)	grad_norm 1776759.3750 (inf)	mem 14543MB
[2023-10-10 03:51:18 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][4500/6787]	eta 0:09:33 lr 0.000018	time 0.2514 (0.2507)	loss 0.4322 (0.4509)	grad_norm 922950.3125 (inf)	mem 14543MB
[2023-10-10 03:53:23 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][5000/6787]	eta 0:07:27 lr 0.000018	time 0.2493 (0.2507)	loss 0.4397 (0.4497)	grad_norm 1040136.3750 (inf)	mem 14543MB
[2023-10-10 03:55:28 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][5500/6787]	eta 0:05:22 lr 0.000019	time 0.2485 (0.2507)	loss 0.4340 (0.4487)	grad_norm 647195.6250 (inf)	mem 14543MB
[2023-10-10 03:57:33 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][6000/6787]	eta 0:03:17 lr 0.000020	time 0.2502 (0.2507)	loss 0.4386 (0.4477)	grad_norm 1406970.0000 (inf)	mem 14543MB
[2023-10-10 03:59:39 simmim_pretrain](main_simmim.py 218): INFO Train: [1/200][6500/6787]	eta 0:01:11 lr 0.000020	time 0.2488 (0.2507)	loss 0.4304 (0.4467)	grad_norm 487872.5938 (inf)	mem 14543MB
[2023-10-10 04:00:51 simmim_pretrain](main_simmim.py 228): INFO EPOCH 1 training takes 0:28:22
[2023-10-10 04:00:53 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][0/6787]	eta 2:35:04 lr 0.000021	time 1.3709 (1.3709)	loss 0.4393 (0.4393)	grad_norm 659639.8125 (659639.8125)	mem 14543MB
[2023-10-10 04:02:57 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][500/6787]	eta 0:26:23 lr 0.000022	time 0.2462 (0.2518)	loss 0.4335 (0.4324)	grad_norm 872738.8125 (inf)	mem 14543MB
[2023-10-10 04:05:03 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][1000/6787]	eta 0:24:13 lr 0.000022	time 0.2536 (0.2512)	loss 0.4051 (0.4329)	grad_norm 1444892.6250 (inf)	mem 14543MB
[2023-10-10 04:07:08 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][1500/6787]	eta 0:22:06 lr 0.000023	time 0.2511 (0.2510)	loss 0.4447 (0.4324)	grad_norm 728204.2500 (inf)	mem 14543MB
[2023-10-10 04:09:14 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][2000/6787]	eta 0:20:01 lr 0.000024	time 0.2473 (0.2511)	loss 0.4198 (0.4320)	grad_norm 922745.8750 (inf)	mem 14543MB
[2023-10-10 04:11:19 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][2500/6787]	eta 0:17:56 lr 0.000025	time 0.2559 (0.2512)	loss 0.4247 (0.4317)	grad_norm 1370773.6250 (inf)	mem 14543MB
[2023-10-10 04:13:25 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][3000/6787]	eta 0:15:51 lr 0.000025	time 0.2496 (0.2513)	loss 0.3997 (0.4312)	grad_norm 585347.3750 (inf)	mem 14543MB
[2023-10-10 04:15:31 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][3500/6787]	eta 0:13:46 lr 0.000026	time 0.2492 (0.2514)	loss 0.4111 (0.4308)	grad_norm 592507.3125 (inf)	mem 14543MB
[2023-10-10 04:17:38 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][4000/6787]	eta 0:11:40 lr 0.000027	time 0.2577 (0.2515)	loss 0.4029 (0.4304)	grad_norm 939298.0625 (inf)	mem 14543MB
[2023-10-10 04:19:44 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][4500/6787]	eta 0:09:35 lr 0.000027	time 0.2520 (0.2516)	loss 0.4360 (0.4301)	grad_norm 746308.8750 (inf)	mem 14543MB
[2023-10-10 04:21:50 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][5000/6787]	eta 0:07:29 lr 0.000028	time 0.2493 (0.2516)	loss 0.4662 (0.4298)	grad_norm 573671.5625 (inf)	mem 14543MB
[2023-10-10 04:23:55 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][5500/6787]	eta 0:05:23 lr 0.000029	time 0.2523 (0.2516)	loss 0.4098 (0.4294)	grad_norm 2750094.2500 (inf)	mem 14543MB
[2023-10-10 04:26:01 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][6000/6787]	eta 0:03:17 lr 0.000030	time 0.2487 (0.2516)	loss 0.4324 (0.4292)	grad_norm 1130291.7500 (inf)	mem 14543MB
[2023-10-10 04:28:07 simmim_pretrain](main_simmim.py 218): INFO Train: [2/200][6500/6787]	eta 0:01:12 lr 0.000030	time 0.2520 (0.2515)	loss 0.4199 (0.4290)	grad_norm 529819.1875 (inf)	mem 14543MB
[2023-10-10 04:29:19 simmim_pretrain](main_simmim.py 228): INFO EPOCH 2 training takes 0:28:27
[2023-10-10 04:29:21 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][0/6787]	eta 2:32:21 lr 0.000031	time 1.3469 (1.3469)	loss 0.4341 (0.4341)	grad_norm 794711.5000 (794711.5000)	mem 14543MB
[2023-10-10 04:31:26 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][500/6787]	eta 0:26:31 lr 0.000032	time 0.2562 (0.2531)	loss 0.4010 (0.4247)	grad_norm 601396.8750 (687885.3125)	mem 14543MB
[2023-10-10 04:33:32 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][1000/6787]	eta 0:24:19 lr 0.000032	time 0.2506 (0.2522)	loss 0.4401 (0.4241)	grad_norm 709212.1250 (711774.1250)	mem 14543MB
[2023-10-10 04:35:37 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][1500/6787]	eta 0:22:10 lr 0.000033	time 0.2517 (0.2517)	loss 0.4268 (0.4241)	grad_norm 403870.3125 (764413.6875)	mem 14543MB
[2023-10-10 04:37:42 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][2000/6787]	eta 0:20:03 lr 0.000034	time 0.2501 (0.2515)	loss 0.4287 (0.4238)	grad_norm 1236570.1250 (inf)	mem 14543MB
[2023-10-10 04:39:48 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][2500/6787]	eta 0:17:57 lr 0.000035	time 0.2558 (0.2514)	loss 0.4235 (0.4238)	grad_norm 465070.2188 (inf)	mem 14543MB
[2023-10-10 04:41:53 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][3000/6787]	eta 0:15:51 lr 0.000035	time 0.2520 (0.2513)	loss 0.4204 (0.4235)	grad_norm 961153.3125 (inf)	mem 14543MB
[2023-10-10 04:43:59 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][3500/6787]	eta 0:13:45 lr 0.000036	time 0.2535 (0.2512)	loss 0.4419 (0.4232)	grad_norm 600768.2500 (inf)	mem 14543MB
[2023-10-10 04:46:04 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][4000/6787]	eta 0:11:39 lr 0.000037	time 0.2496 (0.2512)	loss 0.4316 (0.4232)	grad_norm 530462.1250 (inf)	mem 14543MB
[2023-10-10 04:48:09 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][4500/6787]	eta 0:09:34 lr 0.000037	time 0.2522 (0.2511)	loss 0.4503 (0.4227)	grad_norm 399515.7500 (inf)	mem 14543MB
[2023-10-10 04:50:15 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][5000/6787]	eta 0:07:28 lr 0.000038	time 0.2537 (0.2510)	loss 0.4279 (0.4223)	grad_norm 513325.5000 (inf)	mem 14543MB
[2023-10-10 04:52:20 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][5500/6787]	eta 0:05:23 lr 0.000039	time 0.2517 (0.2510)	loss 0.4282 (0.4220)	grad_norm 868282.9375 (inf)	mem 14543MB
[2023-10-10 04:54:25 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][6000/6787]	eta 0:03:17 lr 0.000040	time 0.2473 (0.2510)	loss 0.4171 (0.4216)	grad_norm 571394.0000 (inf)	mem 14543MB
[2023-10-10 04:56:31 simmim_pretrain](main_simmim.py 218): INFO Train: [3/200][6500/6787]	eta 0:01:12 lr 0.000040	time 0.2577 (0.2510)	loss 0.4230 (0.4212)	grad_norm 919010.5000 (inf)	mem 14543MB
[2023-10-10 04:57:43 simmim_pretrain](main_simmim.py 228): INFO EPOCH 3 training takes 0:28:23
[2023-10-10 04:57:44 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][0/6787]	eta 2:34:16 lr 0.000041	time 1.3639 (1.3639)	loss 0.4357 (0.4357)	grad_norm 661257.6250 (661257.6250)	mem 14543MB
[2023-10-10 04:59:49 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][500/6787]	eta 0:26:24 lr 0.000042	time 0.2461 (0.2521)	loss 0.4066 (0.4155)	grad_norm 774128.5625 (671610.5000)	mem 14543MB
[2023-10-10 05:01:54 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][1000/6787]	eta 0:24:14 lr 0.000042	time 0.2503 (0.2513)	loss 0.4002 (0.4164)	grad_norm 274338.7500 (nan)	mem 14543MB
[2023-10-10 05:04:00 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][1500/6787]	eta 0:22:07 lr 0.000043	time 0.2459 (0.2511)	loss 0.3930 (0.4164)	grad_norm 233489.1562 (nan)	mem 14543MB
[2023-10-10 05:06:05 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][2000/6787]	eta 0:20:01 lr 0.000044	time 0.2518 (0.2511)	loss 0.4203 (0.4162)	grad_norm 322065.9688 (nan)	mem 14543MB
[2023-10-10 05:08:11 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][2500/6787]	eta 0:17:56 lr 0.000044	time 0.2514 (0.2511)	loss 0.4085 (0.4157)	grad_norm 197069.8906 (nan)	mem 14543MB
[2023-10-10 05:10:16 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][3000/6787]	eta 0:15:50 lr 0.000045	time 0.2458 (0.2510)	loss 0.4203 (0.4153)	grad_norm 397812.2500 (nan)	mem 14543MB
[2023-10-10 05:12:22 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][3500/6787]	eta 0:13:45 lr 0.000046	time 0.2501 (0.2510)	loss 0.3780 (0.4148)	grad_norm 517283.5312 (nan)	mem 14543MB
[2023-10-10 05:14:28 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][4000/6787]	eta 0:11:39 lr 0.000047	time 0.2540 (0.2511)	loss 0.4296 (0.4143)	grad_norm 309018.5000 (nan)	mem 14543MB
[2023-10-10 05:16:33 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][4500/6787]	eta 0:09:34 lr 0.000047	time 0.2561 (0.2512)	loss 0.4167 (0.4138)	grad_norm 505430.5000 (nan)	mem 14543MB
[2023-10-10 05:18:39 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][5000/6787]	eta 0:07:28 lr 0.000048	time 0.2596 (0.2512)	loss 0.4021 (0.4132)	grad_norm 410150.2188 (nan)	mem 14543MB
[2023-10-10 05:20:45 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][5500/6787]	eta 0:05:23 lr 0.000049	time 0.2457 (0.2512)	loss 0.3934 (0.4127)	grad_norm 854229.9375 (nan)	mem 14543MB
[2023-10-10 05:22:50 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][6000/6787]	eta 0:03:17 lr 0.000050	time 0.2588 (0.2511)	loss 0.4204 (0.4122)	grad_norm 1532492.7500 (nan)	mem 14543MB
[2023-10-10 05:24:55 simmim_pretrain](main_simmim.py 218): INFO Train: [4/200][6500/6787]	eta 0:01:12 lr 0.000050	time 0.2514 (0.2511)	loss 0.4155 (0.4118)	grad_norm 491622.1562 (nan)	mem 14543MB
[2023-10-10 05:26:08 simmim_pretrain](main_simmim.py 228): INFO EPOCH 4 training takes 0:28:24
[2023-10-10 05:26:09 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][0/6787]	eta 2:28:05 lr 0.000051	time 1.3092 (1.3092)	loss 0.3984 (0.3984)	grad_norm 578239.0625 (578239.0625)	mem 14543MB
[2023-10-10 05:28:14 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][500/6787]	eta 0:26:27 lr 0.000051	time 0.2496 (0.2525)	loss 0.4156 (0.4047)	grad_norm 390009.2500 (515957.2188)	mem 14543MB
[2023-10-10 05:30:20 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][1000/6787]	eta 0:24:17 lr 0.000052	time 0.2547 (0.2519)	loss 0.3872 (0.4049)	grad_norm 904920.0000 (521818.1562)	mem 14543MB
[2023-10-10 05:32:25 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][1500/6787]	eta 0:22:07 lr 0.000053	time 0.2457 (0.2511)	loss 0.3968 (0.4047)	grad_norm 943757.4375 (557525.3125)	mem 14543MB
[2023-10-10 05:34:30 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][2000/6787]	eta 0:20:00 lr 0.000054	time 0.2535 (0.2508)	loss 0.4031 (0.4044)	grad_norm 814286.0625 (582936.7500)	mem 14543MB
[2023-10-10 05:36:35 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][2500/6787]	eta 0:17:54 lr 0.000054	time 0.2540 (0.2507)	loss 0.4162 (0.4042)	grad_norm 487653.4062 (605626.3750)	mem 14543MB
[2023-10-10 05:38:40 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][3000/6787]	eta 0:15:49 lr 0.000055	time 0.2470 (0.2506)	loss 0.3849 (0.4038)	grad_norm 422073.7188 (inf)	mem 14543MB
[2023-10-10 05:40:45 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][3500/6787]	eta 0:13:43 lr 0.000056	time 0.2520 (0.2506)	loss 0.4068 (0.4036)	grad_norm 520833.2500 (inf)	mem 14543MB
[2023-10-10 05:42:50 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][4000/6787]	eta 0:11:38 lr 0.000057	time 0.2447 (0.2506)	loss 0.4007 (0.4034)	grad_norm 401273.1250 (inf)	mem 14543MB
[2023-10-10 05:44:55 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][4500/6787]	eta 0:09:32 lr 0.000057	time 0.2544 (0.2505)	loss 0.3900 (0.4033)	grad_norm 527926.8125 (inf)	mem 14543MB
[2023-10-10 05:47:01 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][5000/6787]	eta 0:07:27 lr 0.000058	time 0.2523 (0.2505)	loss 0.3939 (0.4032)	grad_norm 721252.0000 (inf)	mem 14543MB
[2023-10-10 05:49:06 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][5500/6787]	eta 0:05:22 lr 0.000059	time 0.2524 (0.2505)	loss 0.3907 (0.4030)	grad_norm 570211.2500 (inf)	mem 14543MB
[2023-10-10 05:51:11 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][6000/6787]	eta 0:03:17 lr 0.000060	time 0.2588 (0.2505)	loss 0.4046 (0.4028)	grad_norm 538420.2500 (inf)	mem 14543MB
[2023-10-10 05:53:17 simmim_pretrain](main_simmim.py 218): INFO Train: [5/200][6500/6787]	eta 0:01:11 lr 0.000060	time 0.2486 (0.2506)	loss 0.4047 (0.4024)	grad_norm 555881.3750 (inf)	mem 14543MB
[2023-10-10 05:54:29 simmim_pretrain](main_simmim.py 228): INFO EPOCH 5 training takes 0:28:21
[2023-10-10 05:54:31 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][0/6787]	eta 2:38:55 lr 0.000061	time 1.4049 (1.4049)	loss 0.3786 (0.3786)	grad_norm 523171.9375 (523171.9375)	mem 14543MB
[2023-10-10 05:56:36 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][500/6787]	eta 0:26:28 lr 0.000061	time 0.2455 (0.2527)	loss 0.4249 (0.3978)	grad_norm 772955.5000 (582496.6875)	mem 14543MB
[2023-10-10 05:58:41 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][1000/6787]	eta 0:24:17 lr 0.000062	time 0.2521 (0.2519)	loss 0.3953 (0.3980)	grad_norm 493784.6875 (613746.7500)	mem 14543MB
[2023-10-10 06:00:47 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][1500/6787]	eta 0:22:10 lr 0.000063	time 0.2495 (0.2516)	loss 0.3997 (0.3980)	grad_norm 631632.8750 (inf)	mem 14543MB
[2023-10-10 06:02:52 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][2000/6787]	eta 0:20:03 lr 0.000064	time 0.2463 (0.2515)	loss 0.4048 (0.3977)	grad_norm 246547.5156 (inf)	mem 14543MB
[2023-10-10 06:04:58 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][2500/6787]	eta 0:17:57 lr 0.000064	time 0.2526 (0.2514)	loss 0.3726 (0.3976)	grad_norm 428185.0312 (inf)	mem 14543MB
[2023-10-10 06:07:03 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][3000/6787]	eta 0:15:51 lr 0.000065	time 0.2465 (0.2513)	loss 0.3938 (0.3975)	grad_norm 538215.9375 (inf)	mem 14543MB
[2023-10-10 06:09:09 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][3500/6787]	eta 0:13:45 lr 0.000066	time 0.2511 (0.2512)	loss 0.3874 (0.3972)	grad_norm 542470.0000 (inf)	mem 14543MB
[2023-10-10 06:11:14 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][4000/6787]	eta 0:11:39 lr 0.000067	time 0.2470 (0.2511)	loss 0.3968 (0.3970)	grad_norm 662246.0000 (inf)	mem 14543MB
[2023-10-10 06:13:20 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][4500/6787]	eta 0:09:34 lr 0.000067	time 0.2465 (0.2511)	loss 0.3794 (0.3967)	grad_norm 518386.2812 (inf)	mem 14543MB
[2023-10-10 06:15:25 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][5000/6787]	eta 0:07:28 lr 0.000068	time 0.2447 (0.2511)	loss 0.3752 (0.3966)	grad_norm 489676.6250 (inf)	mem 14543MB
[2023-10-10 06:17:30 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][5500/6787]	eta 0:05:23 lr 0.000069	time 0.2504 (0.2510)	loss 0.3967 (0.3964)	grad_norm 667977.8125 (inf)	mem 14543MB
[2023-10-10 06:19:35 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][6000/6787]	eta 0:03:17 lr 0.000069	time 0.2541 (0.2510)	loss 0.3923 (0.3961)	grad_norm 547869.0000 (inf)	mem 14543MB
[2023-10-10 06:21:41 simmim_pretrain](main_simmim.py 218): INFO Train: [6/200][6500/6787]	eta 0:01:12 lr 0.000070	time 0.2496 (0.2510)	loss 0.4107 (0.3959)	grad_norm 792803.1250 (inf)	mem 14543MB
[2023-10-10 06:22:53 simmim_pretrain](main_simmim.py 228): INFO EPOCH 6 training takes 0:28:24
[2023-10-10 06:22:55 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][0/6787]	eta 2:32:16 lr 0.000071	time 1.3461 (1.3461)	loss 0.3952 (0.3952)	grad_norm 719464.4375 (719464.4375)	mem 14543MB
[2023-10-10 06:25:00 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][500/6787]	eta 0:26:29 lr 0.000071	time 0.2512 (0.2528)	loss 0.3729 (0.3929)	grad_norm 400657.5000 (725651.1250)	mem 14543MB
[2023-10-10 06:27:05 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][1000/6787]	eta 0:24:16 lr 0.000072	time 0.2507 (0.2517)	loss 0.4076 (0.3936)	grad_norm 420490.4375 (inf)	mem 14543MB
[2023-10-10 06:29:11 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][1500/6787]	eta 0:22:08 lr 0.000073	time 0.2477 (0.2513)	loss 0.3962 (0.3933)	grad_norm 409381.5312 (inf)	mem 14543MB
[2023-10-10 06:31:16 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][2000/6787]	eta 0:20:02 lr 0.000074	time 0.2521 (0.2511)	loss 0.4027 (0.3934)	grad_norm 650768.6875 (inf)	mem 14543MB
[2023-10-10 06:33:21 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][2500/6787]	eta 0:17:56 lr 0.000074	time 0.2519 (0.2511)	loss 0.3823 (0.3932)	grad_norm 423769.8125 (inf)	mem 14543MB
[2023-10-10 06:35:27 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][3000/6787]	eta 0:15:50 lr 0.000075	time 0.2556 (0.2511)	loss 0.3847 (0.3928)	grad_norm 785393.5000 (inf)	mem 14543MB
[2023-10-10 06:37:32 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][3500/6787]	eta 0:13:45 lr 0.000076	time 0.2523 (0.2511)	loss 0.3747 (0.3927)	grad_norm 567105.4375 (inf)	mem 14543MB
[2023-10-10 06:39:38 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][4000/6787]	eta 0:11:39 lr 0.000077	time 0.2543 (0.2510)	loss 0.3926 (0.3927)	grad_norm 563567.3125 (inf)	mem 14543MB
[2023-10-10 06:41:43 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][4500/6787]	eta 0:09:34 lr 0.000077	time 0.2515 (0.2510)	loss 0.3847 (0.3925)	grad_norm 639863.4375 (inf)	mem 14543MB
[2023-10-10 06:43:49 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][5000/6787]	eta 0:07:28 lr 0.000078	time 0.2466 (0.2510)	loss 0.3835 (0.3924)	grad_norm 266915.2812 (inf)	mem 14543MB
[2023-10-10 06:45:54 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][5500/6787]	eta 0:05:23 lr 0.000079	time 0.2496 (0.2510)	loss 0.3880 (0.3922)	grad_norm 526473.0625 (inf)	mem 14543MB
[2023-10-10 06:48:00 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][6000/6787]	eta 0:03:17 lr 0.000079	time 0.2510 (0.2510)	loss 0.3696 (0.3920)	grad_norm 810871.0000 (inf)	mem 14543MB
[2023-10-10 06:50:05 simmim_pretrain](main_simmim.py 218): INFO Train: [7/200][6500/6787]	eta 0:01:12 lr 0.000080	time 0.2573 (0.2510)	loss 0.3907 (0.3918)	grad_norm 390052.0625 (inf)	mem 14543MB
[2023-10-10 06:51:18 simmim_pretrain](main_simmim.py 228): INFO EPOCH 7 training takes 0:28:24
[2023-10-10 06:51:19 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][0/6787]	eta 2:29:18 lr 0.000081	time 1.3200 (1.3200)	loss 0.4024 (0.4024)	grad_norm 462567.0938 (462567.0938)	mem 14543MB
[2023-10-10 06:53:24 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][500/6787]	eta 0:26:28 lr 0.000081	time 0.2499 (0.2527)	loss 0.3791 (0.3907)	grad_norm 581210.1875 (inf)	mem 14543MB
[2023-10-10 06:55:30 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][1000/6787]	eta 0:24:17 lr 0.000082	time 0.2506 (0.2519)	loss 0.3972 (0.3905)	grad_norm 479175.9062 (inf)	mem 14543MB
[2023-10-10 06:57:36 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][1500/6787]	eta 0:22:10 lr 0.000083	time 0.2520 (0.2516)	loss 0.3999 (0.3902)	grad_norm 466565.5938 (inf)	mem 14543MB
[2023-10-10 06:59:41 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][2000/6787]	eta 0:20:04 lr 0.000084	time 0.2565 (0.2516)	loss 0.3970 (0.3901)	grad_norm 299479.5625 (inf)	mem 14543MB
[2023-10-10 07:01:47 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][2500/6787]	eta 0:17:58 lr 0.000084	time 0.2592 (0.2515)	loss 0.3868 (0.3900)	grad_norm 555698.1250 (inf)	mem 14543MB
[2023-10-10 07:03:52 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][3000/6787]	eta 0:15:52 lr 0.000085	time 0.2514 (0.2515)	loss 0.4017 (0.3901)	grad_norm 632740.1875 (inf)	mem 14543MB
[2023-10-10 07:05:58 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][3500/6787]	eta 0:13:46 lr 0.000086	time 0.2549 (0.2514)	loss 0.3963 (0.3898)	grad_norm 455604.8438 (inf)	mem 14543MB
[2023-10-10 07:08:04 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][4000/6787]	eta 0:11:40 lr 0.000086	time 0.2590 (0.2514)	loss 0.3721 (0.3896)	grad_norm 485743.6875 (inf)	mem 14543MB
[2023-10-10 07:10:09 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][4500/6787]	eta 0:09:34 lr 0.000087	time 0.2587 (0.2514)	loss 0.3873 (0.3893)	grad_norm 326329.6250 (inf)	mem 14543MB
[2023-10-10 07:12:15 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][5000/6787]	eta 0:07:29 lr 0.000088	time 0.2525 (0.2513)	loss 0.3877 (0.3890)	grad_norm 401584.0625 (inf)	mem 14543MB
[2023-10-10 07:14:20 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][5500/6787]	eta 0:05:23 lr 0.000089	time 0.2459 (0.2512)	loss 0.4064 (0.3892)	grad_norm 189235.9375 (inf)	mem 14543MB
[2023-10-10 07:16:25 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][6000/6787]	eta 0:03:17 lr 0.000089	time 0.2467 (0.2512)	loss 0.4035 (0.3892)	grad_norm 362180.9062 (inf)	mem 14543MB
[2023-10-10 07:18:31 simmim_pretrain](main_simmim.py 218): INFO Train: [8/200][6500/6787]	eta 0:01:12 lr 0.000090	time 0.2507 (0.2512)	loss 0.4013 (0.3892)	grad_norm 273559.9375 (inf)	mem 14543MB
[2023-10-10 07:19:43 simmim_pretrain](main_simmim.py 228): INFO EPOCH 8 training takes 0:28:25
[2023-10-10 07:19:45 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][0/6787]	eta 2:30:51 lr 0.000091	time 1.3336 (1.3336)	loss 0.3687 (0.3687)	grad_norm 269559.4375 (269559.4375)	mem 14543MB
[2023-10-10 07:21:50 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][500/6787]	eta 0:26:26 lr 0.000091	time 0.2483 (0.2524)	loss 0.4103 (0.3880)	grad_norm 234218.1094 (248650.3594)	mem 14543MB
[2023-10-10 07:23:55 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][1000/6787]	eta 0:24:15 lr 0.000092	time 0.2495 (0.2516)	loss 0.3877 (0.3875)	grad_norm 313479.8750 (302919.0625)	mem 14543MB
[2023-10-10 07:26:00 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][1500/6787]	eta 0:22:07 lr 0.000093	time 0.2496 (0.2510)	loss 0.3852 (0.3871)	grad_norm 438994.5938 (334929.5938)	mem 14543MB
[2023-10-10 07:28:05 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][2000/6787]	eta 0:20:00 lr 0.000093	time 0.2517 (0.2509)	loss 0.3997 (0.3871)	grad_norm 341424.4688 (344583.5000)	mem 14543MB
[2023-10-10 07:30:10 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][2500/6787]	eta 0:17:55 lr 0.000094	time 0.2499 (0.2508)	loss 0.3826 (0.3870)	grad_norm 555100.7500 (inf)	mem 14543MB
[2023-10-10 07:32:16 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][3000/6787]	eta 0:15:49 lr 0.000095	time 0.2470 (0.2508)	loss 0.3847 (0.3868)	grad_norm 362904.6875 (inf)	mem 14543MB
[2023-10-10 07:34:21 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][3500/6787]	eta 0:13:44 lr 0.000096	time 0.2512 (0.2508)	loss 0.4190 (0.3867)	grad_norm 335807.7812 (inf)	mem 14543MB
[2023-10-10 07:36:26 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][4000/6787]	eta 0:11:38 lr 0.000096	time 0.2588 (0.2507)	loss 0.3723 (0.3866)	grad_norm 727835.9375 (inf)	mem 14543MB
[2023-10-10 07:38:31 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][4500/6787]	eta 0:09:33 lr 0.000097	time 0.2522 (0.2506)	loss 0.3831 (0.3865)	grad_norm 556983.2500 (inf)	mem 14543MB
[2023-10-10 07:40:37 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][5000/6787]	eta 0:07:27 lr 0.000098	time 0.2449 (0.2506)	loss 0.3679 (0.3865)	grad_norm 215332.0156 (inf)	mem 14543MB
[2023-10-10 07:42:42 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][5500/6787]	eta 0:05:22 lr 0.000099	time 0.2553 (0.2507)	loss 0.3855 (0.3864)	grad_norm 302305.9375 (inf)	mem 14543MB
[2023-10-10 07:44:48 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][6000/6787]	eta 0:03:17 lr 0.000099	time 0.2467 (0.2507)	loss 0.3639 (0.3863)	grad_norm 642916.5625 (inf)	mem 14543MB
[2023-10-10 07:46:53 simmim_pretrain](main_simmim.py 218): INFO Train: [9/200][6500/6787]	eta 0:01:11 lr 0.000100	time 0.2517 (0.2507)	loss 0.3862 (0.3861)	grad_norm 245829.7031 (inf)	mem 14543MB
[2023-10-10 07:48:05 simmim_pretrain](main_simmim.py 228): INFO EPOCH 9 training takes 0:28:22
[2023-10-10 07:48:07 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][0/6787]	eta 2:39:31 lr 0.000101	time 1.4102 (1.4102)	loss 0.3614 (0.3614)	grad_norm 206831.5000 (206831.5000)	mem 14543MB
[2023-10-10 07:50:12 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][500/6787]	eta 0:26:29 lr 0.000101	time 0.2537 (0.2528)	loss 0.3976 (0.3877)	grad_norm 250481.3281 (277964.6875)	mem 14543MB
[2023-10-10 07:52:18 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][1000/6787]	eta 0:24:19 lr 0.000102	time 0.2493 (0.2522)	loss 0.3950 (0.3866)	grad_norm 289378.8438 (261880.9688)	mem 14543MB
[2023-10-10 07:54:24 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][1500/6787]	eta 0:22:12 lr 0.000103	time 0.2479 (0.2520)	loss 0.3967 (0.3860)	grad_norm 238961.7344 (258310.2500)	mem 14543MB
[2023-10-10 07:56:29 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][2000/6787]	eta 0:20:05 lr 0.000103	time 0.2485 (0.2519)	loss 0.4014 (0.3857)	grad_norm 327502.4688 (254304.8438)	mem 14543MB
[2023-10-10 07:58:35 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][2500/6787]	eta 0:17:58 lr 0.000104	time 0.2483 (0.2517)	loss 0.3639 (0.3853)	grad_norm 400637.7812 (281078.4688)	mem 14543MB
[2023-10-10 08:00:40 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][3000/6787]	eta 0:15:52 lr 0.000105	time 0.2491 (0.2515)	loss 0.3961 (0.3848)	grad_norm 352890.6250 (296152.2812)	mem 14543MB
[2023-10-10 08:02:46 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][3500/6787]	eta 0:13:46 lr 0.000106	time 0.2568 (0.2514)	loss 0.3667 (0.3847)	grad_norm 162273.3750 (310088.4688)	mem 14543MB
[2023-10-10 08:04:51 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][4000/6787]	eta 0:11:40 lr 0.000106	time 0.2547 (0.2514)	loss 0.3828 (0.3848)	grad_norm 212811.9688 (inf)	mem 14543MB
[2023-10-10 08:06:57 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][4500/6787]	eta 0:09:34 lr 0.000107	time 0.2542 (0.2514)	loss 0.3775 (0.3848)	grad_norm 204729.8438 (inf)	mem 14543MB
[2023-10-10 08:09:02 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][5000/6787]	eta 0:07:29 lr 0.000108	time 0.2515 (0.2513)	loss 0.3938 (0.3846)	grad_norm 193556.4219 (inf)	mem 14543MB
[2023-10-10 08:11:07 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][5500/6787]	eta 0:05:23 lr 0.000109	time 0.2584 (0.2512)	loss 0.3777 (0.3845)	grad_norm 337832.3438 (inf)	mem 14543MB
[2023-10-10 08:13:13 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][6000/6787]	eta 0:03:17 lr 0.000109	time 0.2485 (0.2512)	loss 0.3934 (0.3845)	grad_norm 202112.8438 (inf)	mem 14543MB
[2023-10-10 08:15:18 simmim_pretrain](main_simmim.py 218): INFO Train: [10/200][6500/6787]	eta 0:01:12 lr 0.000110	time 0.2473 (0.2511)	loss 0.3743 (0.3844)	grad_norm 253926.7344 (inf)	mem 14543MB
[2023-10-10 08:16:31 simmim_pretrain](main_simmim.py 228): INFO EPOCH 10 training takes 0:28:25
[2023-10-10 08:16:32 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][0/6787]	eta 2:35:59 lr 0.000110	time 1.3791 (1.3791)	loss 0.3652 (0.3652)	grad_norm 205525.9062 (205525.9062)	mem 14543MB
[2023-10-10 08:18:37 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][500/6787]	eta 0:26:27 lr 0.000111	time 0.2514 (0.2524)	loss 0.3697 (0.3828)	grad_norm 146882.2188 (211697.1562)	mem 14543MB
[2023-10-10 08:20:42 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][1000/6787]	eta 0:24:14 lr 0.000112	time 0.2513 (0.2514)	loss 0.3967 (0.3824)	grad_norm 592611.6875 (235206.2344)	mem 14543MB
[2023-10-10 08:22:47 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][1500/6787]	eta 0:22:06 lr 0.000113	time 0.2457 (0.2510)	loss 0.3838 (0.3819)	grad_norm 375908.1250 (275599.5938)	mem 14543MB
[2023-10-10 08:24:53 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][2000/6787]	eta 0:20:00 lr 0.000113	time 0.2545 (0.2509)	loss 0.3628 (0.3817)	grad_norm 183156.7656 (281917.5625)	mem 14543MB
[2023-10-10 08:26:58 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][2500/6787]	eta 0:17:55 lr 0.000114	time 0.2504 (0.2508)	loss 0.3877 (0.3815)	grad_norm 225173.9062 (291856.5938)	mem 14543MB
[2023-10-10 08:29:03 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][3000/6787]	eta 0:15:49 lr 0.000115	time 0.2463 (0.2508)	loss 0.3689 (0.3813)	grad_norm 298418.0625 (315759.6250)	mem 14543MB
[2023-10-10 08:31:09 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][3500/6787]	eta 0:13:44 lr 0.000116	time 0.2540 (0.2508)	loss 0.3907 (0.3813)	grad_norm 367320.2188 (inf)	mem 14543MB
[2023-10-10 08:33:14 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][4000/6787]	eta 0:11:38 lr 0.000116	time 0.2466 (0.2508)	loss 0.3818 (0.3813)	grad_norm 263023.5312 (inf)	mem 14543MB
[2023-10-10 08:35:19 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][4500/6787]	eta 0:09:33 lr 0.000117	time 0.2502 (0.2508)	loss 0.3637 (0.3813)	grad_norm 244497.2344 (inf)	mem 14543MB
[2023-10-10 08:37:25 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][5000/6787]	eta 0:07:28 lr 0.000118	time 0.2505 (0.2508)	loss 0.3614 (0.3814)	grad_norm 191996.0156 (inf)	mem 14543MB
[2023-10-10 08:39:30 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][5500/6787]	eta 0:05:22 lr 0.000119	time 0.2514 (0.2508)	loss 0.3688 (0.3812)	grad_norm 299578.2500 (inf)	mem 14543MB
[2023-10-10 08:41:36 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][6000/6787]	eta 0:03:17 lr 0.000119	time 0.2511 (0.2508)	loss 0.3755 (0.3811)	grad_norm 296311.7188 (inf)	mem 14543MB
[2023-10-10 08:43:41 simmim_pretrain](main_simmim.py 218): INFO Train: [11/200][6500/6787]	eta 0:01:11 lr 0.000120	time 0.2488 (0.2509)	loss 0.3962 (0.3810)	grad_norm 422952.8750 (inf)	mem 14543MB
[2023-10-10 08:44:54 simmim_pretrain](main_simmim.py 228): INFO EPOCH 11 training takes 0:28:23
[2023-10-10 08:44:55 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][0/6787]	eta 2:39:31 lr 0.000120	time 1.4102 (1.4102)	loss 0.3745 (0.3745)	grad_norm 484865.1562 (484865.1562)	mem 14543MB
[2023-10-10 08:47:01 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][500/6787]	eta 0:26:31 lr 0.000121	time 0.2541 (0.2532)	loss 0.3719 (0.3793)	grad_norm 470115.7188 (inf)	mem 14543MB
[2023-10-10 08:49:06 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][1000/6787]	eta 0:24:19 lr 0.000122	time 0.2529 (0.2522)	loss 0.3842 (0.3792)	grad_norm 764396.7500 (inf)	mem 14543MB
[2023-10-10 08:51:12 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][1500/6787]	eta 0:22:12 lr 0.000123	time 0.2485 (0.2520)	loss 0.3747 (0.3795)	grad_norm 328970.7188 (inf)	mem 14543MB
[2023-10-10 08:53:18 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][2000/6787]	eta 0:20:05 lr 0.000123	time 0.2571 (0.2518)	loss 0.3731 (0.3796)	grad_norm 670594.7500 (inf)	mem 14543MB
[2023-10-10 08:55:23 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][2500/6787]	eta 0:17:58 lr 0.000124	time 0.2509 (0.2516)	loss 0.3944 (0.3794)	grad_norm 296960.9688 (inf)	mem 14543MB
[2023-10-10 08:57:29 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][3000/6787]	eta 0:15:52 lr 0.000125	time 0.2590 (0.2514)	loss 0.3735 (0.3791)	grad_norm 424444.0000 (inf)	mem 14543MB
[2023-10-10 08:59:34 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][3500/6787]	eta 0:13:46 lr 0.000126	time 0.2523 (0.2514)	loss 0.3920 (0.3791)	grad_norm 327560.0312 (inf)	mem 14543MB
[2023-10-10 09:01:40 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][4000/6787]	eta 0:11:40 lr 0.000126	time 0.2525 (0.2514)	loss 0.3766 (0.3790)	grad_norm 415809.1875 (inf)	mem 14543MB
[2023-10-10 09:03:45 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][4500/6787]	eta 0:09:34 lr 0.000127	time 0.2504 (0.2514)	loss 0.3872 (0.3789)	grad_norm 255386.7344 (inf)	mem 14543MB
[2023-10-10 09:05:51 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][5000/6787]	eta 0:07:29 lr 0.000128	time 0.2589 (0.2513)	loss 0.3900 (0.3788)	grad_norm 466542.5000 (inf)	mem 14543MB
[2023-10-10 09:07:56 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][5500/6787]	eta 0:05:23 lr 0.000128	time 0.2495 (0.2513)	loss 0.3769 (0.3787)	grad_norm 407039.7188 (inf)	mem 14543MB
[2023-10-10 09:10:02 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][6000/6787]	eta 0:03:17 lr 0.000129	time 0.2507 (0.2513)	loss 0.3963 (0.3787)	grad_norm 707011.6250 (inf)	mem 14543MB
[2023-10-10 09:12:07 simmim_pretrain](main_simmim.py 218): INFO Train: [12/200][6500/6787]	eta 0:01:12 lr 0.000130	time 0.2570 (0.2513)	loss 0.3745 (0.3787)	grad_norm 349811.6562 (inf)	mem 14543MB
[2023-10-10 09:13:20 simmim_pretrain](main_simmim.py 228): INFO EPOCH 12 training takes 0:28:25
[2023-10-10 09:13:21 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][0/6787]	eta 2:45:14 lr 0.000130	time 1.4608 (1.4608)	loss 0.4052 (0.4052)	grad_norm 206445.3281 (206445.3281)	mem 14543MB
[2023-10-10 09:15:27 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][500/6787]	eta 0:26:32 lr 0.000131	time 0.2471 (0.2533)	loss 0.3712 (0.3775)	grad_norm 356742.4375 (400614.3125)	mem 14543MB
[2023-10-10 09:17:32 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][1000/6787]	eta 0:24:18 lr 0.000132	time 0.2492 (0.2521)	loss 0.3737 (0.3769)	grad_norm 364778.0938 (404376.3125)	mem 14543MB
[2023-10-10 09:19:38 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][1500/6787]	eta 0:22:10 lr 0.000133	time 0.2487 (0.2516)	loss 0.4008 (0.3768)	grad_norm 237716.0156 (inf)	mem 14543MB
[2023-10-10 09:21:43 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][2000/6787]	eta 0:20:03 lr 0.000133	time 0.2489 (0.2514)	loss 0.3800 (0.3775)	grad_norm 351537.3125 (inf)	mem 14543MB
[2023-10-10 09:23:49 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][2500/6787]	eta 0:17:57 lr 0.000134	time 0.2520 (0.2514)	loss 0.3871 (0.3779)	grad_norm 112729.3516 (inf)	mem 14543MB
[2023-10-10 09:25:54 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][3000/6787]	eta 0:15:51 lr 0.000135	time 0.2508 (0.2513)	loss 0.4020 (0.3781)	grad_norm 184437.5469 (inf)	mem 14543MB
[2023-10-10 09:27:59 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][3500/6787]	eta 0:13:45 lr 0.000135	time 0.2513 (0.2512)	loss 0.3640 (0.3782)	grad_norm 221889.7969 (inf)	mem 14543MB
[2023-10-10 09:30:05 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][4000/6787]	eta 0:11:39 lr 0.000136	time 0.2492 (0.2511)	loss 0.3579 (0.3780)	grad_norm 317096.5000 (inf)	mem 14543MB
[2023-10-10 09:32:10 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][4500/6787]	eta 0:09:34 lr 0.000137	time 0.2519 (0.2510)	loss 0.3949 (0.3779)	grad_norm 290177.7188 (inf)	mem 14543MB
[2023-10-10 09:34:15 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][5000/6787]	eta 0:07:28 lr 0.000138	time 0.2482 (0.2510)	loss 0.3680 (0.3778)	grad_norm 273392.9375 (inf)	mem 14543MB
[2023-10-10 09:36:21 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][5500/6787]	eta 0:05:23 lr 0.000138	time 0.2463 (0.2510)	loss 0.3673 (0.3777)	grad_norm 167449.9688 (inf)	mem 14543MB
[2023-10-10 09:38:26 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][6000/6787]	eta 0:03:17 lr 0.000139	time 0.2525 (0.2510)	loss 0.3810 (0.3775)	grad_norm 343543.6875 (inf)	mem 14543MB
[2023-10-10 09:40:32 simmim_pretrain](main_simmim.py 218): INFO Train: [13/200][6500/6787]	eta 0:01:12 lr 0.000140	time 0.2468 (0.2510)	loss 0.3784 (0.3774)	grad_norm 397498.8125 (inf)	mem 14543MB
[2023-10-10 09:41:44 simmim_pretrain](main_simmim.py 228): INFO EPOCH 13 training takes 0:28:24
[2023-10-10 09:41:45 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][0/6787]	eta 2:32:41 lr 0.000140	time 1.3499 (1.3499)	loss 0.3790 (0.3790)	grad_norm 157906.1406 (157906.1406)	mem 14543MB
[2023-10-10 09:43:51 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][500/6787]	eta 0:26:27 lr 0.000141	time 0.2483 (0.2526)	loss 0.3835 (0.3764)	grad_norm 265614.0000 (348892.8750)	mem 14543MB
[2023-10-10 09:45:56 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][1000/6787]	eta 0:24:16 lr 0.000142	time 0.2471 (0.2517)	loss 0.3623 (0.3762)	grad_norm 458638.5312 (376636.5938)	mem 14543MB
[2023-10-10 09:48:01 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][1500/6787]	eta 0:22:09 lr 0.000142	time 0.2499 (0.2515)	loss 0.3736 (0.3758)	grad_norm 315340.2812 (376060.9062)	mem 14543MB
[2023-10-10 09:50:07 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][2000/6787]	eta 0:20:03 lr 0.000143	time 0.2490 (0.2514)	loss 0.3591 (0.3756)	grad_norm 250537.8125 (inf)	mem 14543MB
[2023-10-10 09:52:12 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][2500/6787]	eta 0:17:57 lr 0.000144	time 0.2508 (0.2513)	loss 0.3965 (0.3757)	grad_norm 534742.6875 (inf)	mem 14543MB
[2023-10-10 09:54:18 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][3000/6787]	eta 0:15:51 lr 0.000145	time 0.2540 (0.2513)	loss 0.3713 (0.3757)	grad_norm 177548.0938 (inf)	mem 14543MB
[2023-10-10 09:56:24 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][3500/6787]	eta 0:13:45 lr 0.000145	time 0.2512 (0.2513)	loss 0.3679 (0.3759)	grad_norm 434317.5312 (inf)	mem 14543MB
[2023-10-10 09:58:29 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][4000/6787]	eta 0:11:40 lr 0.000146	time 0.2523 (0.2513)	loss 0.3780 (0.3761)	grad_norm 392255.7500 (inf)	mem 14543MB
[2023-10-10 10:00:35 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][4500/6787]	eta 0:09:34 lr 0.000147	time 0.2472 (0.2513)	loss 0.3873 (0.3763)	grad_norm 267664.6250 (inf)	mem 14543MB
[2023-10-10 10:02:40 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][5000/6787]	eta 0:07:28 lr 0.000148	time 0.2499 (0.2512)	loss 0.3720 (0.3765)	grad_norm 205618.3750 (inf)	mem 14543MB
[2023-10-10 10:04:45 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][5500/6787]	eta 0:05:23 lr 0.000148	time 0.2500 (0.2511)	loss 0.3801 (0.3765)	grad_norm 323696.4062 (inf)	mem 14543MB
[2023-10-10 10:06:51 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][6000/6787]	eta 0:03:17 lr 0.000149	time 0.2513 (0.2511)	loss 0.3932 (0.3765)	grad_norm 334242.9375 (inf)	mem 14543MB
[2023-10-10 10:08:56 simmim_pretrain](main_simmim.py 218): INFO Train: [14/200][6500/6787]	eta 0:01:12 lr 0.000150	time 0.2473 (0.2511)	loss 0.3664 (0.3765)	grad_norm 168673.9531 (inf)	mem 14543MB
[2023-10-10 10:10:09 simmim_pretrain](main_simmim.py 228): INFO EPOCH 14 training takes 0:28:24
[2023-10-10 10:10:10 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][0/6787]	eta 2:28:00 lr 0.000150	time 1.3084 (1.3084)	loss 0.3545 (0.3545)	grad_norm 348921.0938 (348921.0938)	mem 14543MB
[2023-10-10 10:12:15 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][500/6787]	eta 0:26:29 lr 0.000151	time 0.2513 (0.2528)	loss 0.3871 (0.3747)	grad_norm 249418.1562 (388708.0938)	mem 14543MB
[2023-10-10 10:14:21 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][1000/6787]	eta 0:24:15 lr 0.000152	time 0.2491 (0.2516)	loss 0.3828 (0.3745)	grad_norm 672871.3750 (378720.8125)	mem 14543MB
[2023-10-10 10:16:25 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][1500/6787]	eta 0:22:07 lr 0.000152	time 0.2469 (0.2510)	loss 0.3955 (0.3745)	grad_norm 569593.0000 (408535.6250)	mem 14543MB
[2023-10-10 10:18:31 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][2000/6787]	eta 0:20:01 lr 0.000153	time 0.2551 (0.2509)	loss 0.3684 (0.3744)	grad_norm 611606.6250 (433148.2500)	mem 14543MB
[2023-10-10 10:20:36 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][2500/6787]	eta 0:17:55 lr 0.000154	time 0.2512 (0.2509)	loss 0.3799 (0.3746)	grad_norm 244301.2969 (inf)	mem 14543MB
[2023-10-10 10:22:42 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][3000/6787]	eta 0:15:50 lr 0.000155	time 0.2497 (0.2509)	loss 0.3637 (0.3751)	grad_norm 168420.6406 (inf)	mem 14543MB
[2023-10-10 10:24:47 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][3500/6787]	eta 0:13:44 lr 0.000155	time 0.2466 (0.2509)	loss 0.4175 (0.3752)	grad_norm 155449.8438 (inf)	mem 14543MB
[2023-10-10 10:26:52 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][4000/6787]	eta 0:11:38 lr 0.000156	time 0.2534 (0.2507)	loss 0.3790 (0.3754)	grad_norm 273717.5938 (inf)	mem 14543MB
[2023-10-10 10:28:57 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][4500/6787]	eta 0:09:33 lr 0.000157	time 0.2525 (0.2507)	loss 0.3594 (0.3755)	grad_norm 463704.3125 (inf)	mem 14543MB
[2023-10-10 10:31:03 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][5000/6787]	eta 0:07:28 lr 0.000158	time 0.2519 (0.2507)	loss 0.3433 (0.3754)	grad_norm 291185.7812 (inf)	mem 14543MB
[2023-10-10 10:33:08 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][5500/6787]	eta 0:05:22 lr 0.000158	time 0.2596 (0.2508)	loss 0.3643 (0.3753)	grad_norm 334836.7500 (inf)	mem 14543MB
[2023-10-10 10:35:14 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][6000/6787]	eta 0:03:17 lr 0.000159	time 0.2543 (0.2508)	loss 0.3888 (0.3753)	grad_norm 485714.3750 (inf)	mem 14543MB
[2023-10-10 10:37:19 simmim_pretrain](main_simmim.py 218): INFO Train: [15/200][6500/6787]	eta 0:01:11 lr 0.000160	time 0.2473 (0.2508)	loss 0.3791 (0.3752)	grad_norm 241484.3750 (inf)	mem 14543MB
[2023-10-10 10:38:31 simmim_pretrain](main_simmim.py 228): INFO EPOCH 15 training takes 0:28:22
[2023-10-10 10:38:33 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][0/6787]	eta 2:42:39 lr 0.000160	time 1.4380 (1.4380)	loss 0.3894 (0.3894)	grad_norm 362608.6875 (362608.6875)	mem 14543MB
[2023-10-10 10:40:38 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][500/6787]	eta 0:26:30 lr 0.000161	time 0.2467 (0.2531)	loss 0.3715 (0.3739)	grad_norm 204073.4062 (389797.8750)	mem 14543MB
[2023-10-10 10:42:44 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][1000/6787]	eta 0:24:19 lr 0.000162	time 0.2531 (0.2522)	loss 0.4047 (0.3739)	grad_norm 298060.7812 (390827.1250)	mem 14543MB
[2023-10-10 10:44:50 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][1500/6787]	eta 0:22:11 lr 0.000162	time 0.2463 (0.2519)	loss 0.3602 (0.3742)	grad_norm 406142.9375 (413585.6250)	mem 14543MB
[2023-10-10 10:46:55 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][2000/6787]	eta 0:20:05 lr 0.000163	time 0.2520 (0.2518)	loss 0.3567 (0.3739)	grad_norm 382483.0938 (420028.4688)	mem 14543MB
[2023-10-10 10:49:01 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][2500/6787]	eta 0:17:58 lr 0.000164	time 0.2527 (0.2516)	loss 0.3507 (0.3739)	grad_norm 302461.8438 (inf)	mem 14543MB
[2023-10-10 10:51:06 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][3000/6787]	eta 0:15:52 lr 0.000165	time 0.2517 (0.2515)	loss 0.3827 (0.3738)	grad_norm 278482.3750 (inf)	mem 14543MB
[2023-10-10 10:53:12 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][3500/6787]	eta 0:13:46 lr 0.000165	time 0.2530 (0.2515)	loss 0.3645 (0.3738)	grad_norm 391500.1875 (inf)	mem 14543MB
[2023-10-10 10:55:18 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][4000/6787]	eta 0:11:40 lr 0.000166	time 0.2518 (0.2515)	loss 0.3427 (0.3739)	grad_norm 327112.0312 (inf)	mem 14543MB
[2023-10-10 10:57:23 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][4500/6787]	eta 0:09:35 lr 0.000167	time 0.2502 (0.2514)	loss 0.3659 (0.3740)	grad_norm 544566.3750 (inf)	mem 14543MB
[2023-10-10 10:59:28 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][5000/6787]	eta 0:07:29 lr 0.000168	time 0.2477 (0.2514)	loss 0.3801 (0.3740)	grad_norm 525298.6875 (inf)	mem 14543MB
[2023-10-10 11:01:34 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][5500/6787]	eta 0:05:23 lr 0.000168	time 0.2459 (0.2513)	loss 0.3583 (0.3740)	grad_norm 315833.1562 (inf)	mem 14543MB
[2023-10-10 11:03:39 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][6000/6787]	eta 0:03:17 lr 0.000169	time 0.2518 (0.2512)	loss 0.3775 (0.3740)	grad_norm 313538.5000 (inf)	mem 14543MB
[2023-10-10 11:05:45 simmim_pretrain](main_simmim.py 218): INFO Train: [16/200][6500/6787]	eta 0:01:12 lr 0.000170	time 0.2450 (0.2512)	loss 0.3825 (0.3740)	grad_norm 463360.4062 (inf)	mem 14543MB
[2023-10-10 11:06:57 simmim_pretrain](main_simmim.py 228): INFO EPOCH 16 training takes 0:28:25
[2023-10-10 11:06:58 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][0/6787]	eta 2:32:04 lr 0.000170	time 1.3444 (1.3444)	loss 0.3684 (0.3684)	grad_norm 429457.3125 (429457.3125)	mem 14543MB
[2023-10-10 11:09:04 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][500/6787]	eta 0:26:28 lr 0.000171	time 0.2518 (0.2527)	loss 0.3724 (0.3734)	grad_norm 277655.5625 (435504.7188)	mem 14543MB
[2023-10-10 11:11:09 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][1000/6787]	eta 0:24:16 lr 0.000172	time 0.2500 (0.2516)	loss 0.3500 (0.3734)	grad_norm 880038.3750 (430012.0625)	mem 14543MB
[2023-10-10 11:13:14 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][1500/6787]	eta 0:22:08 lr 0.000172	time 0.2460 (0.2512)	loss 0.3756 (0.3735)	grad_norm 368309.5938 (427902.3750)	mem 14543MB
[2023-10-10 11:15:20 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][2000/6787]	eta 0:20:01 lr 0.000173	time 0.2537 (0.2511)	loss 0.3495 (0.3735)	grad_norm 314261.6875 (inf)	mem 14543MB
[2023-10-10 11:17:25 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][2500/6787]	eta 0:17:56 lr 0.000174	time 0.2474 (0.2511)	loss 0.3671 (0.3736)	grad_norm 403794.0625 (inf)	mem 14543MB
[2023-10-10 11:19:31 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][3000/6787]	eta 0:15:50 lr 0.000175	time 0.2529 (0.2511)	loss 0.3741 (0.3736)	grad_norm 328522.8438 (inf)	mem 14543MB
[2023-10-10 11:21:36 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][3500/6787]	eta 0:13:45 lr 0.000175	time 0.2515 (0.2511)	loss 0.3539 (0.3736)	grad_norm 207432.8125 (inf)	mem 14543MB
[2023-10-10 11:23:41 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][4000/6787]	eta 0:11:39 lr 0.000176	time 0.2533 (0.2510)	loss 0.3923 (0.3739)	grad_norm 253584.5469 (inf)	mem 14543MB
[2023-10-10 11:25:47 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][4500/6787]	eta 0:09:34 lr 0.000177	time 0.2494 (0.2510)	loss 0.3326 (0.3741)	grad_norm 203535.0469 (inf)	mem 14543MB
[2023-10-10 11:27:53 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][5000/6787]	eta 0:07:28 lr 0.000177	time 0.2547 (0.2511)	loss 0.3751 (0.3742)	grad_norm 213703.9531 (inf)	mem 14543MB
[2023-10-10 11:29:59 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][5500/6787]	eta 0:05:23 lr 0.000178	time 0.2507 (0.2511)	loss 0.3826 (0.3743)	grad_norm 269971.9375 (inf)	mem 14543MB
[2023-10-10 11:32:05 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][6000/6787]	eta 0:03:17 lr 0.000179	time 0.2462 (0.2512)	loss 0.3550 (0.3742)	grad_norm 183230.6094 (inf)	mem 14543MB
[2023-10-10 11:34:10 simmim_pretrain](main_simmim.py 218): INFO Train: [17/200][6500/6787]	eta 0:01:12 lr 0.000180	time 0.2534 (0.2512)	loss 0.3435 (0.3741)	grad_norm 274625.6250 (inf)	mem 14543MB
[2023-10-10 11:35:23 simmim_pretrain](main_simmim.py 228): INFO EPOCH 17 training takes 0:28:25
[2023-10-10 11:35:24 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][0/6787]	eta 2:32:31 lr 0.000180	time 1.3484 (1.3484)	loss 0.3527 (0.3527)	grad_norm 467103.2188 (467103.2188)	mem 14543MB
[2023-10-10 11:37:30 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][500/6787]	eta 0:26:32 lr 0.000181	time 0.2516 (0.2534)	loss 0.3815 (0.3724)	grad_norm 338192.0312 (373958.0938)	mem 14543MB
[2023-10-10 11:39:36 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][1000/6787]	eta 0:24:22 lr 0.000182	time 0.2586 (0.2527)	loss 0.3758 (0.3723)	grad_norm 247274.8750 (inf)	mem 14543MB
[2023-10-10 11:41:42 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][1500/6787]	eta 0:22:14 lr 0.000182	time 0.2521 (0.2524)	loss 0.3602 (0.3725)	grad_norm 319412.8750 (inf)	mem 14543MB
[2023-10-10 11:43:48 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][2000/6787]	eta 0:20:07 lr 0.000183	time 0.2493 (0.2523)	loss 0.3636 (0.3723)	grad_norm 288363.0625 (inf)	mem 14543MB
[2023-10-10 11:45:53 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][2500/6787]	eta 0:18:00 lr 0.000184	time 0.2502 (0.2520)	loss 0.3819 (0.3723)	grad_norm 243989.2812 (inf)	mem 14543MB
[2023-10-10 11:47:59 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][3000/6787]	eta 0:15:54 lr 0.000184	time 0.2545 (0.2519)	loss 0.3540 (0.3725)	grad_norm 432844.7188 (inf)	mem 14543MB
[2023-10-10 11:50:05 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][3500/6787]	eta 0:13:48 lr 0.000185	time 0.2486 (0.2519)	loss 0.3596 (0.3725)	grad_norm 425532.1562 (inf)	mem 14543MB
[2023-10-10 11:52:12 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][4000/6787]	eta 0:11:42 lr 0.000186	time 0.2540 (0.2521)	loss 0.3539 (0.3723)	grad_norm 317772.3438 (inf)	mem 14543MB
[2023-10-10 11:54:19 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][4500/6787]	eta 0:09:37 lr 0.000187	time 0.2525 (0.2524)	loss 0.3680 (0.3724)	grad_norm 671943.8750 (inf)	mem 14543MB
[2023-10-10 11:56:26 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][5000/6787]	eta 0:07:31 lr 0.000187	time 0.2496 (0.2526)	loss 0.3616 (0.3725)	grad_norm 406137.6250 (inf)	mem 14543MB
[2023-10-10 11:58:33 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][5500/6787]	eta 0:05:25 lr 0.000188	time 0.2542 (0.2527)	loss 0.3831 (0.3725)	grad_norm 449747.0938 (inf)	mem 14543MB
[2023-10-10 12:00:40 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][6000/6787]	eta 0:03:19 lr 0.000189	time 0.2527 (0.2529)	loss 0.3725 (0.3727)	grad_norm 172115.6719 (inf)	mem 14543MB
[2023-10-10 12:02:48 simmim_pretrain](main_simmim.py 218): INFO Train: [18/200][6500/6787]	eta 0:01:12 lr 0.000190	time 0.2593 (0.2530)	loss 0.3618 (0.3728)	grad_norm 194137.2812 (inf)	mem 14543MB
[2023-10-10 12:04:01 simmim_pretrain](main_simmim.py 228): INFO EPOCH 18 training takes 0:28:38
[2023-10-10 12:04:02 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][0/6787]	eta 2:32:05 lr 0.000190	time 1.3446 (1.3446)	loss 0.3613 (0.3613)	grad_norm 464952.2188 (464952.2188)	mem 14543MB
[2023-10-10 12:06:08 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][500/6787]	eta 0:26:31 lr 0.000191	time 0.2536 (0.2532)	loss 0.3670 (0.3738)	grad_norm 212797.4062 (246745.7656)	mem 14543MB
[2023-10-10 12:08:13 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][1000/6787]	eta 0:24:17 lr 0.000192	time 0.2521 (0.2519)	loss 0.3634 (0.3736)	grad_norm 267791.7188 (266371.5312)	mem 14543MB
[2023-10-10 12:10:19 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][1500/6787]	eta 0:22:11 lr 0.000192	time 0.2545 (0.2518)	loss 0.3799 (0.3732)	grad_norm 311535.1562 (294528.4062)	mem 14543MB
[2023-10-10 12:12:25 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][2000/6787]	eta 0:20:05 lr 0.000193	time 0.2470 (0.2518)	loss 0.3873 (0.3727)	grad_norm 849710.6875 (328538.2188)	mem 14543MB
[2023-10-10 12:14:31 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][2500/6787]	eta 0:17:59 lr 0.000194	time 0.2561 (0.2519)	loss 0.3572 (0.3726)	grad_norm 539647.1875 (348918.1562)	mem 14543MB
[2023-10-10 12:16:38 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][3000/6787]	eta 0:15:54 lr 0.000194	time 0.2559 (0.2521)	loss 0.3821 (0.3723)	grad_norm 341284.0938 (inf)	mem 14543MB
[2023-10-10 12:18:44 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][3500/6787]	eta 0:13:49 lr 0.000195	time 0.2488 (0.2522)	loss 0.3678 (0.3724)	grad_norm 221480.1094 (inf)	mem 14543MB
[2023-10-10 12:20:51 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][4000/6787]	eta 0:11:43 lr 0.000196	time 0.2517 (0.2524)	loss 0.3748 (0.3727)	grad_norm 328909.1875 (inf)	mem 14543MB
[2023-10-10 12:22:58 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][4500/6787]	eta 0:09:37 lr 0.000197	time 0.2564 (0.2526)	loss 0.3677 (0.3729)	grad_norm 413293.4375 (inf)	mem 14543MB
[2023-10-10 12:25:06 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][5000/6787]	eta 0:07:32 lr 0.000197	time 0.2556 (0.2530)	loss 0.3593 (0.3730)	grad_norm 174848.3281 (inf)	mem 14543MB
[2023-10-10 12:27:14 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][5500/6787]	eta 0:05:25 lr 0.000198	time 0.2559 (0.2533)	loss 0.3619 (0.3731)	grad_norm 319927.0625 (inf)	mem 14543MB
[2023-10-10 12:29:22 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][6000/6787]	eta 0:03:19 lr 0.000199	time 0.2542 (0.2535)	loss 0.3671 (0.3729)	grad_norm 284328.2812 (inf)	mem 14543MB
[2023-10-10 12:31:30 simmim_pretrain](main_simmim.py 218): INFO Train: [19/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2496 (0.2536)	loss 0.3611 (0.3728)	grad_norm 325417.2188 (inf)	mem 14543MB
[2023-10-10 12:32:43 simmim_pretrain](main_simmim.py 228): INFO EPOCH 19 training takes 0:28:41
[2023-10-10 12:32:44 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][0/6787]	eta 2:29:16 lr 0.000200	time 1.3197 (1.3197)	loss 0.3926 (0.3926)	grad_norm 302473.0938 (302473.0938)	mem 14543MB
[2023-10-10 12:34:50 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][500/6787]	eta 0:26:31 lr 0.000200	time 0.2449 (0.2531)	loss 0.3911 (0.3718)	grad_norm 356058.3438 (379502.5000)	mem 14543MB
[2023-10-10 12:36:56 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][1000/6787]	eta 0:24:20 lr 0.000200	time 0.2467 (0.2524)	loss 0.3344 (0.3719)	grad_norm 461852.4062 (inf)	mem 14543MB
[2023-10-10 12:39:02 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][1500/6787]	eta 0:22:14 lr 0.000200	time 0.2537 (0.2524)	loss 0.3749 (0.3719)	grad_norm 966050.7500 (inf)	mem 14543MB
[2023-10-10 12:41:08 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][2000/6787]	eta 0:20:08 lr 0.000200	time 0.2518 (0.2524)	loss 0.3607 (0.3717)	grad_norm 371261.0938 (inf)	mem 14543MB
[2023-10-10 12:43:14 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][2500/6787]	eta 0:18:00 lr 0.000200	time 0.2475 (0.2521)	loss 0.3600 (0.3716)	grad_norm 453384.7500 (inf)	mem 14543MB
[2023-10-10 12:45:19 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][3000/6787]	eta 0:15:54 lr 0.000200	time 0.2489 (0.2520)	loss 0.3779 (0.3715)	grad_norm 363761.8750 (inf)	mem 14543MB
[2023-10-10 12:47:25 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][3500/6787]	eta 0:13:48 lr 0.000200	time 0.2504 (0.2520)	loss 0.3503 (0.3715)	grad_norm 405188.3750 (inf)	mem 14543MB
[2023-10-10 12:49:31 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2469 (0.2520)	loss 0.3788 (0.3714)	grad_norm 404538.0000 (inf)	mem 14543MB
[2023-10-10 12:51:37 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2527 (0.2520)	loss 0.3607 (0.3714)	grad_norm 401065.4062 (inf)	mem 14543MB
[2023-10-10 12:53:43 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2490 (0.2520)	loss 0.3415 (0.3714)	grad_norm 457884.4062 (inf)	mem 14543MB
[2023-10-10 12:55:50 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2540 (0.2520)	loss 0.3888 (0.3715)	grad_norm 152101.7031 (inf)	mem 14543MB
[2023-10-10 12:57:56 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2518 (0.2521)	loss 0.3691 (0.3716)	grad_norm 115370.9375 (inf)	mem 14543MB
[2023-10-10 13:00:02 simmim_pretrain](main_simmim.py 218): INFO Train: [20/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2573 (0.2521)	loss 0.3680 (0.3718)	grad_norm 431211.0312 (inf)	mem 14543MB
[2023-10-10 13:01:16 simmim_pretrain](main_simmim.py 228): INFO EPOCH 20 training takes 0:28:33
[2023-10-10 13:01:16 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_20.pth saving......
[2023-10-10 13:01:17 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_20.pth saved !!!
[2023-10-10 13:01:18 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][0/6787]	eta 2:23:19 lr 0.000200	time 1.2671 (1.2671)	loss 0.3834 (0.3834)	grad_norm 235104.2188 (235104.2188)	mem 14543MB
[2023-10-10 13:03:24 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2570 (0.2530)	loss 0.3685 (0.3731)	grad_norm 222242.5000 (275479.8125)	mem 14543MB
[2023-10-10 13:05:29 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2494 (0.2519)	loss 0.3713 (0.3718)	grad_norm 424868.4062 (327895.8125)	mem 14543MB
[2023-10-10 13:07:35 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2467 (0.2516)	loss 0.3673 (0.3716)	grad_norm 630535.5625 (352256.3750)	mem 14543MB
[2023-10-10 13:09:40 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][2000/6787]	eta 0:20:04 lr 0.000200	time 0.2512 (0.2515)	loss 0.3743 (0.3714)	grad_norm 846767.5625 (389730.0625)	mem 14543MB
[2023-10-10 13:11:46 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2588 (0.2516)	loss 0.3435 (0.3713)	grad_norm 334865.5625 (392149.5625)	mem 14543MB
[2023-10-10 13:13:52 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2594 (0.2516)	loss 0.3633 (0.3712)	grad_norm 259036.5000 (inf)	mem 14543MB
[2023-10-10 13:15:58 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2527 (0.2516)	loss 0.3686 (0.3712)	grad_norm 262700.6875 (inf)	mem 14543MB
[2023-10-10 13:18:04 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2464 (0.2516)	loss 0.3899 (0.3712)	grad_norm 409823.5312 (inf)	mem 14543MB
[2023-10-10 13:20:10 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2471 (0.2516)	loss 0.3811 (0.3711)	grad_norm 286651.1562 (inf)	mem 14543MB
[2023-10-10 13:22:17 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2606 (0.2520)	loss 0.3807 (0.3711)	grad_norm 592382.5000 (inf)	mem 14543MB
[2023-10-10 13:24:27 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2603 (0.2527)	loss 0.3903 (0.3711)	grad_norm 286478.8125 (inf)	mem 14543MB
[2023-10-10 13:26:37 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2598 (0.2533)	loss 0.3667 (0.3710)	grad_norm 451122.3438 (inf)	mem 14543MB
[2023-10-10 13:28:47 simmim_pretrain](main_simmim.py 218): INFO Train: [21/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2524 (0.2537)	loss 0.3643 (0.3710)	grad_norm 154783.6250 (inf)	mem 14543MB
[2023-10-10 13:30:02 simmim_pretrain](main_simmim.py 228): INFO EPOCH 21 training takes 0:28:44
[2023-10-10 13:30:03 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][0/6787]	eta 2:31:40 lr 0.000200	time 1.3409 (1.3409)	loss 0.3810 (0.3810)	grad_norm 289879.5938 (289879.5938)	mem 14543MB
[2023-10-10 13:32:09 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][500/6787]	eta 0:26:35 lr 0.000200	time 0.2547 (0.2538)	loss 0.3609 (0.3736)	grad_norm 270675.0312 (268461.7188)	mem 14543MB
[2023-10-10 13:34:15 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][1000/6787]	eta 0:24:23 lr 0.000200	time 0.2518 (0.2529)	loss 0.3704 (0.3732)	grad_norm 394348.3750 (259644.0938)	mem 14543MB
[2023-10-10 13:36:20 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][1500/6787]	eta 0:22:14 lr 0.000200	time 0.2502 (0.2525)	loss 0.3590 (0.3720)	grad_norm 193207.6562 (273961.2812)	mem 14543MB
[2023-10-10 13:38:26 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][2000/6787]	eta 0:20:07 lr 0.000200	time 0.2446 (0.2522)	loss 0.3753 (0.3715)	grad_norm 227379.9531 (283740.4375)	mem 14543MB
[2023-10-10 13:40:32 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][2500/6787]	eta 0:18:00 lr 0.000200	time 0.2485 (0.2520)	loss 0.3821 (0.3711)	grad_norm 520665.6875 (300077.6875)	mem 14543MB
[2023-10-10 13:42:37 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][3000/6787]	eta 0:15:53 lr 0.000200	time 0.2529 (0.2519)	loss 0.3750 (0.3708)	grad_norm 405808.3438 (317226.6250)	mem 14543MB
[2023-10-10 13:44:43 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2467 (0.2518)	loss 0.3653 (0.3706)	grad_norm 303378.8438 (inf)	mem 14543MB
[2023-10-10 13:46:49 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2515 (0.2518)	loss 0.3600 (0.3705)	grad_norm 269864.5000 (inf)	mem 14543MB
[2023-10-10 13:48:55 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2494 (0.2517)	loss 0.3691 (0.3705)	grad_norm 742575.8750 (inf)	mem 14543MB
[2023-10-10 13:51:00 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2490 (0.2516)	loss 0.3680 (0.3708)	grad_norm 341472.4062 (inf)	mem 14543MB
[2023-10-10 13:53:06 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2560 (0.2516)	loss 0.3643 (0.3709)	grad_norm 281018.0312 (inf)	mem 14543MB
[2023-10-10 13:55:13 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2464 (0.2518)	loss 0.3654 (0.3711)	grad_norm 255319.9219 (inf)	mem 14543MB
[2023-10-10 13:57:21 simmim_pretrain](main_simmim.py 218): INFO Train: [22/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2570 (0.2522)	loss 0.3789 (0.3712)	grad_norm 211942.9688 (inf)	mem 14543MB
[2023-10-10 13:58:35 simmim_pretrain](main_simmim.py 228): INFO EPOCH 22 training takes 0:28:33
[2023-10-10 13:58:36 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][0/6787]	eta 2:41:54 lr 0.000200	time 1.4313 (1.4313)	loss 0.3728 (0.3728)	grad_norm 229706.9688 (229706.9688)	mem 14543MB
[2023-10-10 14:00:44 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][500/6787]	eta 0:27:05 lr 0.000200	time 0.2596 (0.2585)	loss 0.3633 (0.3691)	grad_norm 414433.1562 (420590.0000)	mem 14543MB
[2023-10-10 14:02:53 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][1000/6787]	eta 0:24:51 lr 0.000200	time 0.2571 (0.2577)	loss 0.3611 (0.3691)	grad_norm 436161.5938 (404555.8125)	mem 14543MB
[2023-10-10 14:05:01 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][1500/6787]	eta 0:22:40 lr 0.000200	time 0.2550 (0.2573)	loss 0.3597 (0.3696)	grad_norm 752669.5000 (415470.2188)	mem 14543MB
[2023-10-10 14:07:10 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][2000/6787]	eta 0:20:31 lr 0.000200	time 0.2558 (0.2572)	loss 0.3747 (0.3697)	grad_norm 398325.4375 (440738.3750)	mem 14543MB
[2023-10-10 14:09:18 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][2500/6787]	eta 0:18:22 lr 0.000200	time 0.2560 (0.2572)	loss 0.3679 (0.3695)	grad_norm 380331.3125 (inf)	mem 14543MB
[2023-10-10 14:11:27 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][3000/6787]	eta 0:16:13 lr 0.000200	time 0.2596 (0.2572)	loss 0.3509 (0.3693)	grad_norm 256807.2188 (inf)	mem 14543MB
[2023-10-10 14:13:35 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][3500/6787]	eta 0:14:04 lr 0.000200	time 0.2601 (0.2570)	loss 0.3745 (0.3693)	grad_norm 368639.8750 (inf)	mem 14543MB
[2023-10-10 14:15:43 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][4000/6787]	eta 0:11:56 lr 0.000200	time 0.2542 (0.2570)	loss 0.3767 (0.3694)	grad_norm 232656.0156 (inf)	mem 14543MB
[2023-10-10 14:17:51 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][4500/6787]	eta 0:09:47 lr 0.000200	time 0.2599 (0.2569)	loss 0.3766 (0.3694)	grad_norm 519942.1250 (inf)	mem 14543MB
[2023-10-10 14:20:00 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][5000/6787]	eta 0:07:39 lr 0.000200	time 0.2558 (0.2570)	loss 0.3692 (0.3694)	grad_norm 196221.0000 (inf)	mem 14543MB
[2023-10-10 14:22:09 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][5500/6787]	eta 0:05:30 lr 0.000200	time 0.2588 (0.2570)	loss 0.3740 (0.3694)	grad_norm 454338.6250 (inf)	mem 14543MB
[2023-10-10 14:24:17 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2586 (0.2570)	loss 0.3660 (0.3694)	grad_norm 584048.8125 (inf)	mem 14543MB
[2023-10-10 14:26:27 simmim_pretrain](main_simmim.py 218): INFO Train: [23/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2674 (0.2572)	loss 0.3715 (0.3694)	grad_norm 496958.9688 (inf)	mem 14543MB
[2023-10-10 14:27:41 simmim_pretrain](main_simmim.py 228): INFO EPOCH 23 training takes 0:29:06
[2023-10-10 14:27:42 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][0/6787]	eta 2:32:36 lr 0.000200	time 1.3492 (1.3492)	loss 0.3663 (0.3663)	grad_norm 379275.5000 (379275.5000)	mem 14543MB
[2023-10-10 14:29:51 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][500/6787]	eta 0:27:15 lr 0.000200	time 0.2597 (0.2602)	loss 0.3696 (0.3697)	grad_norm 483015.3125 (464004.2188)	mem 14543MB
[2023-10-10 14:32:00 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][1000/6787]	eta 0:24:58 lr 0.000200	time 0.2615 (0.2590)	loss 0.3676 (0.3705)	grad_norm 348116.3750 (inf)	mem 14543MB
[2023-10-10 14:34:10 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][1500/6787]	eta 0:22:48 lr 0.000200	time 0.2604 (0.2589)	loss 0.3557 (0.3712)	grad_norm 233333.4531 (inf)	mem 14543MB
[2023-10-10 14:36:18 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][2000/6787]	eta 0:20:37 lr 0.000200	time 0.2571 (0.2586)	loss 0.3783 (0.3716)	grad_norm 469070.0938 (inf)	mem 14543MB
[2023-10-10 14:38:28 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][2500/6787]	eta 0:18:28 lr 0.000200	time 0.2593 (0.2585)	loss 0.3658 (0.3714)	grad_norm 397583.6875 (inf)	mem 14543MB
[2023-10-10 14:40:37 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][3000/6787]	eta 0:16:19 lr 0.000200	time 0.2541 (0.2585)	loss 0.3706 (0.3713)	grad_norm 334887.9062 (inf)	mem 14543MB
[2023-10-10 14:42:46 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][3500/6787]	eta 0:14:10 lr 0.000200	time 0.2584 (0.2586)	loss 0.3691 (0.3709)	grad_norm 303614.9062 (inf)	mem 14543MB
[2023-10-10 14:44:56 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][4000/6787]	eta 0:12:00 lr 0.000200	time 0.2583 (0.2586)	loss 0.3598 (0.3708)	grad_norm 268938.7188 (inf)	mem 14543MB
[2023-10-10 14:47:05 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][4500/6787]	eta 0:09:51 lr 0.000200	time 0.2702 (0.2585)	loss 0.3562 (0.3709)	grad_norm 341748.3438 (inf)	mem 14543MB
[2023-10-10 14:49:14 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][5000/6787]	eta 0:07:41 lr 0.000200	time 0.2560 (0.2585)	loss 0.3705 (0.3709)	grad_norm 261469.5469 (inf)	mem 14543MB
[2023-10-10 14:51:23 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][5500/6787]	eta 0:05:32 lr 0.000200	time 0.2587 (0.2585)	loss 0.3703 (0.3709)	grad_norm 298047.9688 (inf)	mem 14543MB
[2023-10-10 14:53:32 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][6000/6787]	eta 0:03:23 lr 0.000200	time 0.2491 (0.2585)	loss 0.3607 (0.3708)	grad_norm 342671.8438 (inf)	mem 14543MB
[2023-10-10 14:55:42 simmim_pretrain](main_simmim.py 218): INFO Train: [24/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2568 (0.2585)	loss 0.3590 (0.3706)	grad_norm 449279.7188 (inf)	mem 14543MB
[2023-10-10 14:56:56 simmim_pretrain](main_simmim.py 228): INFO EPOCH 24 training takes 0:29:15
[2023-10-10 14:56:58 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][0/6787]	eta 2:19:38 lr 0.000200	time 1.2346 (1.2346)	loss 0.3524 (0.3524)	grad_norm 642508.6250 (642508.6250)	mem 14543MB
[2023-10-10 14:59:07 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][500/6787]	eta 0:27:13 lr 0.000200	time 0.2540 (0.2598)	loss 0.3810 (0.3692)	grad_norm 483071.6875 (447253.1562)	mem 14543MB
[2023-10-10 15:01:15 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][1000/6787]	eta 0:24:56 lr 0.000200	time 0.2555 (0.2586)	loss 0.3376 (0.3692)	grad_norm 475614.5625 (inf)	mem 14543MB
[2023-10-10 15:03:24 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][1500/6787]	eta 0:22:45 lr 0.000200	time 0.2480 (0.2582)	loss 0.3769 (0.3690)	grad_norm 412166.6875 (inf)	mem 14543MB
[2023-10-10 15:05:33 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][2000/6787]	eta 0:20:35 lr 0.000200	time 0.2608 (0.2581)	loss 0.4118 (0.3691)	grad_norm 215914.2188 (inf)	mem 14543MB
[2023-10-10 15:07:42 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][2500/6787]	eta 0:18:26 lr 0.000200	time 0.2592 (0.2580)	loss 0.3598 (0.3696)	grad_norm 356511.2188 (inf)	mem 14543MB
[2023-10-10 15:09:51 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][3000/6787]	eta 0:16:17 lr 0.000200	time 0.2543 (0.2580)	loss 0.3507 (0.3698)	grad_norm 249067.2031 (inf)	mem 14543MB
[2023-10-10 15:12:00 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][3500/6787]	eta 0:14:07 lr 0.000200	time 0.2595 (0.2580)	loss 0.3824 (0.3700)	grad_norm 306355.7500 (inf)	mem 14543MB
[2023-10-10 15:14:09 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][4000/6787]	eta 0:11:59 lr 0.000200	time 0.2556 (0.2580)	loss 0.3645 (0.3699)	grad_norm 264329.4688 (inf)	mem 14543MB
[2023-10-10 15:16:18 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][4500/6787]	eta 0:09:50 lr 0.000200	time 0.2596 (0.2581)	loss 0.3684 (0.3698)	grad_norm 201503.5312 (inf)	mem 14543MB
[2023-10-10 15:18:27 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][5000/6787]	eta 0:07:41 lr 0.000200	time 0.2620 (0.2581)	loss 0.3564 (0.3697)	grad_norm 391118.1875 (inf)	mem 14543MB
[2023-10-10 15:20:36 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][5500/6787]	eta 0:05:32 lr 0.000200	time 0.2599 (0.2581)	loss 0.3547 (0.3696)	grad_norm 544776.5000 (inf)	mem 14543MB
[2023-10-10 15:22:45 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][6000/6787]	eta 0:03:23 lr 0.000200	time 0.3232 (0.2581)	loss 0.3382 (0.3695)	grad_norm 322811.3438 (inf)	mem 14543MB
[2023-10-10 15:24:54 simmim_pretrain](main_simmim.py 218): INFO Train: [25/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2552 (0.2581)	loss 0.3623 (0.3695)	grad_norm 281809.4062 (inf)	mem 14543MB
[2023-10-10 15:26:09 simmim_pretrain](main_simmim.py 228): INFO EPOCH 25 training takes 0:29:12
[2023-10-10 15:26:10 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][0/6787]	eta 2:32:04 lr 0.000200	time 1.3445 (1.3445)	loss 0.3839 (0.3839)	grad_norm 391179.9375 (391179.9375)	mem 14543MB
[2023-10-10 15:28:20 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][500/6787]	eta 0:27:21 lr 0.000200	time 0.2600 (0.2610)	loss 0.3830 (0.3718)	grad_norm 160152.8594 (280513.9688)	mem 14543MB
[2023-10-10 15:30:29 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][1000/6787]	eta 0:25:01 lr 0.000200	time 0.2572 (0.2595)	loss 0.3767 (0.3703)	grad_norm 212435.6250 (273766.3438)	mem 14543MB
[2023-10-10 15:32:38 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][1500/6787]	eta 0:22:50 lr 0.000200	time 0.2560 (0.2592)	loss 0.3584 (0.3704)	grad_norm 289258.7188 (inf)	mem 14543MB
[2023-10-10 15:34:47 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][2000/6787]	eta 0:20:38 lr 0.000200	time 0.2600 (0.2588)	loss 0.3674 (0.3704)	grad_norm 219745.4219 (inf)	mem 14543MB
[2023-10-10 15:36:56 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][2500/6787]	eta 0:18:29 lr 0.000200	time 0.2580 (0.2587)	loss 0.3742 (0.3705)	grad_norm 251749.8594 (inf)	mem 14543MB
[2023-10-10 15:39:05 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][3000/6787]	eta 0:16:19 lr 0.000200	time 0.2593 (0.2587)	loss 0.3725 (0.3704)	grad_norm 155780.5312 (inf)	mem 14543MB
[2023-10-10 15:41:15 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][3500/6787]	eta 0:14:10 lr 0.000200	time 0.2575 (0.2589)	loss 0.3571 (0.3702)	grad_norm 587182.5000 (inf)	mem 14543MB
[2023-10-10 15:43:25 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][4000/6787]	eta 0:12:01 lr 0.000200	time 0.2541 (0.2588)	loss 0.3812 (0.3700)	grad_norm 330259.1875 (inf)	mem 14543MB
[2023-10-10 15:45:34 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][4500/6787]	eta 0:09:51 lr 0.000200	time 0.2606 (0.2587)	loss 0.3644 (0.3700)	grad_norm 410214.2500 (inf)	mem 14543MB
[2023-10-10 15:47:43 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][5000/6787]	eta 0:07:42 lr 0.000200	time 0.2620 (0.2588)	loss 0.3703 (0.3698)	grad_norm 684560.3750 (inf)	mem 14543MB
[2023-10-10 15:49:53 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][5500/6787]	eta 0:05:33 lr 0.000200	time 0.2609 (0.2589)	loss 0.3766 (0.3697)	grad_norm 433148.9688 (inf)	mem 14543MB
[2023-10-10 15:52:03 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][6000/6787]	eta 0:03:23 lr 0.000200	time 0.2597 (0.2589)	loss 0.3448 (0.3696)	grad_norm 389326.5000 (inf)	mem 14543MB
[2023-10-10 15:54:11 simmim_pretrain](main_simmim.py 218): INFO Train: [26/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2617 (0.2588)	loss 0.4199 (0.3753)	grad_norm 21360.9102 (inf)	mem 14543MB
[2023-10-10 15:55:26 simmim_pretrain](main_simmim.py 228): INFO EPOCH 26 training takes 0:29:16
[2023-10-10 15:55:27 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][0/6787]	eta 2:22:33 lr 0.000200	time 1.2603 (1.2603)	loss 0.3957 (0.3957)	grad_norm 37415.8945 (37415.8945)	mem 14543MB
[2023-10-10 15:57:36 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][500/6787]	eta 0:27:18 lr 0.000200	time 0.2585 (0.2606)	loss 0.3674 (0.3884)	grad_norm 23052.9512 (31458.7070)	mem 14543MB
[2023-10-10 15:59:46 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][1000/6787]	eta 0:25:05 lr 0.000200	time 0.2540 (0.2601)	loss 0.3839 (0.3843)	grad_norm 22628.7949 (31893.4414)	mem 14543MB
[2023-10-10 16:01:56 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][1500/6787]	eta 0:22:54 lr 0.000200	time 0.2680 (0.2600)	loss 0.3809 (0.3815)	grad_norm 28995.1387 (32161.4082)	mem 14543MB
[2023-10-10 16:04:06 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][2000/6787]	eta 0:20:44 lr 0.000200	time 0.2663 (0.2599)	loss 0.3732 (0.3793)	grad_norm 55555.1836 (35052.3203)	mem 14543MB
[2023-10-10 16:06:15 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][2500/6787]	eta 0:18:33 lr 0.000200	time 0.2539 (0.2597)	loss 0.3566 (0.3779)	grad_norm 59955.3164 (38509.3945)	mem 14543MB
[2023-10-10 16:08:24 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][3000/6787]	eta 0:16:21 lr 0.000200	time 0.2657 (0.2593)	loss 0.3595 (0.3769)	grad_norm 45988.8633 (41120.0352)	mem 14543MB
[2023-10-10 16:10:34 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][3500/6787]	eta 0:14:12 lr 0.000200	time 0.2578 (0.2593)	loss 0.3818 (0.3761)	grad_norm 49253.2695 (43320.5508)	mem 14543MB
[2023-10-10 16:12:43 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][4000/6787]	eta 0:12:02 lr 0.000200	time 0.2587 (0.2593)	loss 0.3730 (0.3753)	grad_norm 79705.6094 (47119.9258)	mem 14543MB
[2023-10-10 16:14:54 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][4500/6787]	eta 0:09:53 lr 0.000200	time 0.2582 (0.2596)	loss 0.3524 (0.3746)	grad_norm 138937.0781 (52247.7617)	mem 14543MB
[2023-10-10 16:17:04 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][5000/6787]	eta 0:07:43 lr 0.000200	time 0.2699 (0.2596)	loss 0.3621 (0.3741)	grad_norm 96436.4453 (56802.6055)	mem 14543MB
[2023-10-10 16:19:13 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][5500/6787]	eta 0:05:33 lr 0.000200	time 0.2577 (0.2595)	loss 0.3819 (0.3736)	grad_norm 85795.3125 (61281.0195)	mem 14543MB
[2023-10-10 16:21:22 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][6000/6787]	eta 0:03:24 lr 0.000200	time 0.2525 (0.2594)	loss 0.3586 (0.3732)	grad_norm 61373.0898 (68195.5078)	mem 14543MB
[2023-10-10 16:23:32 simmim_pretrain](main_simmim.py 218): INFO Train: [27/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2507 (0.2593)	loss 0.3549 (0.3729)	grad_norm 83640.8047 (74236.5156)	mem 14543MB
[2023-10-10 16:24:47 simmim_pretrain](main_simmim.py 228): INFO EPOCH 27 training takes 0:29:21
[2023-10-10 16:24:48 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][0/6787]	eta 2:30:28 lr 0.000200	time 1.3302 (1.3302)	loss 0.3544 (0.3544)	grad_norm 187873.9531 (187873.9531)	mem 14543MB
[2023-10-10 16:26:58 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][500/6787]	eta 0:27:29 lr 0.000200	time 0.3378 (0.2624)	loss 0.3951 (0.3669)	grad_norm 63378.6602 (174702.1250)	mem 14543MB
[2023-10-10 16:29:08 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][1000/6787]	eta 0:25:11 lr 0.000200	time 0.2545 (0.2611)	loss 0.3523 (0.3669)	grad_norm 201273.6875 (195749.8281)	mem 14543MB
[2023-10-10 16:31:17 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][1500/6787]	eta 0:22:54 lr 0.000200	time 0.2578 (0.2601)	loss 0.3694 (0.3672)	grad_norm 253867.1719 (216915.2969)	mem 14543MB
[2023-10-10 16:33:27 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][2000/6787]	eta 0:20:43 lr 0.000200	time 0.2603 (0.2598)	loss 0.3662 (0.3672)	grad_norm 398629.9062 (268910.2188)	mem 14543MB
[2023-10-10 16:35:37 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][2500/6787]	eta 0:18:33 lr 0.000200	time 0.2618 (0.2597)	loss 0.3522 (0.3669)	grad_norm 674539.5000 (295994.8438)	mem 14543MB
[2023-10-10 16:37:47 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][3000/6787]	eta 0:16:23 lr 0.000200	time 0.2590 (0.2597)	loss 0.3657 (0.3670)	grad_norm 339590.1250 (inf)	mem 14543MB
[2023-10-10 16:39:57 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][3500/6787]	eta 0:14:14 lr 0.000200	time 0.2547 (0.2600)	loss 0.3941 (0.3670)	grad_norm 301137.6875 (inf)	mem 14543MB
[2023-10-10 16:42:06 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][4000/6787]	eta 0:12:03 lr 0.000200	time 0.2603 (0.2596)	loss 0.3630 (0.3670)	grad_norm 308230.6562 (inf)	mem 14543MB
[2023-10-10 16:44:15 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][4500/6787]	eta 0:09:53 lr 0.000200	time 0.2593 (0.2594)	loss 0.3493 (0.3667)	grad_norm 487719.5625 (inf)	mem 14543MB
[2023-10-10 16:46:24 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][5000/6787]	eta 0:07:43 lr 0.000200	time 0.2737 (0.2594)	loss 0.3537 (0.3667)	grad_norm 498045.3438 (inf)	mem 14543MB
[2023-10-10 16:48:34 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][5500/6787]	eta 0:05:33 lr 0.000200	time 0.2605 (0.2594)	loss 0.3700 (0.3668)	grad_norm 321145.5625 (inf)	mem 14543MB
[2023-10-10 16:50:44 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][6000/6787]	eta 0:03:24 lr 0.000200	time 0.2558 (0.2594)	loss 0.3826 (0.3668)	grad_norm 329313.7500 (inf)	mem 14543MB
[2023-10-10 16:52:53 simmim_pretrain](main_simmim.py 218): INFO Train: [28/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2597 (0.2594)	loss 0.3861 (0.3669)	grad_norm 391732.5938 (inf)	mem 14543MB
[2023-10-10 16:54:08 simmim_pretrain](main_simmim.py 228): INFO EPOCH 28 training takes 0:29:20
[2023-10-10 16:54:09 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][0/6787]	eta 2:32:37 lr 0.000200	time 1.3493 (1.3493)	loss 0.3603 (0.3603)	grad_norm 315861.4375 (315861.4375)	mem 14543MB
[2023-10-10 16:56:18 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][500/6787]	eta 0:27:14 lr 0.000200	time 0.2595 (0.2600)	loss 0.3534 (0.3667)	grad_norm 434402.4375 (inf)	mem 14543MB
[2023-10-10 16:58:27 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][1000/6787]	eta 0:24:59 lr 0.000200	time 0.2564 (0.2591)	loss 0.3626 (0.3665)	grad_norm 366216.0312 (inf)	mem 14543MB
[2023-10-10 17:00:37 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][1500/6787]	eta 0:22:51 lr 0.000200	time 0.2586 (0.2593)	loss 0.3572 (0.3663)	grad_norm 355779.8438 (inf)	mem 14543MB
[2023-10-10 17:02:47 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][2000/6787]	eta 0:20:43 lr 0.000200	time 0.2625 (0.2598)	loss 0.3775 (0.3664)	grad_norm 151953.0000 (inf)	mem 14543MB
[2023-10-10 17:04:57 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][2500/6787]	eta 0:18:33 lr 0.000200	time 0.2515 (0.2598)	loss 0.3604 (0.3667)	grad_norm 291492.6875 (inf)	mem 14543MB
[2023-10-10 17:07:06 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][3000/6787]	eta 0:16:22 lr 0.000200	time 0.2589 (0.2595)	loss 0.3652 (0.3669)	grad_norm 173830.3906 (inf)	mem 14543MB
[2023-10-10 17:09:16 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][3500/6787]	eta 0:14:13 lr 0.000200	time 0.2566 (0.2596)	loss 0.3779 (0.3670)	grad_norm 217783.1875 (inf)	mem 14543MB
[2023-10-10 17:11:26 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][4000/6787]	eta 0:12:03 lr 0.000200	time 0.2574 (0.2596)	loss 0.3743 (0.3672)	grad_norm 218028.3438 (inf)	mem 14543MB
[2023-10-10 17:13:37 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][4500/6787]	eta 0:09:53 lr 0.000200	time 0.2543 (0.2597)	loss 0.3449 (0.3673)	grad_norm 306959.4688 (inf)	mem 14543MB
[2023-10-10 17:15:46 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][5000/6787]	eta 0:07:44 lr 0.000200	time 0.2528 (0.2597)	loss 0.3803 (0.3672)	grad_norm 335075.6875 (inf)	mem 14543MB
[2023-10-10 17:17:55 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][5500/6787]	eta 0:05:34 lr 0.000200	time 0.2551 (0.2596)	loss 0.3613 (0.3672)	grad_norm 368315.3438 (inf)	mem 14543MB
[2023-10-10 17:20:06 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][6000/6787]	eta 0:03:24 lr 0.000200	time 0.2604 (0.2597)	loss 0.3827 (0.3671)	grad_norm 491268.8438 (inf)	mem 14543MB
[2023-10-10 17:22:16 simmim_pretrain](main_simmim.py 218): INFO Train: [29/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2598 (0.2597)	loss 0.3631 (0.3670)	grad_norm 389803.7500 (inf)	mem 14543MB
[2023-10-10 17:23:30 simmim_pretrain](main_simmim.py 228): INFO EPOCH 29 training takes 0:29:22
[2023-10-10 17:23:32 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][0/6787]	eta 2:40:39 lr 0.000200	time 1.4203 (1.4203)	loss 0.3706 (0.3706)	grad_norm 325290.2188 (325290.2188)	mem 14543MB
[2023-10-10 17:25:42 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][500/6787]	eta 0:27:26 lr 0.000200	time 0.2592 (0.2619)	loss 0.3641 (0.3672)	grad_norm 310988.2812 (293879.4062)	mem 14543MB
[2023-10-10 17:27:51 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][1000/6787]	eta 0:25:09 lr 0.000200	time 0.2510 (0.2608)	loss 0.3746 (0.3677)	grad_norm 199780.5156 (271692.2812)	mem 14543MB
[2023-10-10 17:30:01 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][1500/6787]	eta 0:22:54 lr 0.000200	time 0.2555 (0.2601)	loss 0.3648 (0.3676)	grad_norm 241104.8281 (262166.2812)	mem 14543MB
[2023-10-10 17:32:11 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][2000/6787]	eta 0:20:44 lr 0.000200	time 0.2571 (0.2600)	loss 0.3735 (0.3675)	grad_norm 590034.1875 (256445.9219)	mem 14543MB
[2023-10-10 17:34:20 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][2500/6787]	eta 0:18:34 lr 0.000200	time 0.2565 (0.2599)	loss 0.3631 (0.3675)	grad_norm 388314.3750 (263672.1562)	mem 14543MB
[2023-10-10 17:36:30 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][3000/6787]	eta 0:16:23 lr 0.000200	time 0.2633 (0.2597)	loss 0.3639 (0.3674)	grad_norm 335827.6562 (284529.8125)	mem 14543MB
[2023-10-10 17:38:38 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][3500/6787]	eta 0:14:12 lr 0.000200	time 0.2581 (0.2593)	loss 0.3755 (0.3673)	grad_norm 264653.5938 (297412.7188)	mem 14543MB
[2023-10-10 17:40:47 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][4000/6787]	eta 0:12:01 lr 0.000200	time 0.2525 (0.2590)	loss 0.3548 (0.3672)	grad_norm inf (inf)	mem 14543MB
[2023-10-10 17:42:56 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][4500/6787]	eta 0:09:52 lr 0.000200	time 0.2599 (0.2589)	loss 0.3550 (0.3669)	grad_norm 574306.4375 (inf)	mem 14543MB
[2023-10-10 17:45:05 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][5000/6787]	eta 0:07:42 lr 0.000200	time 0.2599 (0.2589)	loss 0.3664 (0.3668)	grad_norm 356478.4688 (inf)	mem 14543MB
[2023-10-10 17:47:15 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][5500/6787]	eta 0:05:33 lr 0.000200	time 0.2587 (0.2589)	loss 0.3625 (0.3668)	grad_norm 197556.9219 (inf)	mem 14543MB
[2023-10-10 17:49:24 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][6000/6787]	eta 0:03:23 lr 0.000200	time 0.2586 (0.2589)	loss 0.3650 (0.3668)	grad_norm 185451.1719 (inf)	mem 14543MB
[2023-10-10 17:51:34 simmim_pretrain](main_simmim.py 218): INFO Train: [30/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2600 (0.2589)	loss 0.3594 (0.3668)	grad_norm 243726.2812 (inf)	mem 14543MB
[2023-10-10 17:52:48 simmim_pretrain](main_simmim.py 228): INFO EPOCH 30 training takes 0:29:18
[2023-10-10 17:52:50 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][0/6787]	eta 2:47:00 lr 0.000200	time 1.4765 (1.4765)	loss 0.3584 (0.3584)	grad_norm 279391.9375 (279391.9375)	mem 14543MB
[2023-10-10 17:54:55 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][500/6787]	eta 0:26:28 lr 0.000200	time 0.2529 (0.2526)	loss 0.3634 (0.3679)	grad_norm 199318.0469 (300677.0625)	mem 14543MB
[2023-10-10 17:57:01 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2514 (0.2518)	loss 0.3859 (0.3678)	grad_norm 134295.1719 (inf)	mem 14543MB
[2023-10-10 17:59:06 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2488 (0.2517)	loss 0.3656 (0.3686)	grad_norm 172415.0156 (inf)	mem 14543MB
[2023-10-10 18:01:12 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][2000/6787]	eta 0:20:05 lr 0.000200	time 0.2463 (0.2517)	loss 0.3565 (0.3691)	grad_norm 109556.2266 (inf)	mem 14543MB
[2023-10-10 18:03:18 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2582 (0.2515)	loss 0.3634 (0.3693)	grad_norm 97669.3125 (inf)	mem 14543MB
[2023-10-10 18:05:23 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2495 (0.2516)	loss 0.3709 (0.3691)	grad_norm 84036.6562 (inf)	mem 14543MB
[2023-10-10 18:07:30 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2586 (0.2517)	loss 0.3605 (0.3689)	grad_norm 99617.6484 (inf)	mem 14543MB
[2023-10-10 18:09:36 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2593 (0.2518)	loss 0.3570 (0.3687)	grad_norm 95499.8047 (inf)	mem 14543MB
[2023-10-10 18:11:42 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2465 (0.2519)	loss 0.3641 (0.3686)	grad_norm 235403.1562 (inf)	mem 14543MB
[2023-10-10 18:13:48 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2507 (0.2520)	loss 0.3516 (0.3685)	grad_norm 161023.8750 (inf)	mem 14543MB
[2023-10-10 18:15:55 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2511 (0.2520)	loss 0.3751 (0.3683)	grad_norm 241905.4688 (inf)	mem 14543MB
[2023-10-10 18:18:03 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2599 (0.2524)	loss 0.3895 (0.3680)	grad_norm 471995.2500 (inf)	mem 14543MB
[2023-10-10 18:20:12 simmim_pretrain](main_simmim.py 218): INFO Train: [31/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2575 (0.2529)	loss 0.3712 (0.3678)	grad_norm 501597.9375 (inf)	mem 14543MB
[2023-10-10 18:21:27 simmim_pretrain](main_simmim.py 228): INFO EPOCH 31 training takes 0:28:38
[2023-10-10 18:21:29 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][0/6787]	eta 2:45:23 lr 0.000200	time 1.4621 (1.4621)	loss 0.3753 (0.3753)	grad_norm 374420.7812 (374420.7812)	mem 14543MB
[2023-10-10 18:23:35 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][500/6787]	eta 0:26:45 lr 0.000200	time 0.2468 (0.2554)	loss 0.3577 (0.3658)	grad_norm 540711.9375 (383967.7188)	mem 14543MB
[2023-10-10 18:25:41 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][1000/6787]	eta 0:24:29 lr 0.000200	time 0.2494 (0.2540)	loss 0.3798 (0.3660)	grad_norm 258010.8750 (inf)	mem 14543MB
[2023-10-10 18:27:48 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][1500/6787]	eta 0:22:22 lr 0.000200	time 0.2598 (0.2540)	loss 0.3689 (0.3662)	grad_norm 159268.8281 (inf)	mem 14543MB
[2023-10-10 18:29:58 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][2000/6787]	eta 0:20:20 lr 0.000200	time 0.2572 (0.2551)	loss 0.3899 (0.3666)	grad_norm 260919.7344 (inf)	mem 14543MB
[2023-10-10 18:32:06 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][2500/6787]	eta 0:18:15 lr 0.000200	time 0.2573 (0.2554)	loss 0.3765 (0.3669)	grad_norm 171259.2188 (inf)	mem 14543MB
[2023-10-10 18:34:15 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][3000/6787]	eta 0:16:08 lr 0.000200	time 0.2580 (0.2557)	loss 0.3593 (0.3666)	grad_norm 201563.5312 (inf)	mem 14543MB
[2023-10-10 18:36:23 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][3500/6787]	eta 0:14:01 lr 0.000200	time 0.2596 (0.2559)	loss 0.3660 (0.3665)	grad_norm 284134.8750 (inf)	mem 14543MB
[2023-10-10 18:38:32 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][4000/6787]	eta 0:11:53 lr 0.000200	time 0.2570 (0.2560)	loss 0.3641 (0.3666)	grad_norm 294874.4688 (inf)	mem 14543MB
[2023-10-10 18:40:40 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][4500/6787]	eta 0:09:45 lr 0.000200	time 0.2594 (0.2562)	loss 0.3833 (0.3666)	grad_norm 265753.1562 (inf)	mem 14543MB
[2023-10-10 18:42:49 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][5000/6787]	eta 0:07:37 lr 0.000200	time 0.2547 (0.2562)	loss 0.3934 (0.3666)	grad_norm 160660.1406 (inf)	mem 14543MB
[2023-10-10 18:44:57 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][5500/6787]	eta 0:05:29 lr 0.000200	time 0.2572 (0.2563)	loss 0.3668 (0.3666)	grad_norm 650383.4375 (inf)	mem 14543MB
[2023-10-10 18:47:06 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2571 (0.2564)	loss 0.3618 (0.3666)	grad_norm 218859.6562 (inf)	mem 14543MB
[2023-10-10 18:49:14 simmim_pretrain](main_simmim.py 218): INFO Train: [32/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2577 (0.2564)	loss 0.3807 (0.3666)	grad_norm 311430.9062 (inf)	mem 14543MB
[2023-10-10 18:50:28 simmim_pretrain](main_simmim.py 228): INFO EPOCH 32 training takes 0:29:01
[2023-10-10 18:50:30 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][0/6787]	eta 2:36:37 lr 0.000200	time 1.3846 (1.3846)	loss 0.3678 (0.3678)	grad_norm 293304.9375 (293304.9375)	mem 14543MB
[2023-10-10 18:52:36 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][500/6787]	eta 0:26:34 lr 0.000200	time 0.2477 (0.2536)	loss 0.3506 (0.3671)	grad_norm 188162.4375 (257625.1719)	mem 14543MB
[2023-10-10 18:54:42 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][1000/6787]	eta 0:24:23 lr 0.000200	time 0.2519 (0.2529)	loss 0.3647 (0.3667)	grad_norm 351517.0625 (262316.6875)	mem 14543MB
[2023-10-10 18:56:48 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][1500/6787]	eta 0:22:15 lr 0.000200	time 0.2507 (0.2526)	loss 0.3523 (0.3659)	grad_norm 408499.0938 (284289.0625)	mem 14543MB
[2023-10-10 18:58:54 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][2000/6787]	eta 0:20:08 lr 0.000200	time 0.2541 (0.2524)	loss 0.3555 (0.3660)	grad_norm 317959.3438 (inf)	mem 14543MB
[2023-10-10 19:01:00 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][2500/6787]	eta 0:18:01 lr 0.000200	time 0.2588 (0.2523)	loss 0.3766 (0.3663)	grad_norm 296599.7812 (inf)	mem 14543MB
[2023-10-10 19:03:06 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][3000/6787]	eta 0:15:55 lr 0.000200	time 0.2539 (0.2523)	loss 0.3786 (0.3665)	grad_norm 280083.1250 (inf)	mem 14543MB
[2023-10-10 19:05:12 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][3500/6787]	eta 0:13:49 lr 0.000200	time 0.2516 (0.2524)	loss 0.3966 (0.3665)	grad_norm 197832.0156 (inf)	mem 14543MB
[2023-10-10 19:07:18 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][4000/6787]	eta 0:11:43 lr 0.000200	time 0.2500 (0.2524)	loss 0.3745 (0.3666)	grad_norm 349727.8125 (inf)	mem 14543MB
[2023-10-10 19:09:24 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][4500/6787]	eta 0:09:37 lr 0.000200	time 0.2461 (0.2524)	loss 0.3581 (0.3665)	grad_norm 202528.2656 (inf)	mem 14543MB
[2023-10-10 19:11:30 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2526 (0.2523)	loss 0.3579 (0.3665)	grad_norm 267166.7188 (inf)	mem 14543MB
[2023-10-10 19:13:36 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2530 (0.2523)	loss 0.3607 (0.3666)	grad_norm 217122.0938 (inf)	mem 14543MB
[2023-10-10 19:15:43 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2483 (0.2523)	loss 0.3606 (0.3666)	grad_norm 111676.1406 (inf)	mem 14543MB
[2023-10-10 19:17:49 simmim_pretrain](main_simmim.py 218): INFO Train: [33/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2473 (0.2523)	loss 0.3408 (0.3666)	grad_norm 366012.4688 (inf)	mem 14543MB
[2023-10-10 19:19:02 simmim_pretrain](main_simmim.py 228): INFO EPOCH 33 training takes 0:28:33
[2023-10-10 19:19:03 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][0/6787]	eta 2:42:52 lr 0.000200	time 1.4399 (1.4399)	loss 0.3570 (0.3570)	grad_norm 304229.9062 (304229.9062)	mem 14543MB
[2023-10-10 19:21:09 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][500/6787]	eta 0:26:37 lr 0.000200	time 0.2470 (0.2541)	loss 0.3538 (0.3670)	grad_norm 203120.2344 (252354.2188)	mem 14543MB
[2023-10-10 19:23:16 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][1000/6787]	eta 0:24:30 lr 0.000200	time 0.2552 (0.2541)	loss 0.3746 (0.3667)	grad_norm 340257.7500 (254896.8750)	mem 14543MB
[2023-10-10 19:25:24 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][1500/6787]	eta 0:22:26 lr 0.000200	time 0.2552 (0.2547)	loss 0.3709 (0.3661)	grad_norm 376421.8438 (274746.2188)	mem 14543MB
[2023-10-10 19:27:32 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][2000/6787]	eta 0:20:21 lr 0.000200	time 0.2569 (0.2551)	loss 0.3675 (0.3658)	grad_norm 192640.7188 (299802.8750)	mem 14543MB
[2023-10-10 19:29:40 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][2500/6787]	eta 0:18:14 lr 0.000200	time 0.2553 (0.2554)	loss 0.3585 (0.3658)	grad_norm 400062.5000 (324304.0938)	mem 14543MB
[2023-10-10 19:31:49 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][3000/6787]	eta 0:16:07 lr 0.000200	time 0.2571 (0.2556)	loss 0.3634 (0.3656)	grad_norm 335525.5312 (inf)	mem 14543MB
[2023-10-10 19:33:57 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][3500/6787]	eta 0:14:00 lr 0.000200	time 0.2564 (0.2557)	loss 0.3775 (0.3656)	grad_norm 247021.4688 (inf)	mem 14543MB
[2023-10-10 19:36:05 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][4000/6787]	eta 0:11:52 lr 0.000200	time 0.2551 (0.2557)	loss 0.3628 (0.3657)	grad_norm 288159.8125 (inf)	mem 14543MB
[2023-10-10 19:38:13 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][4500/6787]	eta 0:09:45 lr 0.000200	time 0.2565 (0.2558)	loss 0.3805 (0.3658)	grad_norm 452970.0000 (inf)	mem 14543MB
[2023-10-10 19:40:21 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][5000/6787]	eta 0:07:36 lr 0.000200	time 0.2546 (0.2557)	loss 0.3581 (0.3660)	grad_norm 311581.0938 (inf)	mem 14543MB
[2023-10-10 19:42:27 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][5500/6787]	eta 0:05:28 lr 0.000200	time 0.2464 (0.2554)	loss 0.3735 (0.3661)	grad_norm 183112.2500 (inf)	mem 14543MB
[2023-10-10 19:44:32 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][6000/6787]	eta 0:03:20 lr 0.000200	time 0.2492 (0.2551)	loss 0.3578 (0.3661)	grad_norm 746149.3125 (inf)	mem 14543MB
[2023-10-10 19:46:38 simmim_pretrain](main_simmim.py 218): INFO Train: [34/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2530 (0.2548)	loss 0.3643 (0.3660)	grad_norm 397526.0000 (inf)	mem 14543MB
[2023-10-10 19:47:51 simmim_pretrain](main_simmim.py 228): INFO EPOCH 34 training takes 0:28:49
[2023-10-10 19:47:52 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][0/6787]	eta 2:27:51 lr 0.000200	time 1.3071 (1.3071)	loss 0.3896 (0.3896)	grad_norm 319609.0000 (319609.0000)	mem 14543MB
[2023-10-10 19:49:58 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][500/6787]	eta 0:26:37 lr 0.000200	time 0.2490 (0.2542)	loss 0.3565 (0.3664)	grad_norm 272074.5625 (inf)	mem 14543MB
[2023-10-10 19:52:05 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][1000/6787]	eta 0:24:24 lr 0.000200	time 0.2475 (0.2532)	loss 0.3687 (0.3664)	grad_norm 385989.0312 (inf)	mem 14543MB
[2023-10-10 19:54:10 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][1500/6787]	eta 0:22:16 lr 0.000200	time 0.2487 (0.2527)	loss 0.3684 (0.3666)	grad_norm 203559.9531 (inf)	mem 14543MB
[2023-10-10 19:56:16 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][2000/6787]	eta 0:20:08 lr 0.000200	time 0.2504 (0.2525)	loss 0.3785 (0.3672)	grad_norm 112302.0938 (inf)	mem 14543MB
[2023-10-10 19:58:22 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][2500/6787]	eta 0:18:01 lr 0.000200	time 0.2531 (0.2524)	loss 0.3476 (0.3675)	grad_norm 174679.9375 (inf)	mem 14543MB
[2023-10-10 20:00:28 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][3000/6787]	eta 0:15:55 lr 0.000200	time 0.2521 (0.2523)	loss 0.3589 (0.3677)	grad_norm 112545.1719 (inf)	mem 14543MB
[2023-10-10 20:02:35 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][3500/6787]	eta 0:13:50 lr 0.000200	time 0.2543 (0.2525)	loss 0.3740 (0.3676)	grad_norm 273287.6875 (inf)	mem 14543MB
[2023-10-10 20:04:43 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][4000/6787]	eta 0:11:44 lr 0.000200	time 0.2547 (0.2529)	loss 0.3826 (0.3676)	grad_norm 156023.8750 (inf)	mem 14543MB
[2023-10-10 20:06:49 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][4500/6787]	eta 0:09:38 lr 0.000200	time 0.2516 (0.2529)	loss 0.3852 (0.3674)	grad_norm 281602.5312 (inf)	mem 14543MB
[2023-10-10 20:08:55 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][5000/6787]	eta 0:07:31 lr 0.000200	time 0.2497 (0.2528)	loss 0.3557 (0.3673)	grad_norm 237661.0781 (inf)	mem 14543MB
[2023-10-10 20:11:03 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2606 (0.2530)	loss 0.3621 (0.3673)	grad_norm 337653.1875 (inf)	mem 14543MB
[2023-10-10 20:13:13 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2552 (0.2536)	loss 0.3739 (0.3672)	grad_norm 305393.1875 (inf)	mem 14543MB
[2023-10-10 20:15:23 simmim_pretrain](main_simmim.py 218): INFO Train: [35/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2607 (0.2541)	loss 0.3521 (0.3670)	grad_norm 284520.5312 (inf)	mem 14543MB
[2023-10-10 20:16:38 simmim_pretrain](main_simmim.py 228): INFO EPOCH 35 training takes 0:28:46
[2023-10-10 20:16:39 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][0/6787]	eta 2:40:34 lr 0.000200	time 1.4196 (1.4196)	loss 0.3630 (0.3630)	grad_norm 215011.3750 (215011.3750)	mem 14543MB
[2023-10-10 20:18:45 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][500/6787]	eta 0:26:34 lr 0.000200	time 0.2491 (0.2536)	loss 0.3545 (0.3661)	grad_norm 241011.5156 (inf)	mem 14543MB
[2023-10-10 20:20:51 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][1000/6787]	eta 0:24:22 lr 0.000200	time 0.2551 (0.2527)	loss 0.3205 (0.3655)	grad_norm 138857.3750 (inf)	mem 14543MB
[2023-10-10 20:22:57 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][1500/6787]	eta 0:22:16 lr 0.000200	time 0.2472 (0.2527)	loss 0.3753 (0.3659)	grad_norm 314728.5938 (inf)	mem 14543MB
[2023-10-10 20:25:04 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][2000/6787]	eta 0:20:09 lr 0.000200	time 0.2474 (0.2527)	loss 0.3612 (0.3660)	grad_norm 286663.6875 (inf)	mem 14543MB
[2023-10-10 20:27:11 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][2500/6787]	eta 0:18:05 lr 0.000200	time 0.2558 (0.2532)	loss 0.3782 (0.3661)	grad_norm 289186.4688 (inf)	mem 14543MB
[2023-10-10 20:29:19 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][3000/6787]	eta 0:16:00 lr 0.000200	time 0.2545 (0.2536)	loss 0.3788 (0.3662)	grad_norm 309308.5312 (inf)	mem 14543MB
[2023-10-10 20:31:26 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][3500/6787]	eta 0:13:53 lr 0.000200	time 0.2589 (0.2537)	loss 0.3573 (0.3663)	grad_norm 225424.7969 (inf)	mem 14543MB
[2023-10-10 20:33:34 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][4000/6787]	eta 0:11:47 lr 0.000200	time 0.2502 (0.2538)	loss 0.3606 (0.3662)	grad_norm 141248.1406 (inf)	mem 14543MB
[2023-10-10 20:35:41 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][4500/6787]	eta 0:09:40 lr 0.000200	time 0.2538 (0.2538)	loss 0.3410 (0.3661)	grad_norm 297924.9062 (inf)	mem 14543MB
[2023-10-10 20:37:47 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][5000/6787]	eta 0:07:33 lr 0.000200	time 0.2535 (0.2538)	loss 0.3575 (0.3660)	grad_norm 246211.4062 (inf)	mem 14543MB
[2023-10-10 20:39:54 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2536 (0.2538)	loss 0.3660 (0.3659)	grad_norm 340184.7812 (inf)	mem 14543MB
[2023-10-10 20:42:00 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2514 (0.2537)	loss 0.3714 (0.3660)	grad_norm 321946.5312 (inf)	mem 14543MB
[2023-10-10 20:44:06 simmim_pretrain](main_simmim.py 218): INFO Train: [36/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2518 (0.2536)	loss 0.3493 (0.3660)	grad_norm 235837.4688 (inf)	mem 14543MB
[2023-10-10 20:45:19 simmim_pretrain](main_simmim.py 228): INFO EPOCH 36 training takes 0:28:41
[2023-10-10 20:45:21 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][0/6787]	eta 2:26:49 lr 0.000200	time 1.2980 (1.2980)	loss 0.3625 (0.3625)	grad_norm 334360.1875 (334360.1875)	mem 14543MB
[2023-10-10 20:47:24 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][500/6787]	eta 0:26:10 lr 0.000200	time 0.2461 (0.2498)	loss 0.3499 (0.3651)	grad_norm 274292.8750 (293740.8125)	mem 14543MB
[2023-10-10 20:49:28 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][1000/6787]	eta 0:24:00 lr 0.000200	time 0.2491 (0.2489)	loss 0.3947 (0.3654)	grad_norm 603381.3750 (327743.5938)	mem 14543MB
[2023-10-10 20:51:32 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][1500/6787]	eta 0:21:54 lr 0.000200	time 0.2461 (0.2486)	loss 0.3687 (0.3651)	grad_norm 321693.0625 (402229.9062)	mem 14543MB
[2023-10-10 20:53:37 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][2000/6787]	eta 0:19:49 lr 0.000200	time 0.2478 (0.2485)	loss 0.3550 (0.3653)	grad_norm 385785.1875 (inf)	mem 14543MB
[2023-10-10 20:55:41 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][2500/6787]	eta 0:17:45 lr 0.000200	time 0.2461 (0.2485)	loss 0.3841 (0.3652)	grad_norm 198693.8906 (inf)	mem 14543MB
[2023-10-10 20:57:45 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][3000/6787]	eta 0:15:40 lr 0.000200	time 0.2455 (0.2485)	loss 0.3653 (0.3654)	grad_norm 251116.9375 (inf)	mem 14543MB
[2023-10-10 20:59:49 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][3500/6787]	eta 0:13:36 lr 0.000200	time 0.2531 (0.2484)	loss 0.3858 (0.3655)	grad_norm 269586.3438 (inf)	mem 14543MB
[2023-10-10 21:01:53 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][4000/6787]	eta 0:11:32 lr 0.000200	time 0.2461 (0.2483)	loss 0.3715 (0.3656)	grad_norm 498564.3750 (inf)	mem 14543MB
[2023-10-10 21:03:57 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][4500/6787]	eta 0:09:27 lr 0.000200	time 0.2569 (0.2483)	loss 0.3783 (0.3656)	grad_norm 189048.2500 (inf)	mem 14543MB
[2023-10-10 21:06:01 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][5000/6787]	eta 0:07:23 lr 0.000200	time 0.2458 (0.2483)	loss 0.3606 (0.3657)	grad_norm 152714.5312 (inf)	mem 14543MB
[2023-10-10 21:08:05 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][5500/6787]	eta 0:05:19 lr 0.000200	time 0.2464 (0.2483)	loss 0.3796 (0.3657)	grad_norm 240211.0469 (inf)	mem 14543MB
[2023-10-10 21:10:09 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][6000/6787]	eta 0:03:15 lr 0.000200	time 0.2494 (0.2482)	loss 0.3738 (0.3657)	grad_norm 311883.7188 (inf)	mem 14543MB
[2023-10-10 21:12:13 simmim_pretrain](main_simmim.py 218): INFO Train: [37/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2462 (0.2482)	loss 0.3732 (0.3656)	grad_norm 403084.1875 (inf)	mem 14543MB
[2023-10-10 21:13:25 simmim_pretrain](main_simmim.py 228): INFO EPOCH 37 training takes 0:28:05
[2023-10-10 21:13:26 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][0/6787]	eta 2:27:03 lr 0.000200	time 1.3001 (1.3001)	loss 0.3839 (0.3839)	grad_norm 450857.7500 (450857.7500)	mem 14543MB
[2023-10-10 21:15:30 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][500/6787]	eta 0:26:12 lr 0.000200	time 0.2457 (0.2501)	loss 0.3687 (0.3645)	grad_norm 208406.9688 (443340.9375)	mem 14543MB
[2023-10-10 21:17:34 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][1000/6787]	eta 0:24:01 lr 0.000200	time 0.2446 (0.2492)	loss 0.3754 (0.3651)	grad_norm 265558.0312 (inf)	mem 14543MB
[2023-10-10 21:19:38 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][1500/6787]	eta 0:21:55 lr 0.000200	time 0.2470 (0.2488)	loss 0.3650 (0.3652)	grad_norm 279909.9375 (inf)	mem 14543MB
[2023-10-10 21:21:42 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][2000/6787]	eta 0:19:50 lr 0.000200	time 0.2539 (0.2486)	loss 0.3613 (0.3653)	grad_norm 202835.1875 (inf)	mem 14543MB
[2023-10-10 21:23:46 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][2500/6787]	eta 0:17:45 lr 0.000200	time 0.2447 (0.2485)	loss 0.3575 (0.3654)	grad_norm 235722.7188 (inf)	mem 14543MB
[2023-10-10 21:25:50 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][3000/6787]	eta 0:15:40 lr 0.000200	time 0.2490 (0.2484)	loss 0.3805 (0.3654)	grad_norm 307796.7812 (inf)	mem 14543MB
[2023-10-10 21:27:54 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][3500/6787]	eta 0:13:36 lr 0.000200	time 0.2456 (0.2483)	loss 0.3769 (0.3652)	grad_norm 564839.4375 (inf)	mem 14543MB
[2023-10-10 21:29:58 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][4000/6787]	eta 0:11:31 lr 0.000200	time 0.2486 (0.2482)	loss 0.3585 (0.3651)	grad_norm 532107.1250 (inf)	mem 14543MB
[2023-10-10 21:32:02 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][4500/6787]	eta 0:09:27 lr 0.000200	time 0.2483 (0.2482)	loss 0.3684 (0.3650)	grad_norm 534331.6250 (inf)	mem 14543MB
[2023-10-10 21:34:06 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][5000/6787]	eta 0:07:23 lr 0.000200	time 0.2515 (0.2482)	loss 0.3707 (0.3651)	grad_norm 435952.1562 (inf)	mem 14543MB
[2023-10-10 21:36:10 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][5500/6787]	eta 0:05:19 lr 0.000200	time 0.2495 (0.2482)	loss 0.3884 (0.3651)	grad_norm 253426.7812 (inf)	mem 14543MB
[2023-10-10 21:38:14 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][6000/6787]	eta 0:03:15 lr 0.000200	time 0.2473 (0.2482)	loss 0.3581 (0.3652)	grad_norm 226109.5469 (inf)	mem 14543MB
[2023-10-10 21:40:18 simmim_pretrain](main_simmim.py 218): INFO Train: [38/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2467 (0.2482)	loss 0.3604 (0.3653)	grad_norm 631440.5000 (inf)	mem 14543MB
[2023-10-10 21:41:30 simmim_pretrain](main_simmim.py 228): INFO EPOCH 38 training takes 0:28:05
[2023-10-10 21:41:32 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][0/6787]	eta 2:36:16 lr 0.000200	time 1.3816 (1.3816)	loss 0.3679 (0.3679)	grad_norm 706728.5625 (706728.5625)	mem 14543MB
[2023-10-10 21:43:36 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][500/6787]	eta 0:26:13 lr 0.000200	time 0.2490 (0.2503)	loss 0.4073 (0.3653)	grad_norm 350115.0312 (398354.1875)	mem 14543MB
[2023-10-10 21:45:40 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][1000/6787]	eta 0:24:02 lr 0.000200	time 0.2507 (0.2493)	loss 0.3873 (0.3652)	grad_norm 270967.1875 (414624.0625)	mem 14543MB
[2023-10-10 21:47:44 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][1500/6787]	eta 0:21:56 lr 0.000200	time 0.2464 (0.2490)	loss 0.3938 (0.3650)	grad_norm 643002.1875 (443122.7500)	mem 14543MB
[2023-10-10 21:49:48 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][2000/6787]	eta 0:19:50 lr 0.000200	time 0.2453 (0.2488)	loss 0.4011 (0.3903)	grad_norm 41909.7773 (inf)	mem 14543MB
[2023-10-10 21:51:52 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][2500/6787]	eta 0:17:46 lr 0.000200	time 0.2504 (0.2487)	loss 0.4061 (0.3891)	grad_norm 35817.0938 (inf)	mem 14543MB
[2023-10-10 21:53:56 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][3000/6787]	eta 0:15:41 lr 0.000200	time 0.2506 (0.2487)	loss 0.3861 (0.3866)	grad_norm 29815.2129 (inf)	mem 14543MB
[2023-10-10 21:56:01 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][3500/6787]	eta 0:13:37 lr 0.000200	time 0.2464 (0.2486)	loss 0.3990 (0.3845)	grad_norm 34887.1523 (inf)	mem 14543MB
[2023-10-10 21:58:05 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][4000/6787]	eta 0:11:32 lr 0.000200	time 0.2461 (0.2486)	loss 0.3736 (0.3826)	grad_norm 44092.2148 (inf)	mem 14543MB
[2023-10-10 22:00:09 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][4500/6787]	eta 0:09:28 lr 0.000200	time 0.2479 (0.2486)	loss 0.3700 (0.3811)	grad_norm 100508.8438 (inf)	mem 14543MB
[2023-10-10 22:02:13 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][5000/6787]	eta 0:07:24 lr 0.000200	time 0.2494 (0.2485)	loss 0.3529 (0.3799)	grad_norm 71744.2188 (inf)	mem 14543MB
[2023-10-10 22:04:17 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][5500/6787]	eta 0:05:19 lr 0.000200	time 0.2467 (0.2485)	loss 0.4027 (0.3788)	grad_norm 78603.0625 (inf)	mem 14543MB
[2023-10-10 22:06:22 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][6000/6787]	eta 0:03:15 lr 0.000200	time 0.2452 (0.2485)	loss 0.3646 (0.3778)	grad_norm 118329.6953 (inf)	mem 14543MB
[2023-10-10 22:08:26 simmim_pretrain](main_simmim.py 218): INFO Train: [39/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2496 (0.2485)	loss 0.3442 (0.3769)	grad_norm 115296.9219 (inf)	mem 14543MB
[2023-10-10 22:09:37 simmim_pretrain](main_simmim.py 228): INFO EPOCH 39 training takes 0:28:07
[2023-10-10 22:09:39 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][0/6787]	eta 2:33:26 lr 0.000200	time 1.3565 (1.3565)	loss 0.3461 (0.3461)	grad_norm 119867.4453 (119867.4453)	mem 14543MB
[2023-10-10 22:11:43 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][500/6787]	eta 0:26:13 lr 0.000200	time 0.2498 (0.2503)	loss 0.3801 (0.3651)	grad_norm 93892.8125 (92858.3359)	mem 14543MB
[2023-10-10 22:13:47 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][1000/6787]	eta 0:24:02 lr 0.000200	time 0.2456 (0.2492)	loss 0.3660 (0.3657)	grad_norm 83616.7109 (104966.8594)	mem 14543MB
[2023-10-10 22:15:51 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][1500/6787]	eta 0:21:55 lr 0.000200	time 0.2535 (0.2488)	loss 0.3530 (0.3654)	grad_norm 86830.6875 (122288.4844)	mem 14543MB
[2023-10-10 22:17:55 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][2000/6787]	eta 0:19:50 lr 0.000200	time 0.2460 (0.2487)	loss 0.3633 (0.3653)	grad_norm 252444.9375 (134365.3750)	mem 14543MB
[2023-10-10 22:19:59 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][2500/6787]	eta 0:17:45 lr 0.000200	time 0.2468 (0.2486)	loss 0.3802 (0.3653)	grad_norm 129132.5625 (146398.0625)	mem 14543MB
[2023-10-10 22:22:03 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][3000/6787]	eta 0:15:41 lr 0.000200	time 0.2509 (0.2485)	loss 0.3658 (0.3652)	grad_norm 243458.6875 (156810.0781)	mem 14543MB
[2023-10-10 22:24:07 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][3500/6787]	eta 0:13:36 lr 0.000200	time 0.2470 (0.2484)	loss 0.3649 (0.3651)	grad_norm 162436.7656 (181904.1094)	mem 14543MB
[2023-10-10 22:26:11 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][4000/6787]	eta 0:11:32 lr 0.000200	time 0.2473 (0.2483)	loss 0.3626 (0.3649)	grad_norm 283710.0312 (194689.8906)	mem 14543MB
[2023-10-10 22:28:15 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][4500/6787]	eta 0:09:27 lr 0.000200	time 0.2489 (0.2483)	loss 0.3599 (0.3648)	grad_norm 224440.3594 (219000.1719)	mem 14543MB
[2023-10-10 22:30:19 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][5000/6787]	eta 0:07:23 lr 0.000200	time 0.2485 (0.2483)	loss 0.3666 (0.3647)	grad_norm 160116.5156 (inf)	mem 14543MB
[2023-10-10 22:32:23 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][5500/6787]	eta 0:05:19 lr 0.000200	time 0.2471 (0.2483)	loss 0.3772 (0.3647)	grad_norm 87426.3594 (inf)	mem 14543MB
[2023-10-10 22:34:27 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][6000/6787]	eta 0:03:15 lr 0.000200	time 0.2485 (0.2483)	loss 0.3623 (0.3647)	grad_norm 110052.3672 (inf)	mem 14543MB
[2023-10-10 22:36:32 simmim_pretrain](main_simmim.py 218): INFO Train: [40/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2465 (0.2483)	loss 0.3623 (0.3647)	grad_norm 254506.9219 (inf)	mem 14543MB
[2023-10-10 22:37:44 simmim_pretrain](main_simmim.py 228): INFO EPOCH 40 training takes 0:28:06
[2023-10-10 22:37:44 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_40.pth saving......
[2023-10-10 22:37:44 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_40.pth saved !!!
[2023-10-10 22:37:46 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][0/6787]	eta 2:31:36 lr 0.000200	time 1.3403 (1.3403)	loss 0.3592 (0.3592)	grad_norm 335095.7500 (335095.7500)	mem 14543MB
[2023-10-10 22:39:50 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][500/6787]	eta 0:26:12 lr 0.000200	time 0.2459 (0.2502)	loss 0.3690 (0.3645)	grad_norm 261329.5156 (292073.2812)	mem 14543MB
[2023-10-10 22:41:54 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][1000/6787]	eta 0:24:03 lr 0.000200	time 0.2466 (0.2494)	loss 0.3745 (0.3642)	grad_norm 457198.6875 (310417.1875)	mem 14543MB
[2023-10-10 22:43:58 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][1500/6787]	eta 0:21:56 lr 0.000200	time 0.2476 (0.2490)	loss 0.3607 (0.3638)	grad_norm 236496.8594 (361824.3438)	mem 14543MB
[2023-10-10 22:46:02 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][2000/6787]	eta 0:19:51 lr 0.000200	time 0.2517 (0.2489)	loss 0.3647 (0.3639)	grad_norm 450821.4688 (inf)	mem 14543MB
[2023-10-10 22:48:06 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][2500/6787]	eta 0:17:46 lr 0.000200	time 0.2515 (0.2488)	loss 0.3587 (0.3637)	grad_norm 173073.8750 (inf)	mem 14543MB
[2023-10-10 22:50:11 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][3000/6787]	eta 0:15:41 lr 0.000200	time 0.2472 (0.2487)	loss 0.3792 (0.3637)	grad_norm 447053.1250 (inf)	mem 14543MB
[2023-10-10 22:52:15 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][3500/6787]	eta 0:13:37 lr 0.000200	time 0.2475 (0.2487)	loss 0.3682 (0.3640)	grad_norm 194206.7031 (inf)	mem 14543MB
[2023-10-10 22:54:19 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][4000/6787]	eta 0:11:33 lr 0.000200	time 0.2503 (0.2487)	loss 0.3821 (0.3642)	grad_norm 220258.4531 (inf)	mem 14543MB
[2023-10-10 22:56:23 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][4500/6787]	eta 0:09:28 lr 0.000200	time 0.2464 (0.2486)	loss 0.3655 (0.3643)	grad_norm 280326.7500 (inf)	mem 14543MB
[2023-10-10 22:58:28 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][5000/6787]	eta 0:07:24 lr 0.000200	time 0.2526 (0.2486)	loss 0.3416 (0.3643)	grad_norm 149814.2031 (inf)	mem 14543MB
[2023-10-10 23:00:32 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][5500/6787]	eta 0:05:19 lr 0.000200	time 0.2469 (0.2486)	loss 0.3415 (0.3644)	grad_norm 160095.1875 (inf)	mem 14543MB
[2023-10-10 23:02:36 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][6000/6787]	eta 0:03:15 lr 0.000200	time 0.2446 (0.2486)	loss 0.3627 (0.3643)	grad_norm 310503.7188 (inf)	mem 14543MB
[2023-10-10 23:04:40 simmim_pretrain](main_simmim.py 218): INFO Train: [41/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2496 (0.2486)	loss 0.3556 (0.3642)	grad_norm 791738.8750 (inf)	mem 14543MB
[2023-10-10 23:05:52 simmim_pretrain](main_simmim.py 228): INFO EPOCH 41 training takes 0:28:07
[2023-10-10 23:05:53 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][0/6787]	eta 2:32:37 lr 0.000200	time 1.3493 (1.3493)	loss 0.3763 (0.3763)	grad_norm 356450.0312 (356450.0312)	mem 14543MB
[2023-10-10 23:07:57 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][500/6787]	eta 0:26:11 lr 0.000200	time 0.2583 (0.2500)	loss 0.3892 (0.3627)	grad_norm 429443.6562 (inf)	mem 14543MB
[2023-10-10 23:10:01 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][1000/6787]	eta 0:24:00 lr 0.000200	time 0.2465 (0.2489)	loss 0.3640 (0.3629)	grad_norm 678288.6250 (inf)	mem 14543MB
[2023-10-10 23:12:05 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][1500/6787]	eta 0:21:54 lr 0.000200	time 0.2488 (0.2486)	loss 0.3653 (0.3633)	grad_norm 333081.0312 (inf)	mem 14543MB
[2023-10-10 23:14:09 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][2000/6787]	eta 0:19:48 lr 0.000200	time 0.2463 (0.2483)	loss 0.3777 (0.3634)	grad_norm 360545.2500 (inf)	mem 14543MB
[2023-10-10 23:16:13 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][2500/6787]	eta 0:17:44 lr 0.000200	time 0.2475 (0.2482)	loss 0.3528 (0.3634)	grad_norm 552183.4375 (inf)	mem 14543MB
[2023-10-10 23:18:16 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][3000/6787]	eta 0:15:39 lr 0.000200	time 0.2463 (0.2481)	loss 0.3798 (0.3634)	grad_norm 300832.6875 (inf)	mem 14543MB
[2023-10-10 23:20:20 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][3500/6787]	eta 0:13:35 lr 0.000200	time 0.2454 (0.2480)	loss 0.3712 (0.3635)	grad_norm 233827.8594 (inf)	mem 14543MB
[2023-10-10 23:22:24 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][4000/6787]	eta 0:11:31 lr 0.000200	time 0.2486 (0.2480)	loss 0.3717 (0.3636)	grad_norm 394343.6875 (inf)	mem 14543MB
[2023-10-10 23:24:28 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][4500/6787]	eta 0:09:27 lr 0.000200	time 0.2584 (0.2479)	loss 0.3503 (0.3637)	grad_norm 317775.4688 (inf)	mem 14543MB
[2023-10-10 23:26:32 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][5000/6787]	eta 0:07:23 lr 0.000200	time 0.2459 (0.2479)	loss 0.3850 (0.3638)	grad_norm 239926.7656 (inf)	mem 14543MB
[2023-10-10 23:28:36 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][5500/6787]	eta 0:05:19 lr 0.000200	time 0.2522 (0.2479)	loss 0.3518 (0.3638)	grad_norm 160476.3125 (inf)	mem 14543MB
[2023-10-10 23:30:40 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][6000/6787]	eta 0:03:15 lr 0.000200	time 0.2462 (0.2479)	loss 0.3756 (0.3638)	grad_norm 210586.4531 (inf)	mem 14543MB
[2023-10-10 23:32:44 simmim_pretrain](main_simmim.py 218): INFO Train: [42/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2484 (0.2479)	loss 0.3865 (0.3638)	grad_norm 663934.7500 (inf)	mem 14543MB
[2023-10-10 23:33:55 simmim_pretrain](main_simmim.py 228): INFO EPOCH 42 training takes 0:28:03
[2023-10-10 23:33:57 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][0/6787]	eta 2:17:25 lr 0.000200	time 1.2148 (1.2148)	loss 0.3362 (0.3362)	grad_norm 664057.2500 (664057.2500)	mem 14543MB
[2023-10-10 23:36:01 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][500/6787]	eta 0:26:11 lr 0.000200	time 0.2461 (0.2500)	loss 0.3644 (0.3627)	grad_norm 370556.8750 (inf)	mem 14543MB
[2023-10-10 23:38:05 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][1000/6787]	eta 0:24:01 lr 0.000200	time 0.2528 (0.2491)	loss 0.3590 (0.3631)	grad_norm 758542.1250 (inf)	mem 14543MB
[2023-10-10 23:40:09 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][1500/6787]	eta 0:21:55 lr 0.000200	time 0.2461 (0.2488)	loss 0.3608 (0.3637)	grad_norm 274564.7812 (inf)	mem 14543MB
[2023-10-10 23:42:13 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][2000/6787]	eta 0:19:50 lr 0.000200	time 0.2473 (0.2487)	loss 0.3464 (0.3639)	grad_norm 267989.1250 (inf)	mem 14543MB
[2023-10-10 23:44:17 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][2500/6787]	eta 0:17:45 lr 0.000200	time 0.2460 (0.2486)	loss 0.3591 (0.3643)	grad_norm 283347.2188 (inf)	mem 14543MB
[2023-10-10 23:46:21 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][3000/6787]	eta 0:15:41 lr 0.000200	time 0.2521 (0.2486)	loss 0.3408 (0.3643)	grad_norm 279111.9688 (inf)	mem 14543MB
[2023-10-10 23:48:25 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][3500/6787]	eta 0:13:36 lr 0.000200	time 0.2460 (0.2485)	loss 0.3596 (0.3643)	grad_norm 640211.0625 (inf)	mem 14543MB
[2023-10-10 23:50:30 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][4000/6787]	eta 0:11:32 lr 0.000200	time 0.2504 (0.2485)	loss 0.3527 (0.3642)	grad_norm 488216.4688 (inf)	mem 14543MB
[2023-10-10 23:52:34 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][4500/6787]	eta 0:09:28 lr 0.000200	time 0.2482 (0.2485)	loss 0.3690 (0.3639)	grad_norm 217386.0469 (inf)	mem 14543MB
[2023-10-10 23:54:38 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][5000/6787]	eta 0:07:24 lr 0.000200	time 0.2494 (0.2485)	loss 0.3559 (0.3640)	grad_norm 340602.0625 (inf)	mem 14543MB
[2023-10-10 23:56:42 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][5500/6787]	eta 0:05:19 lr 0.000200	time 0.2445 (0.2485)	loss 0.3807 (0.3639)	grad_norm 232049.5000 (inf)	mem 14543MB
[2023-10-10 23:58:46 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][6000/6787]	eta 0:03:15 lr 0.000200	time 0.2447 (0.2485)	loss 0.3534 (0.3639)	grad_norm 516933.0312 (inf)	mem 14543MB
[2023-10-11 00:00:51 simmim_pretrain](main_simmim.py 218): INFO Train: [43/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2486 (0.2484)	loss 0.3595 (0.3639)	grad_norm 367178.9062 (inf)	mem 14543MB
[2023-10-11 00:02:02 simmim_pretrain](main_simmim.py 228): INFO EPOCH 43 training takes 0:28:06
[2023-10-11 00:02:04 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][0/6787]	eta 2:32:22 lr 0.000200	time 1.3471 (1.3471)	loss 0.3786 (0.3786)	grad_norm 544773.5625 (544773.5625)	mem 14543MB
[2023-10-11 00:04:07 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][500/6787]	eta 0:26:10 lr 0.000200	time 0.2483 (0.2498)	loss 0.3803 (0.3625)	grad_norm 584269.8125 (inf)	mem 14543MB
[2023-10-11 00:06:11 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][1000/6787]	eta 0:24:00 lr 0.000200	time 0.2501 (0.2489)	loss 0.3747 (0.3633)	grad_norm 776864.4375 (inf)	mem 14543MB
[2023-10-11 00:08:15 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][1500/6787]	eta 0:21:54 lr 0.000200	time 0.2456 (0.2486)	loss 0.3549 (0.3631)	grad_norm 564549.8125 (inf)	mem 14543MB
[2023-10-11 00:10:19 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][2000/6787]	eta 0:19:49 lr 0.000200	time 0.2467 (0.2484)	loss 0.3726 (0.3633)	grad_norm 294429.7500 (inf)	mem 14543MB
[2023-10-11 00:12:23 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][2500/6787]	eta 0:17:44 lr 0.000200	time 0.2458 (0.2483)	loss 0.3813 (0.3635)	grad_norm 451391.1875 (inf)	mem 14543MB
[2023-10-11 00:14:27 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][3000/6787]	eta 0:15:40 lr 0.000200	time 0.2465 (0.2483)	loss 0.3803 (0.3638)	grad_norm 440069.8750 (inf)	mem 14543MB
[2023-10-11 00:16:31 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][3500/6787]	eta 0:13:35 lr 0.000200	time 0.2465 (0.2482)	loss 0.3627 (0.3639)	grad_norm 181651.0938 (inf)	mem 14543MB
[2023-10-11 00:18:35 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][4000/6787]	eta 0:11:31 lr 0.000200	time 0.2459 (0.2482)	loss 0.3704 (0.3641)	grad_norm 510534.1875 (inf)	mem 14543MB
[2023-10-11 00:20:39 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][4500/6787]	eta 0:09:27 lr 0.000200	time 0.2484 (0.2482)	loss 0.3561 (0.3640)	grad_norm 203330.4219 (inf)	mem 14543MB
[2023-10-11 00:22:43 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][5000/6787]	eta 0:07:23 lr 0.000200	time 0.2472 (0.2481)	loss 0.3775 (0.3640)	grad_norm 382957.3750 (inf)	mem 14543MB
[2023-10-11 00:24:47 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][5500/6787]	eta 0:05:19 lr 0.000200	time 0.2517 (0.2481)	loss 0.3520 (0.3641)	grad_norm 276487.5312 (inf)	mem 14543MB
[2023-10-11 00:26:51 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][6000/6787]	eta 0:03:15 lr 0.000200	time 0.2484 (0.2481)	loss 0.3767 (0.3642)	grad_norm 248337.1406 (inf)	mem 14543MB
[2023-10-11 00:28:55 simmim_pretrain](main_simmim.py 218): INFO Train: [44/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2452 (0.2481)	loss 0.3934 (0.3642)	grad_norm 320632.6562 (inf)	mem 14543MB
[2023-10-11 00:30:07 simmim_pretrain](main_simmim.py 228): INFO EPOCH 44 training takes 0:28:04
[2023-10-11 00:30:08 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][0/6787]	eta 2:57:11 lr 0.000200	time 1.5664 (1.5664)	loss 0.3878 (0.3878)	grad_norm 163496.7344 (163496.7344)	mem 14543MB
[2023-10-11 00:32:13 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][500/6787]	eta 0:26:18 lr 0.000200	time 0.2454 (0.2510)	loss 0.3620 (0.3642)	grad_norm 379163.0625 (387397.6250)	mem 14543MB
[2023-10-11 00:34:17 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][1000/6787]	eta 0:24:07 lr 0.000200	time 0.2478 (0.2502)	loss 0.3446 (0.3633)	grad_norm 1049138.6250 (387211.0312)	mem 14543MB
[2023-10-11 00:36:22 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][1500/6787]	eta 0:22:01 lr 0.000200	time 0.2451 (0.2500)	loss 0.3507 (0.3638)	grad_norm 250728.8125 (inf)	mem 14543MB
[2023-10-11 00:38:27 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][2000/6787]	eta 0:19:55 lr 0.000200	time 0.2516 (0.2498)	loss 0.3703 (0.3640)	grad_norm 176143.6406 (inf)	mem 14543MB
[2023-10-11 00:40:32 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][2500/6787]	eta 0:17:50 lr 0.000200	time 0.2489 (0.2498)	loss 0.3568 (0.3643)	grad_norm 308656.3125 (inf)	mem 14543MB
[2023-10-11 00:42:36 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][3000/6787]	eta 0:15:45 lr 0.000200	time 0.2470 (0.2498)	loss 0.3668 (0.3644)	grad_norm 361113.4062 (inf)	mem 14543MB
[2023-10-11 00:44:41 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2505 (0.2498)	loss 0.3555 (0.3645)	grad_norm 256804.1250 (inf)	mem 14543MB
[2023-10-11 00:46:47 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2594 (0.2499)	loss 0.3612 (0.3645)	grad_norm 216762.2500 (inf)	mem 14543MB
[2023-10-11 00:48:52 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2455 (0.2499)	loss 0.3551 (0.3645)	grad_norm 350893.2500 (inf)	mem 14543MB
[2023-10-11 00:50:56 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2585 (0.2499)	loss 0.3717 (0.3645)	grad_norm 427980.7500 (inf)	mem 14543MB
[2023-10-11 00:53:01 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2516 (0.2498)	loss 0.3373 (0.3645)	grad_norm 338574.9375 (inf)	mem 14543MB
[2023-10-11 00:55:06 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2522 (0.2499)	loss 0.3605 (0.3643)	grad_norm 401816.5938 (inf)	mem 14543MB
[2023-10-11 00:57:11 simmim_pretrain](main_simmim.py 218): INFO Train: [45/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2586 (0.2499)	loss 0.3600 (0.3643)	grad_norm 627936.7500 (inf)	mem 14543MB
[2023-10-11 00:58:23 simmim_pretrain](main_simmim.py 228): INFO EPOCH 45 training takes 0:28:16
[2023-10-11 00:58:25 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][0/6787]	eta 2:41:29 lr 0.000200	time 1.4277 (1.4277)	loss 0.3555 (0.3555)	grad_norm 489117.3125 (489117.3125)	mem 14543MB
[2023-10-11 01:00:30 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2555 (0.2529)	loss 0.3367 (0.3634)	grad_norm 723940.0625 (inf)	mem 14543MB
[2023-10-11 01:02:36 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][1000/6787]	eta 0:24:20 lr 0.000200	time 0.2505 (0.2523)	loss 0.3571 (0.3634)	grad_norm 697757.7500 (inf)	mem 14543MB
[2023-10-11 01:04:42 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][1500/6787]	eta 0:22:13 lr 0.000200	time 0.2523 (0.2522)	loss 0.3778 (0.3630)	grad_norm 548565.5000 (inf)	mem 14543MB
[2023-10-11 01:06:48 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][2000/6787]	eta 0:20:06 lr 0.000200	time 0.2525 (0.2521)	loss 0.3641 (0.3631)	grad_norm 478167.4062 (inf)	mem 14543MB
[2023-10-11 01:08:54 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][2500/6787]	eta 0:18:00 lr 0.000200	time 0.2524 (0.2520)	loss 0.3573 (0.3627)	grad_norm 481278.5938 (inf)	mem 14543MB
[2023-10-11 01:11:00 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][3000/6787]	eta 0:15:54 lr 0.000200	time 0.2554 (0.2520)	loss 0.3284 (0.3628)	grad_norm 598187.1250 (inf)	mem 14543MB
[2023-10-11 01:13:06 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][3500/6787]	eta 0:13:48 lr 0.000200	time 0.2514 (0.2519)	loss 0.3649 (0.3627)	grad_norm 466964.3125 (inf)	mem 14543MB
[2023-10-11 01:15:11 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2506 (0.2519)	loss 0.3532 (0.3629)	grad_norm 341306.7812 (inf)	mem 14543MB
[2023-10-11 01:17:17 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2500 (0.2518)	loss 0.5133 (0.3670)	grad_norm 8192.9541 (inf)	mem 14543MB
[2023-10-11 01:19:23 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2492 (0.2518)	loss 0.3916 (0.3736)	grad_norm 35077.4961 (inf)	mem 14543MB
[2023-10-11 01:21:28 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2439 (0.2517)	loss 0.3743 (0.3739)	grad_norm 31794.4277 (inf)	mem 14543MB
[2023-10-11 01:23:34 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2500 (0.2517)	loss 0.3786 (0.3737)	grad_norm 40885.3125 (inf)	mem 14543MB
[2023-10-11 01:25:39 simmim_pretrain](main_simmim.py 218): INFO Train: [46/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2510 (0.2516)	loss 0.3573 (0.3736)	grad_norm 29708.0996 (inf)	mem 14543MB
[2023-10-11 01:26:52 simmim_pretrain](main_simmim.py 228): INFO EPOCH 46 training takes 0:28:28
[2023-10-11 01:26:53 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][0/6787]	eta 2:56:28 lr 0.000200	time 1.5602 (1.5602)	loss 0.3808 (0.3808)	grad_norm 27461.1562 (27461.1562)	mem 14543MB
[2023-10-11 01:28:58 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][500/6787]	eta 0:26:22 lr 0.000200	time 0.2512 (0.2517)	loss 0.3734 (0.3680)	grad_norm 69219.5391 (48537.2734)	mem 14543MB
[2023-10-11 01:31:03 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][1000/6787]	eta 0:24:10 lr 0.000200	time 0.2467 (0.2507)	loss 0.3630 (0.3677)	grad_norm 50439.2930 (50515.4961)	mem 14543MB
[2023-10-11 01:33:08 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][1500/6787]	eta 0:22:03 lr 0.000200	time 0.2496 (0.2503)	loss 0.3663 (0.3677)	grad_norm 78190.7188 (51518.5156)	mem 14543MB
[2023-10-11 01:35:12 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][2000/6787]	eta 0:19:57 lr 0.000200	time 0.2471 (0.2501)	loss 0.3632 (0.3675)	grad_norm 59504.5820 (55988.7344)	mem 14543MB
[2023-10-11 01:37:17 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2480 (0.2501)	loss 0.3664 (0.3670)	grad_norm 82650.3438 (62042.2109)	mem 14543MB
[2023-10-11 01:39:22 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2589 (0.2500)	loss 0.3406 (0.3667)	grad_norm 113726.7969 (71312.3906)	mem 14543MB
[2023-10-11 01:41:27 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2461 (0.2500)	loss 0.3812 (0.3665)	grad_norm 113979.7656 (75201.1094)	mem 14543MB
[2023-10-11 01:43:32 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2463 (0.2500)	loss 0.3696 (0.3662)	grad_norm 273631.8750 (85130.3906)	mem 14543MB
[2023-10-11 01:45:37 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2534 (0.2500)	loss 0.3499 (0.3660)	grad_norm 114111.0938 (94094.6016)	mem 14543MB
[2023-10-11 01:47:42 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2548 (0.2500)	loss 0.3617 (0.3658)	grad_norm 345186.6562 (102983.7734)	mem 14543MB
[2023-10-11 01:49:47 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2465 (0.2499)	loss 0.3850 (0.3657)	grad_norm 280478.8125 (111281.3984)	mem 14543MB
[2023-10-11 01:51:52 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2547 (0.2499)	loss 0.3660 (0.3654)	grad_norm 279369.4688 (122865.2031)	mem 14543MB
[2023-10-11 01:53:56 simmim_pretrain](main_simmim.py 218): INFO Train: [47/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2494 (0.2499)	loss 0.3787 (0.3652)	grad_norm 465164.7812 (144529.6719)	mem 14543MB
[2023-10-11 01:55:09 simmim_pretrain](main_simmim.py 228): INFO EPOCH 47 training takes 0:28:16
[2023-10-11 01:55:10 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][0/6787]	eta 2:55:42 lr 0.000200	time 1.5534 (1.5534)	loss 0.3367 (0.3367)	grad_norm 270580.6875 (270580.6875)	mem 14543MB
[2023-10-11 01:57:15 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][500/6787]	eta 0:26:24 lr 0.000200	time 0.2488 (0.2520)	loss 0.3529 (0.3638)	grad_norm 119517.2656 (233062.7812)	mem 14543MB
[2023-10-11 01:59:20 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2472 (0.2507)	loss 0.3352 (0.3642)	grad_norm 247407.5938 (225968.4844)	mem 14543MB
[2023-10-11 02:01:24 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][1500/6787]	eta 0:22:03 lr 0.000200	time 0.2517 (0.2504)	loss 0.3599 (0.3641)	grad_norm 218541.5938 (223707.5938)	mem 14543MB
[2023-10-11 02:03:29 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][2000/6787]	eta 0:19:57 lr 0.000200	time 0.2473 (0.2501)	loss 0.3621 (0.3640)	grad_norm 179888.3750 (225409.7344)	mem 14543MB
[2023-10-11 02:05:34 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][2500/6787]	eta 0:17:51 lr 0.000200	time 0.2461 (0.2499)	loss 0.3708 (0.3637)	grad_norm 216551.4531 (245487.7969)	mem 14543MB
[2023-10-11 02:07:39 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2525 (0.2499)	loss 0.3801 (0.3637)	grad_norm 178786.7500 (inf)	mem 14543MB
[2023-10-11 02:09:43 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2508 (0.2498)	loss 0.3703 (0.3636)	grad_norm 157914.2812 (inf)	mem 14543MB
[2023-10-11 02:11:48 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2535 (0.2498)	loss 0.3606 (0.3637)	grad_norm 310359.0938 (inf)	mem 14543MB
[2023-10-11 02:13:53 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2473 (0.2497)	loss 0.3440 (0.3637)	grad_norm 220890.3125 (inf)	mem 14543MB
[2023-10-11 02:15:57 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2489 (0.2497)	loss 0.3589 (0.3637)	grad_norm 276843.0625 (inf)	mem 14543MB
[2023-10-11 02:18:02 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2513 (0.2497)	loss 0.3608 (0.3636)	grad_norm 451188.0000 (inf)	mem 14543MB
[2023-10-11 02:20:07 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2519 (0.2497)	loss 0.3770 (0.3635)	grad_norm 232435.2344 (inf)	mem 14543MB
[2023-10-11 02:22:12 simmim_pretrain](main_simmim.py 218): INFO Train: [48/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2554 (0.2497)	loss 0.3626 (0.3636)	grad_norm 345978.5312 (inf)	mem 14543MB
[2023-10-11 02:23:24 simmim_pretrain](main_simmim.py 228): INFO EPOCH 48 training takes 0:28:15
[2023-10-11 02:23:25 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][0/6787]	eta 2:57:03 lr 0.000200	time 1.5652 (1.5652)	loss 0.3558 (0.3558)	grad_norm 467449.9375 (467449.9375)	mem 14543MB
[2023-10-11 02:25:30 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][500/6787]	eta 0:26:22 lr 0.000200	time 0.2486 (0.2518)	loss 0.3571 (0.3626)	grad_norm 97589.9141 (inf)	mem 14543MB
[2023-10-11 02:27:35 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][1000/6787]	eta 0:24:10 lr 0.000200	time 0.2478 (0.2507)	loss 0.3597 (0.3634)	grad_norm 234085.4688 (inf)	mem 14543MB
[2023-10-11 02:29:40 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][1500/6787]	eta 0:22:03 lr 0.000200	time 0.2478 (0.2504)	loss 0.3727 (0.3637)	grad_norm 209717.7812 (inf)	mem 14543MB
[2023-10-11 02:31:45 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2473 (0.2503)	loss 0.3841 (0.3640)	grad_norm 149170.3125 (inf)	mem 14543MB
[2023-10-11 02:33:50 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2508 (0.2502)	loss 0.3671 (0.3640)	grad_norm 304377.5938 (inf)	mem 14543MB
[2023-10-11 02:35:54 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2500 (0.2501)	loss 0.3893 (0.3637)	grad_norm 431888.3438 (inf)	mem 14543MB
[2023-10-11 02:37:59 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2553 (0.2501)	loss 0.3362 (0.3633)	grad_norm 448759.0625 (inf)	mem 14543MB
[2023-10-11 02:40:04 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2502 (0.2500)	loss 0.3391 (0.3632)	grad_norm 308764.1250 (inf)	mem 14543MB
[2023-10-11 02:42:09 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2470 (0.2499)	loss 0.3638 (0.3632)	grad_norm 407801.9062 (inf)	mem 14543MB
[2023-10-11 02:44:14 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2511 (0.2499)	loss 0.3914 (0.3631)	grad_norm 403336.8750 (inf)	mem 14543MB
[2023-10-11 02:46:19 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2473 (0.2499)	loss 0.3771 (0.3630)	grad_norm 286049.4688 (inf)	mem 14543MB
[2023-10-11 02:48:24 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2479 (0.2499)	loss 0.3578 (0.3630)	grad_norm 222491.9062 (inf)	mem 14543MB
[2023-10-11 02:50:29 simmim_pretrain](main_simmim.py 218): INFO Train: [49/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2478 (0.2499)	loss 0.3450 (0.3631)	grad_norm 95039.0859 (inf)	mem 14543MB
[2023-10-11 02:51:41 simmim_pretrain](main_simmim.py 228): INFO EPOCH 49 training takes 0:28:17
[2023-10-11 02:51:42 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][0/6787]	eta 2:40:53 lr 0.000200	time 1.4224 (1.4224)	loss 0.3475 (0.3475)	grad_norm 280531.1562 (280531.1562)	mem 14543MB
[2023-10-11 02:53:47 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][500/6787]	eta 0:26:21 lr 0.000200	time 0.2501 (0.2516)	loss 0.3760 (0.3630)	grad_norm 211297.5469 (253206.5469)	mem 14543MB
[2023-10-11 02:55:52 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][1000/6787]	eta 0:24:10 lr 0.000200	time 0.2508 (0.2507)	loss 0.3780 (0.3631)	grad_norm 234479.2031 (256044.3281)	mem 14543MB
[2023-10-11 02:57:57 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][1500/6787]	eta 0:22:03 lr 0.000200	time 0.2462 (0.2503)	loss 0.3833 (0.3632)	grad_norm 309001.9688 (278049.4375)	mem 14543MB
[2023-10-11 03:00:01 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][2000/6787]	eta 0:19:57 lr 0.000200	time 0.2495 (0.2501)	loss 0.3651 (0.3630)	grad_norm 214604.1250 (inf)	mem 14543MB
[2023-10-11 03:02:06 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][2500/6787]	eta 0:17:51 lr 0.000200	time 0.2506 (0.2499)	loss 0.3601 (0.3632)	grad_norm 202331.9219 (inf)	mem 14543MB
[2023-10-11 03:04:11 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2470 (0.2499)	loss 0.3670 (0.3633)	grad_norm 325879.5312 (inf)	mem 14543MB
[2023-10-11 03:06:16 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2446 (0.2499)	loss 0.3825 (0.3633)	grad_norm 153282.1875 (inf)	mem 14543MB
[2023-10-11 03:08:20 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2458 (0.2498)	loss 0.3921 (0.3633)	grad_norm 334027.1562 (inf)	mem 14543MB
[2023-10-11 03:10:25 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2496 (0.2497)	loss 0.3496 (0.3632)	grad_norm 610268.6875 (inf)	mem 14543MB
[2023-10-11 03:12:30 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2576 (0.2497)	loss 0.3593 (0.3631)	grad_norm 562246.0625 (inf)	mem 14543MB
[2023-10-11 03:14:34 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2496 (0.2497)	loss 0.3518 (0.3630)	grad_norm 339417.7812 (inf)	mem 14543MB
[2023-10-11 03:16:39 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2490 (0.2496)	loss 0.3451 (0.3629)	grad_norm 502384.1250 (inf)	mem 14543MB
[2023-10-11 03:18:44 simmim_pretrain](main_simmim.py 218): INFO Train: [50/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2500 (0.2496)	loss 0.3641 (0.3629)	grad_norm 936886.3125 (inf)	mem 14543MB
[2023-10-11 03:19:56 simmim_pretrain](main_simmim.py 228): INFO EPOCH 50 training takes 0:28:14
[2023-10-11 03:19:57 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][0/6787]	eta 2:43:51 lr 0.000200	time 1.4486 (1.4486)	loss 0.3680 (0.3680)	grad_norm 329809.7812 (329809.7812)	mem 14543MB
[2023-10-11 03:22:01 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][500/6787]	eta 0:26:19 lr 0.000200	time 0.2596 (0.2512)	loss 0.3668 (0.3619)	grad_norm 560819.8125 (451228.8438)	mem 14543MB
[2023-10-11 03:24:06 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][1000/6787]	eta 0:24:07 lr 0.000200	time 0.2457 (0.2502)	loss 0.3689 (0.3624)	grad_norm 610100.0625 (453724.4062)	mem 14543MB
[2023-10-11 03:26:11 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][1500/6787]	eta 0:22:01 lr 0.000200	time 0.2473 (0.2500)	loss 0.3591 (0.3626)	grad_norm 563284.8750 (inf)	mem 14543MB
[2023-10-11 03:28:16 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][2000/6787]	eta 0:19:56 lr 0.000200	time 0.2569 (0.2499)	loss 0.3576 (0.3625)	grad_norm 374223.4375 (inf)	mem 14543MB
[2023-10-11 03:30:21 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][2500/6787]	eta 0:17:51 lr 0.000200	time 0.2482 (0.2499)	loss 0.3655 (0.3626)	grad_norm 427651.9375 (inf)	mem 14543MB
[2023-10-11 03:32:25 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2514 (0.2499)	loss 0.3494 (0.3625)	grad_norm 460327.7500 (inf)	mem 14543MB
[2023-10-11 03:34:30 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2503 (0.2498)	loss 0.3583 (0.3623)	grad_norm 646937.8750 (inf)	mem 14543MB
[2023-10-11 03:36:35 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2524 (0.2498)	loss 0.3729 (0.3623)	grad_norm 815029.9375 (inf)	mem 14543MB
[2023-10-11 03:38:40 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2481 (0.2498)	loss 0.3631 (0.3623)	grad_norm 333791.5312 (inf)	mem 14543MB
[2023-10-11 03:40:45 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2532 (0.2498)	loss 0.3633 (0.3624)	grad_norm 566627.5625 (inf)	mem 14543MB
[2023-10-11 03:42:50 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2463 (0.2499)	loss 0.3683 (0.3624)	grad_norm 473159.7500 (inf)	mem 14543MB
[2023-10-11 03:44:55 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2470 (0.2499)	loss 0.3584 (0.3625)	grad_norm 339222.2812 (inf)	mem 14543MB
[2023-10-11 03:47:00 simmim_pretrain](main_simmim.py 218): INFO Train: [51/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2525 (0.2499)	loss 0.3605 (0.3625)	grad_norm 322059.4375 (inf)	mem 14543MB
[2023-10-11 03:48:12 simmim_pretrain](main_simmim.py 228): INFO EPOCH 51 training takes 0:28:16
[2023-10-11 03:48:14 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][0/6787]	eta 2:54:09 lr 0.000200	time 1.5397 (1.5397)	loss 0.3724 (0.3724)	grad_norm 338129.8750 (338129.8750)	mem 14543MB
[2023-10-11 03:50:19 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][500/6787]	eta 0:26:22 lr 0.000200	time 0.2464 (0.2517)	loss 0.3580 (0.3647)	grad_norm 343022.4375 (311183.4688)	mem 14543MB
[2023-10-11 03:52:24 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2465 (0.2508)	loss 0.3479 (0.3645)	grad_norm 200447.3281 (298474.0312)	mem 14543MB
[2023-10-11 03:54:28 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2545 (0.2505)	loss 0.3681 (0.3643)	grad_norm 349441.0938 (290169.6875)	mem 14543MB
[2023-10-11 03:56:33 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2500 (0.2503)	loss 0.3560 (0.3641)	grad_norm 262786.4375 (302799.0625)	mem 14543MB
[2023-10-11 03:58:38 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2483 (0.2502)	loss 0.3666 (0.3636)	grad_norm 584927.7500 (336663.4062)	mem 14543MB
[2023-10-11 04:00:43 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2468 (0.2501)	loss 0.3611 (0.3634)	grad_norm 346435.5938 (inf)	mem 14543MB
[2023-10-11 04:02:48 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2502 (0.2500)	loss 0.3731 (0.3636)	grad_norm 231555.1875 (inf)	mem 14543MB
[2023-10-11 04:04:53 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2479 (0.2500)	loss 0.3646 (0.3636)	grad_norm 329689.0625 (inf)	mem 14543MB
[2023-10-11 04:06:57 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2516 (0.2499)	loss 0.3608 (0.3636)	grad_norm 219905.7344 (inf)	mem 14543MB
[2023-10-11 04:09:02 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2467 (0.2498)	loss 0.3618 (0.3636)	grad_norm 214960.0938 (inf)	mem 14543MB
[2023-10-11 04:11:07 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2464 (0.2498)	loss 0.3635 (0.3635)	grad_norm 521343.5938 (inf)	mem 14543MB
[2023-10-11 04:13:11 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2492 (0.2497)	loss 0.3731 (0.3635)	grad_norm 264869.9375 (inf)	mem 14543MB
[2023-10-11 04:15:16 simmim_pretrain](main_simmim.py 218): INFO Train: [52/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2502 (0.2497)	loss 0.3503 (0.3634)	grad_norm 493943.5000 (inf)	mem 14543MB
[2023-10-11 04:16:28 simmim_pretrain](main_simmim.py 228): INFO EPOCH 52 training takes 0:28:15
[2023-10-11 04:16:29 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][0/6787]	eta 2:39:04 lr 0.000200	time 1.4063 (1.4063)	loss 0.3741 (0.3741)	grad_norm 189475.5312 (189475.5312)	mem 14543MB
[2023-10-11 04:18:34 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][500/6787]	eta 0:26:18 lr 0.000200	time 0.2534 (0.2511)	loss 0.3836 (0.3623)	grad_norm 406536.2812 (inf)	mem 14543MB
[2023-10-11 04:20:39 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][1000/6787]	eta 0:24:08 lr 0.000200	time 0.2491 (0.2504)	loss 0.3574 (0.3623)	grad_norm 598655.6875 (inf)	mem 14543MB
[2023-10-11 04:22:43 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][1500/6787]	eta 0:22:01 lr 0.000200	time 0.2523 (0.2500)	loss 0.3794 (0.3627)	grad_norm 352266.4375 (inf)	mem 14543MB
[2023-10-11 04:24:48 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][2000/6787]	eta 0:19:55 lr 0.000200	time 0.2589 (0.2498)	loss 0.3681 (0.3630)	grad_norm 229203.3125 (inf)	mem 14543MB
[2023-10-11 04:26:52 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][2500/6787]	eta 0:17:50 lr 0.000200	time 0.2457 (0.2497)	loss 0.3639 (0.3632)	grad_norm 428634.5938 (inf)	mem 14543MB
[2023-10-11 04:28:57 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][3000/6787]	eta 0:15:45 lr 0.000200	time 0.2469 (0.2497)	loss 0.3580 (0.3634)	grad_norm 299912.7188 (inf)	mem 14543MB
[2023-10-11 04:31:02 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][3500/6787]	eta 0:13:40 lr 0.000200	time 0.2511 (0.2496)	loss 0.3597 (0.3634)	grad_norm 258500.3594 (inf)	mem 14543MB
[2023-10-11 04:33:07 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][4000/6787]	eta 0:11:35 lr 0.000200	time 0.2462 (0.2496)	loss 0.3689 (0.3636)	grad_norm 188816.4219 (inf)	mem 14543MB
[2023-10-11 04:35:11 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][4500/6787]	eta 0:09:30 lr 0.000200	time 0.2465 (0.2496)	loss 0.3430 (0.3637)	grad_norm 365742.2812 (inf)	mem 14543MB
[2023-10-11 04:37:16 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2496 (0.2496)	loss 0.3647 (0.3637)	grad_norm 323241.8125 (inf)	mem 14543MB
[2023-10-11 04:39:21 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2494 (0.2496)	loss 0.3451 (0.3637)	grad_norm 396808.9375 (inf)	mem 14543MB
[2023-10-11 04:41:26 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2511 (0.2496)	loss 0.3568 (0.3636)	grad_norm 268041.6250 (inf)	mem 14543MB
[2023-10-11 04:43:31 simmim_pretrain](main_simmim.py 218): INFO Train: [53/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2497 (0.2496)	loss 0.3724 (0.3637)	grad_norm 307951.5312 (inf)	mem 14543MB
[2023-10-11 04:44:43 simmim_pretrain](main_simmim.py 228): INFO EPOCH 53 training takes 0:28:15
[2023-10-11 04:44:44 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][0/6787]	eta 2:43:16 lr 0.000200	time 1.4434 (1.4434)	loss 0.3816 (0.3816)	grad_norm 135215.5000 (135215.5000)	mem 14543MB
[2023-10-11 04:46:49 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][500/6787]	eta 0:26:26 lr 0.000200	time 0.2496 (0.2524)	loss 0.3786 (0.3637)	grad_norm 204125.5156 (290804.1875)	mem 14543MB
[2023-10-11 04:48:55 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][1000/6787]	eta 0:24:14 lr 0.000200	time 0.2466 (0.2513)	loss 0.3555 (0.3640)	grad_norm 337903.7188 (292813.8750)	mem 14543MB
[2023-10-11 04:51:00 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][1500/6787]	eta 0:22:06 lr 0.000200	time 0.2474 (0.2508)	loss 0.3638 (0.3639)	grad_norm 538586.5000 (307389.1875)	mem 14543MB
[2023-10-11 04:53:05 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][2000/6787]	eta 0:19:59 lr 0.000200	time 0.2501 (0.2506)	loss 0.3684 (0.3638)	grad_norm 573000.6875 (338029.5000)	mem 14543MB
[2023-10-11 04:55:10 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][2500/6787]	eta 0:17:54 lr 0.000200	time 0.2518 (0.2505)	loss 0.3692 (0.3635)	grad_norm 613638.8750 (367883.0938)	mem 14543MB
[2023-10-11 04:57:15 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][3000/6787]	eta 0:15:48 lr 0.000200	time 0.2521 (0.2505)	loss 0.3762 (0.3634)	grad_norm 534723.0000 (387348.2812)	mem 14543MB
[2023-10-11 04:59:20 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][3500/6787]	eta 0:13:43 lr 0.000200	time 0.2498 (0.2504)	loss 0.3880 (0.3635)	grad_norm 347911.3438 (inf)	mem 14543MB
[2023-10-11 05:01:25 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2631 (0.2503)	loss 0.3488 (0.3635)	grad_norm 324752.1250 (inf)	mem 14543MB
[2023-10-11 05:03:30 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2465 (0.2503)	loss 0.3550 (0.3636)	grad_norm 306758.8438 (inf)	mem 14543MB
[2023-10-11 05:05:34 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2519 (0.2502)	loss 0.3842 (0.3638)	grad_norm 284463.9375 (inf)	mem 14543MB
[2023-10-11 05:07:39 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2536 (0.2502)	loss 0.3631 (0.3638)	grad_norm 309042.9062 (inf)	mem 14543MB
[2023-10-11 05:09:44 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2523 (0.2502)	loss 0.3498 (0.3637)	grad_norm 571494.4375 (inf)	mem 14543MB
[2023-10-11 05:11:49 simmim_pretrain](main_simmim.py 218): INFO Train: [54/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2506 (0.2501)	loss 0.3789 (0.3636)	grad_norm 316518.9375 (inf)	mem 14543MB
[2023-10-11 05:13:01 simmim_pretrain](main_simmim.py 228): INFO EPOCH 54 training takes 0:28:18
[2023-10-11 05:13:03 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][0/6787]	eta 2:39:58 lr 0.000200	time 1.4142 (1.4142)	loss 0.3666 (0.3666)	grad_norm 373138.6250 (373138.6250)	mem 14543MB
[2023-10-11 05:15:07 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][500/6787]	eta 0:26:23 lr 0.000200	time 0.2470 (0.2518)	loss 0.3757 (0.3639)	grad_norm 201458.0781 (304766.2812)	mem 14543MB
[2023-10-11 05:17:12 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][1000/6787]	eta 0:24:10 lr 0.000200	time 0.2594 (0.2506)	loss 0.3644 (0.3637)	grad_norm 237650.2344 (303395.6250)	mem 14543MB
[2023-10-11 05:19:17 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][1500/6787]	eta 0:22:02 lr 0.000200	time 0.2459 (0.2502)	loss 0.3680 (0.3641)	grad_norm 388402.5938 (304719.1562)	mem 14543MB
[2023-10-11 05:21:21 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][2000/6787]	eta 0:19:56 lr 0.000200	time 0.2467 (0.2500)	loss 0.3593 (0.3640)	grad_norm 432491.8125 (337349.0312)	mem 14543MB
[2023-10-11 05:23:26 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][2500/6787]	eta 0:17:51 lr 0.000200	time 0.2547 (0.2498)	loss 0.3549 (0.3634)	grad_norm 413327.5000 (inf)	mem 14543MB
[2023-10-11 05:25:31 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][3000/6787]	eta 0:15:45 lr 0.000200	time 0.2427 (0.2498)	loss 0.3729 (0.3636)	grad_norm 169436.2656 (inf)	mem 14543MB
[2023-10-11 05:27:36 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][3500/6787]	eta 0:13:40 lr 0.000200	time 0.2521 (0.2498)	loss 0.3611 (0.3637)	grad_norm 251431.1406 (inf)	mem 14543MB
[2023-10-11 05:29:40 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][4000/6787]	eta 0:11:35 lr 0.000200	time 0.2472 (0.2497)	loss 0.3703 (0.3637)	grad_norm 263475.0625 (inf)	mem 14543MB
[2023-10-11 05:31:45 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2472 (0.2497)	loss 0.3467 (0.3640)	grad_norm 515986.5938 (inf)	mem 14543MB
[2023-10-11 05:33:50 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2469 (0.2497)	loss 0.3753 (0.3640)	grad_norm 357400.7500 (inf)	mem 14543MB
[2023-10-11 05:35:54 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2465 (0.2496)	loss 0.3626 (0.3640)	grad_norm 316332.9688 (inf)	mem 14543MB
[2023-10-11 05:37:59 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2474 (0.2496)	loss 0.3652 (0.3641)	grad_norm 306102.3125 (inf)	mem 14543MB
[2023-10-11 05:40:04 simmim_pretrain](main_simmim.py 218): INFO Train: [55/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2457 (0.2496)	loss 0.3545 (0.3640)	grad_norm 312450.6875 (inf)	mem 14543MB
[2023-10-11 05:41:16 simmim_pretrain](main_simmim.py 228): INFO EPOCH 55 training takes 0:28:14
[2023-10-11 05:41:18 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][0/6787]	eta 2:54:25 lr 0.000200	time 1.5420 (1.5420)	loss 0.3633 (0.3633)	grad_norm 213465.1719 (213465.1719)	mem 14543MB
[2023-10-11 05:43:22 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][500/6787]	eta 0:26:25 lr 0.000200	time 0.2522 (0.2522)	loss 0.3426 (0.3637)	grad_norm 549147.5000 (410852.0938)	mem 14543MB
[2023-10-11 05:45:27 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2564 (0.2509)	loss 0.3264 (0.3629)	grad_norm 712221.4375 (437120.6562)	mem 14543MB
[2023-10-11 05:47:32 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2465 (0.2506)	loss 0.3655 (0.3626)	grad_norm 872100.8750 (461076.6562)	mem 14543MB
[2023-10-11 05:49:37 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2496 (0.2504)	loss 0.5545 (0.3697)	grad_norm 2022.5883 (inf)	mem 14543MB
[2023-10-11 05:51:42 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2460 (0.2502)	loss 0.4950 (0.3989)	grad_norm 5994.0884 (inf)	mem 14543MB
[2023-10-11 05:53:46 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2493 (0.2500)	loss 0.4947 (0.4146)	grad_norm 5440.5225 (inf)	mem 14543MB
[2023-10-11 05:55:51 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2496 (0.2499)	loss 0.4753 (0.4229)	grad_norm 9829.1738 (inf)	mem 14543MB
[2023-10-11 05:57:56 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2491 (0.2498)	loss 0.4198 (0.4257)	grad_norm 14463.5820 (inf)	mem 14543MB
[2023-10-11 06:00:01 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2492 (0.2498)	loss 0.3962 (0.4241)	grad_norm 20710.0352 (inf)	mem 14543MB
[2023-10-11 06:02:05 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2490 (0.2498)	loss 0.3704 (0.4213)	grad_norm 10343.1875 (inf)	mem 14543MB
[2023-10-11 06:04:10 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2523 (0.2498)	loss 0.3971 (0.4183)	grad_norm 8229.6523 (inf)	mem 14543MB
[2023-10-11 06:06:15 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2467 (0.2498)	loss 0.3810 (0.4151)	grad_norm 9307.1475 (inf)	mem 14543MB
[2023-10-11 06:08:20 simmim_pretrain](main_simmim.py 218): INFO Train: [56/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2593 (0.2498)	loss 0.3769 (0.4120)	grad_norm 17468.2266 (inf)	mem 14543MB
[2023-10-11 06:09:32 simmim_pretrain](main_simmim.py 228): INFO EPOCH 56 training takes 0:28:15
[2023-10-11 06:09:33 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][0/6787]	eta 2:46:16 lr 0.000200	time 1.4699 (1.4699)	loss 0.3819 (0.3819)	grad_norm 21356.7773 (21356.7773)	mem 14543MB
[2023-10-11 06:11:38 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][500/6787]	eta 0:26:20 lr 0.000200	time 0.2459 (0.2515)	loss 0.3795 (0.3728)	grad_norm 28660.2031 (24196.7012)	mem 14543MB
[2023-10-11 06:13:42 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][1000/6787]	eta 0:24:08 lr 0.000200	time 0.2484 (0.2503)	loss 0.3651 (0.3726)	grad_norm 20412.0098 (24111.9883)	mem 14543MB
[2023-10-11 06:15:47 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][1500/6787]	eta 0:22:01 lr 0.000200	time 0.2529 (0.2499)	loss 0.3744 (0.3717)	grad_norm 18188.6523 (25952.2031)	mem 14543MB
[2023-10-11 06:17:52 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][2000/6787]	eta 0:19:55 lr 0.000200	time 0.2449 (0.2497)	loss 0.3675 (0.3710)	grad_norm 52481.3477 (28705.1250)	mem 14543MB
[2023-10-11 06:19:56 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][2500/6787]	eta 0:17:50 lr 0.000200	time 0.2547 (0.2496)	loss 0.3701 (0.3705)	grad_norm 44398.6250 (31606.7324)	mem 14543MB
[2023-10-11 06:22:01 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][3000/6787]	eta 0:15:45 lr 0.000200	time 0.2451 (0.2495)	loss 0.3719 (0.3702)	grad_norm 44861.0195 (33857.7969)	mem 14543MB
[2023-10-11 06:24:05 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][3500/6787]	eta 0:13:40 lr 0.000200	time 0.2491 (0.2495)	loss 0.3695 (0.3697)	grad_norm 37820.1406 (36847.7344)	mem 14543MB
[2023-10-11 06:26:10 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][4000/6787]	eta 0:11:35 lr 0.000200	time 0.2523 (0.2495)	loss 0.3829 (0.3693)	grad_norm 89612.6172 (40809.8164)	mem 14543MB
[2023-10-11 06:28:15 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][4500/6787]	eta 0:09:30 lr 0.000200	time 0.2495 (0.2495)	loss 0.3915 (0.3689)	grad_norm 95887.1953 (44727.4023)	mem 14543MB
[2023-10-11 06:30:20 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][5000/6787]	eta 0:07:25 lr 0.000200	time 0.2463 (0.2495)	loss 0.3682 (0.3686)	grad_norm 36438.8633 (48597.1172)	mem 14543MB
[2023-10-11 06:32:24 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2454 (0.2495)	loss 0.3444 (0.3683)	grad_norm 161019.0781 (54351.9453)	mem 14543MB
[2023-10-11 06:34:29 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2469 (0.2495)	loss 0.3418 (0.3681)	grad_norm 176578.9219 (63988.3828)	mem 14543MB
[2023-10-11 06:36:34 simmim_pretrain](main_simmim.py 218): INFO Train: [57/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2450 (0.2495)	loss 0.3682 (0.3678)	grad_norm 141154.0781 (71518.5469)	mem 14543MB
[2023-10-11 06:37:46 simmim_pretrain](main_simmim.py 228): INFO EPOCH 57 training takes 0:28:14
[2023-10-11 06:37:47 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][0/6787]	eta 2:47:45 lr 0.000200	time 1.4830 (1.4830)	loss 0.3654 (0.3654)	grad_norm 121403.5547 (121403.5547)	mem 14543MB
[2023-10-11 06:39:52 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][500/6787]	eta 0:26:21 lr 0.000200	time 0.2486 (0.2515)	loss 0.3538 (0.3654)	grad_norm 267333.2500 (169665.2656)	mem 14543MB
[2023-10-11 06:41:57 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][1000/6787]	eta 0:24:10 lr 0.000200	time 0.2522 (0.2506)	loss 0.3564 (0.3646)	grad_norm 210185.5156 (195570.2812)	mem 14543MB
[2023-10-11 06:44:02 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][1500/6787]	eta 0:22:03 lr 0.000200	time 0.2527 (0.2504)	loss 0.3647 (0.3641)	grad_norm 507732.5625 (231626.2344)	mem 14543MB
[2023-10-11 06:46:07 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2518 (0.2503)	loss 0.3607 (0.3639)	grad_norm 597508.8125 (262564.0312)	mem 14543MB
[2023-10-11 06:48:12 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][2500/6787]	eta 0:17:53 lr 0.000200	time 0.2594 (0.2503)	loss 0.3597 (0.3638)	grad_norm 246748.2656 (inf)	mem 14543MB
[2023-10-11 06:50:17 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2539 (0.2502)	loss 0.3564 (0.3639)	grad_norm 331113.1875 (inf)	mem 14543MB
[2023-10-11 06:52:22 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2462 (0.2501)	loss 0.3629 (0.3637)	grad_norm 260113.2031 (inf)	mem 14543MB
[2023-10-11 06:54:27 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2487 (0.2501)	loss 0.3716 (0.3637)	grad_norm 329937.1875 (inf)	mem 14543MB
[2023-10-11 06:56:32 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2471 (0.2501)	loss 0.3602 (0.3637)	grad_norm 300800.4062 (inf)	mem 14543MB
[2023-10-11 06:58:36 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2513 (0.2500)	loss 0.3538 (0.3636)	grad_norm 385134.5938 (inf)	mem 14543MB
[2023-10-11 07:00:41 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2467 (0.2500)	loss 0.3767 (0.3637)	grad_norm 488168.4062 (inf)	mem 14543MB
[2023-10-11 07:02:46 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2507 (0.2499)	loss 0.3658 (0.3637)	grad_norm 295277.1562 (inf)	mem 14543MB
[2023-10-11 07:04:51 simmim_pretrain](main_simmim.py 218): INFO Train: [58/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2490 (0.2499)	loss 0.3619 (0.3637)	grad_norm 318438.1875 (inf)	mem 14543MB
[2023-10-11 07:06:03 simmim_pretrain](main_simmim.py 228): INFO EPOCH 58 training takes 0:28:16
[2023-10-11 07:06:04 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][0/6787]	eta 2:48:09 lr 0.000200	time 1.4866 (1.4866)	loss 0.3861 (0.3861)	grad_norm 171094.7188 (171094.7188)	mem 14543MB
[2023-10-11 07:08:09 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][500/6787]	eta 0:26:22 lr 0.000200	time 0.2556 (0.2517)	loss 0.3893 (0.3650)	grad_norm 263277.6875 (234104.7812)	mem 14543MB
[2023-10-11 07:10:14 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][1000/6787]	eta 0:24:10 lr 0.000200	time 0.2506 (0.2507)	loss 0.3592 (0.3648)	grad_norm 168489.4688 (224050.7500)	mem 14543MB
[2023-10-11 07:12:18 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][1500/6787]	eta 0:22:03 lr 0.000200	time 0.2592 (0.2502)	loss 0.3361 (0.3645)	grad_norm 201829.3594 (227714.0938)	mem 14543MB
[2023-10-11 07:14:23 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][2000/6787]	eta 0:19:57 lr 0.000200	time 0.2533 (0.2501)	loss 0.3629 (0.3643)	grad_norm 548683.4375 (247417.6250)	mem 14543MB
[2023-10-11 07:16:30 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2540 (0.2509)	loss 0.3416 (0.3641)	grad_norm 536888.0000 (278132.8750)	mem 14543MB
[2023-10-11 07:18:37 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2593 (0.2514)	loss 0.3531 (0.3641)	grad_norm 857486.1875 (288827.4375)	mem 14543MB
[2023-10-11 07:20:44 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2535 (0.2518)	loss 0.3582 (0.3637)	grad_norm 247973.7969 (inf)	mem 14543MB
[2023-10-11 07:22:51 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2529 (0.2520)	loss 0.3634 (0.3639)	grad_norm 270071.6875 (inf)	mem 14543MB
[2023-10-11 07:24:58 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2536 (0.2522)	loss 0.3653 (0.3640)	grad_norm 241580.2812 (inf)	mem 14543MB
[2023-10-11 07:27:05 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][5000/6787]	eta 0:07:31 lr 0.000200	time 0.2531 (0.2524)	loss 0.3675 (0.3640)	grad_norm 176652.3750 (inf)	mem 14543MB
[2023-10-11 07:29:12 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2531 (0.2525)	loss 0.3799 (0.3639)	grad_norm 274522.0625 (inf)	mem 14543MB
[2023-10-11 07:31:19 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2531 (0.2526)	loss 0.3697 (0.3639)	grad_norm 293115.8125 (inf)	mem 14543MB
[2023-10-11 07:33:26 simmim_pretrain](main_simmim.py 218): INFO Train: [59/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2538 (0.2527)	loss 0.3594 (0.3639)	grad_norm 525726.6250 (inf)	mem 14543MB
[2023-10-11 07:34:39 simmim_pretrain](main_simmim.py 228): INFO EPOCH 59 training takes 0:28:36
[2023-10-11 07:34:41 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][0/6787]	eta 3:02:51 lr 0.000200	time 1.6166 (1.6166)	loss 0.3566 (0.3566)	grad_norm 179210.2656 (179210.2656)	mem 14543MB
[2023-10-11 07:36:45 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][500/6787]	eta 0:26:21 lr 0.000200	time 0.2518 (0.2516)	loss 0.3408 (0.3640)	grad_norm 217925.3125 (245494.9688)	mem 14543MB
[2023-10-11 07:38:50 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][1000/6787]	eta 0:24:09 lr 0.000200	time 0.2532 (0.2505)	loss 0.3674 (0.3640)	grad_norm 250901.8125 (238155.1094)	mem 14543MB
[2023-10-11 07:40:54 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][1500/6787]	eta 0:22:02 lr 0.000200	time 0.2460 (0.2501)	loss 0.3567 (0.3637)	grad_norm 227277.7812 (243554.0469)	mem 14543MB
[2023-10-11 07:42:59 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][2000/6787]	eta 0:19:56 lr 0.000200	time 0.2484 (0.2500)	loss 0.3621 (0.3638)	grad_norm 438943.6250 (242379.9688)	mem 14543MB
[2023-10-11 07:45:04 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][2500/6787]	eta 0:17:51 lr 0.000200	time 0.2474 (0.2499)	loss 0.3718 (0.3635)	grad_norm 275961.3438 (259831.9062)	mem 14543MB
[2023-10-11 07:47:09 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2547 (0.2499)	loss 0.3587 (0.3635)	grad_norm 506672.1875 (278491.7188)	mem 14543MB
[2023-10-11 07:49:14 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2521 (0.2499)	loss 0.3585 (0.3634)	grad_norm 366454.0312 (289703.6250)	mem 14543MB
[2023-10-11 07:51:19 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2462 (0.2499)	loss 0.3689 (0.3632)	grad_norm 881423.0625 (inf)	mem 14543MB
[2023-10-11 07:53:24 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2464 (0.2499)	loss 0.3500 (0.3630)	grad_norm 222504.4375 (inf)	mem 14543MB
[2023-10-11 07:55:28 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2489 (0.2498)	loss 0.3705 (0.3629)	grad_norm 283103.1250 (inf)	mem 14543MB
[2023-10-11 07:57:33 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2499 (0.2498)	loss 0.3385 (0.3628)	grad_norm 414764.5938 (inf)	mem 14543MB
[2023-10-11 07:59:38 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2474 (0.2498)	loss 0.3709 (0.3627)	grad_norm 751219.0625 (inf)	mem 14543MB
[2023-10-11 08:01:43 simmim_pretrain](main_simmim.py 218): INFO Train: [60/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2481 (0.2498)	loss 0.3724 (0.3627)	grad_norm 497558.5625 (inf)	mem 14543MB
[2023-10-11 08:02:55 simmim_pretrain](main_simmim.py 228): INFO EPOCH 60 training takes 0:28:16
[2023-10-11 08:02:55 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_60.pth saving......
[2023-10-11 08:02:56 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_60.pth saved !!!
[2023-10-11 08:02:57 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][0/6787]	eta 2:28:35 lr 0.000200	time 1.3136 (1.3136)	loss 0.3442 (0.3442)	grad_norm 527017.0000 (527017.0000)	mem 14543MB
[2023-10-11 08:05:02 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][500/6787]	eta 0:26:19 lr 0.000200	time 0.2487 (0.2512)	loss 0.3651 (0.3636)	grad_norm 251129.5156 (467523.2500)	mem 14543MB
[2023-10-11 08:07:07 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][1000/6787]	eta 0:24:09 lr 0.000200	time 0.2459 (0.2504)	loss 0.3940 (0.3634)	grad_norm 328609.7812 (inf)	mem 14543MB
[2023-10-11 08:09:11 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][1500/6787]	eta 0:22:02 lr 0.000200	time 0.2454 (0.2501)	loss 0.3607 (0.3638)	grad_norm 265209.6875 (inf)	mem 14543MB
[2023-10-11 08:11:16 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][2000/6787]	eta 0:19:56 lr 0.000200	time 0.2449 (0.2500)	loss 0.3559 (0.3638)	grad_norm 239099.8906 (inf)	mem 14543MB
[2023-10-11 08:13:21 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][2500/6787]	eta 0:17:51 lr 0.000200	time 0.2492 (0.2499)	loss 0.3824 (0.3638)	grad_norm 151659.6094 (inf)	mem 14543MB
[2023-10-11 08:15:26 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2590 (0.2498)	loss 0.3791 (0.3642)	grad_norm 159163.5938 (inf)	mem 14543MB
[2023-10-11 08:17:30 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2501 (0.2498)	loss 0.3595 (0.3645)	grad_norm 166781.5938 (inf)	mem 14543MB
[2023-10-11 08:19:35 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2500 (0.2498)	loss 0.3789 (0.3647)	grad_norm 167285.2500 (inf)	mem 14543MB
[2023-10-11 08:21:40 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2496 (0.2498)	loss 0.3309 (0.3647)	grad_norm 169171.1406 (inf)	mem 14543MB
[2023-10-11 08:23:45 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2484 (0.2497)	loss 0.3769 (0.3646)	grad_norm 96959.6484 (inf)	mem 14543MB
[2023-10-11 08:25:50 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2493 (0.2497)	loss 0.3428 (0.3645)	grad_norm 251174.3125 (inf)	mem 14543MB
[2023-10-11 08:27:55 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2491 (0.2498)	loss 0.3385 (0.3645)	grad_norm 231342.7500 (inf)	mem 14543MB
[2023-10-11 08:29:59 simmim_pretrain](main_simmim.py 218): INFO Train: [61/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2511 (0.2497)	loss 0.3734 (0.3643)	grad_norm 293117.8750 (inf)	mem 14543MB
[2023-10-11 08:31:12 simmim_pretrain](main_simmim.py 228): INFO EPOCH 61 training takes 0:28:15
[2023-10-11 08:31:13 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][0/6787]	eta 2:53:16 lr 0.000200	time 1.5318 (1.5318)	loss 0.3577 (0.3577)	grad_norm 260462.5156 (260462.5156)	mem 14543MB
[2023-10-11 08:33:18 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][500/6787]	eta 0:26:21 lr 0.000200	time 0.2467 (0.2516)	loss 0.3852 (0.3623)	grad_norm 190863.5781 (297772.9062)	mem 14543MB
[2023-10-11 08:35:23 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][1000/6787]	eta 0:24:09 lr 0.000200	time 0.2466 (0.2505)	loss 0.3516 (0.3625)	grad_norm 310195.0938 (340491.5000)	mem 14543MB
[2023-10-11 08:37:27 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][1500/6787]	eta 0:22:02 lr 0.000200	time 0.2496 (0.2502)	loss 0.3759 (0.3624)	grad_norm 224799.9531 (352381.9062)	mem 14543MB
[2023-10-11 08:39:32 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][2000/6787]	eta 0:19:56 lr 0.000200	time 0.2490 (0.2500)	loss 0.3648 (0.3622)	grad_norm 453300.7500 (inf)	mem 14543MB
[2023-10-11 08:41:37 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][2500/6787]	eta 0:17:51 lr 0.000200	time 0.2493 (0.2499)	loss 0.3595 (0.3622)	grad_norm 396486.9688 (inf)	mem 14543MB
[2023-10-11 08:43:42 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2506 (0.2499)	loss 0.3502 (0.3623)	grad_norm 285901.0938 (inf)	mem 14543MB
[2023-10-11 08:45:48 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2506 (0.2502)	loss 0.3545 (0.3624)	grad_norm 243416.7812 (inf)	mem 14543MB
[2023-10-11 08:47:54 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2514 (0.2504)	loss 0.3689 (0.3624)	grad_norm 335249.0312 (inf)	mem 14543MB
[2023-10-11 08:50:00 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2542 (0.2506)	loss 0.3760 (0.3626)	grad_norm 213098.8438 (inf)	mem 14543MB
[2023-10-11 08:52:06 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2513 (0.2508)	loss 0.3536 (0.3625)	grad_norm 279225.0312 (inf)	mem 14543MB
[2023-10-11 08:54:12 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2505 (0.2509)	loss 0.3821 (0.3625)	grad_norm 453808.2812 (inf)	mem 14543MB
[2023-10-11 08:56:18 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2568 (0.2509)	loss 0.3696 (0.3625)	grad_norm 157112.4062 (inf)	mem 14543MB
[2023-10-11 08:58:24 simmim_pretrain](main_simmim.py 218): INFO Train: [62/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2507 (0.2510)	loss 0.3533 (0.3625)	grad_norm 936199.6875 (inf)	mem 14543MB
[2023-10-11 08:59:37 simmim_pretrain](main_simmim.py 228): INFO EPOCH 62 training takes 0:28:24
[2023-10-11 08:59:38 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][0/6787]	eta 3:01:41 lr 0.000200	time 1.6062 (1.6062)	loss 0.3561 (0.3561)	grad_norm 489068.6562 (489068.6562)	mem 14543MB
[2023-10-11 09:01:43 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][500/6787]	eta 0:26:25 lr 0.000200	time 0.2545 (0.2522)	loss 0.3433 (0.3618)	grad_norm 523721.9062 (454235.5000)	mem 14543MB
[2023-10-11 09:03:48 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2458 (0.2509)	loss 0.3728 (0.3621)	grad_norm 413777.7500 (447603.9688)	mem 14543MB
[2023-10-11 09:05:52 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][1500/6787]	eta 0:22:03 lr 0.000200	time 0.2459 (0.2504)	loss 0.3750 (0.3621)	grad_norm 574363.0625 (459671.6250)	mem 14543MB
[2023-10-11 09:07:57 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][2000/6787]	eta 0:19:57 lr 0.000200	time 0.2469 (0.2502)	loss 0.3439 (0.3623)	grad_norm 399589.4688 (inf)	mem 14543MB
[2023-10-11 09:10:02 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2477 (0.2501)	loss 0.3575 (0.3626)	grad_norm 300643.6250 (inf)	mem 14543MB
[2023-10-11 09:12:07 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2464 (0.2499)	loss 0.3751 (0.3629)	grad_norm 348417.5312 (inf)	mem 14543MB
[2023-10-11 09:14:11 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2565 (0.2499)	loss 0.3590 (0.3630)	grad_norm 212575.5156 (inf)	mem 14543MB
[2023-10-11 09:16:16 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2499 (0.2498)	loss 0.3504 (0.3629)	grad_norm 675239.0000 (inf)	mem 14543MB
[2023-10-11 09:18:21 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2474 (0.2498)	loss 0.3493 (0.3628)	grad_norm 490092.1875 (inf)	mem 14543MB
[2023-10-11 09:20:25 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2461 (0.2497)	loss 0.3670 (0.3628)	grad_norm 478417.6875 (inf)	mem 14543MB
[2023-10-11 09:22:30 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2478 (0.2497)	loss 0.3536 (0.3628)	grad_norm 457909.7500 (inf)	mem 14543MB
[2023-10-11 09:24:34 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2482 (0.2496)	loss 0.3527 (0.3628)	grad_norm 247812.6875 (inf)	mem 14543MB
[2023-10-11 09:26:39 simmim_pretrain](main_simmim.py 218): INFO Train: [63/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2483 (0.2496)	loss 0.3410 (0.3628)	grad_norm 300270.0938 (inf)	mem 14543MB
[2023-10-11 09:27:51 simmim_pretrain](main_simmim.py 228): INFO EPOCH 63 training takes 0:28:14
[2023-10-11 09:27:53 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][0/6787]	eta 3:07:11 lr 0.000200	time 1.6549 (1.6549)	loss 0.3408 (0.3408)	grad_norm 326039.5938 (326039.5938)	mem 14543MB
[2023-10-11 09:29:58 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][500/6787]	eta 0:26:26 lr 0.000200	time 0.2490 (0.2523)	loss 0.3527 (0.3650)	grad_norm 271117.4062 (266561.8438)	mem 14543MB
[2023-10-11 09:32:03 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][1000/6787]	eta 0:24:14 lr 0.000200	time 0.2486 (0.2513)	loss 0.3396 (0.3642)	grad_norm 259139.3594 (259407.6562)	mem 14543MB
[2023-10-11 09:34:08 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][1500/6787]	eta 0:22:06 lr 0.000200	time 0.2492 (0.2509)	loss 0.3250 (0.3638)	grad_norm 297275.6250 (inf)	mem 14543MB
[2023-10-11 09:36:13 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][2000/6787]	eta 0:20:00 lr 0.000200	time 0.2499 (0.2508)	loss 0.3545 (0.3637)	grad_norm 264638.2188 (inf)	mem 14543MB
[2023-10-11 09:38:18 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][2500/6787]	eta 0:17:54 lr 0.000200	time 0.2481 (0.2507)	loss 0.3680 (0.3638)	grad_norm 205538.4844 (inf)	mem 14543MB
[2023-10-11 09:40:23 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][3000/6787]	eta 0:15:49 lr 0.000200	time 0.2599 (0.2506)	loss 0.3544 (0.3636)	grad_norm 115810.5391 (inf)	mem 14543MB
[2023-10-11 09:42:28 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][3500/6787]	eta 0:13:43 lr 0.000200	time 0.2487 (0.2506)	loss 0.3643 (0.3634)	grad_norm 496984.2812 (inf)	mem 14543MB
[2023-10-11 09:44:34 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2483 (0.2506)	loss 0.3677 (0.3632)	grad_norm 443846.6250 (inf)	mem 14543MB
[2023-10-11 09:46:39 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2552 (0.2506)	loss 0.3740 (0.3630)	grad_norm 490680.4688 (inf)	mem 14543MB
[2023-10-11 09:48:44 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2500 (0.2506)	loss 0.3661 (0.3628)	grad_norm 503764.2188 (inf)	mem 14543MB
[2023-10-11 09:50:49 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2489 (0.2505)	loss 0.3502 (0.3628)	grad_norm 286947.0938 (inf)	mem 14543MB
[2023-10-11 09:52:54 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2496 (0.2505)	loss 0.3489 (0.3629)	grad_norm 222102.7344 (inf)	mem 14543MB
[2023-10-11 09:55:00 simmim_pretrain](main_simmim.py 218): INFO Train: [64/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2486 (0.2505)	loss 0.3438 (0.3630)	grad_norm 204317.4062 (inf)	mem 14543MB
[2023-10-11 09:56:12 simmim_pretrain](main_simmim.py 228): INFO EPOCH 64 training takes 0:28:20
[2023-10-11 09:56:13 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][0/6787]	eta 2:49:34 lr 0.000200	time 1.4992 (1.4992)	loss 0.3618 (0.3618)	grad_norm 131299.1250 (131299.1250)	mem 14543MB
[2023-10-11 09:58:18 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][500/6787]	eta 0:26:23 lr 0.000200	time 0.2527 (0.2518)	loss 0.3447 (0.3635)	grad_norm 348200.5312 (inf)	mem 14543MB
[2023-10-11 10:00:23 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][1000/6787]	eta 0:24:10 lr 0.000200	time 0.2461 (0.2507)	loss 0.3527 (0.3630)	grad_norm 277952.8750 (inf)	mem 14543MB
[2023-10-11 10:02:28 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][1500/6787]	eta 0:22:03 lr 0.000200	time 0.2523 (0.2503)	loss 0.3643 (0.3628)	grad_norm 367702.1562 (inf)	mem 14543MB
[2023-10-11 10:04:33 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][2000/6787]	eta 0:19:57 lr 0.000200	time 0.2454 (0.2502)	loss 0.3575 (0.3631)	grad_norm 337869.9062 (inf)	mem 14543MB
[2023-10-11 10:06:37 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2485 (0.2501)	loss 0.3505 (0.3631)	grad_norm 530708.5000 (inf)	mem 14543MB
[2023-10-11 10:08:42 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2454 (0.2499)	loss 0.3634 (0.3629)	grad_norm 246915.5938 (inf)	mem 14543MB
[2023-10-11 10:10:47 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2470 (0.2499)	loss 0.3667 (0.3627)	grad_norm 420803.4062 (inf)	mem 14543MB
[2023-10-11 10:12:51 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2553 (0.2498)	loss 0.3589 (0.3628)	grad_norm 297858.1562 (inf)	mem 14543MB
[2023-10-11 10:14:56 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2465 (0.2498)	loss 0.3863 (0.3629)	grad_norm 377202.7812 (inf)	mem 14543MB
[2023-10-11 10:17:01 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2450 (0.2497)	loss 0.3784 (0.3629)	grad_norm 179266.7344 (inf)	mem 14543MB
[2023-10-11 10:19:06 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2492 (0.2497)	loss 0.3795 (0.3629)	grad_norm 300468.5625 (inf)	mem 14543MB
[2023-10-11 10:21:10 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2543 (0.2497)	loss 0.3467 (0.3632)	grad_norm 156159.7812 (inf)	mem 14543MB
[2023-10-11 10:23:15 simmim_pretrain](main_simmim.py 218): INFO Train: [65/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2463 (0.2496)	loss 0.3842 (0.3633)	grad_norm 104296.7266 (inf)	mem 14543MB
[2023-10-11 10:24:27 simmim_pretrain](main_simmim.py 228): INFO EPOCH 65 training takes 0:28:15
[2023-10-11 10:24:29 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][0/6787]	eta 3:00:12 lr 0.000200	time 1.5931 (1.5931)	loss 0.3635 (0.3635)	grad_norm 122723.4219 (122723.4219)	mem 14543MB
[2023-10-11 10:26:33 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][500/6787]	eta 0:26:21 lr 0.000200	time 0.2484 (0.2515)	loss 0.3533 (0.3657)	grad_norm 147229.4219 (143896.7969)	mem 14543MB
[2023-10-11 10:28:38 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][1000/6787]	eta 0:24:09 lr 0.000200	time 0.2466 (0.2505)	loss 0.3847 (0.3653)	grad_norm 181782.2031 (144858.1562)	mem 14543MB
[2023-10-11 10:30:42 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][1500/6787]	eta 0:22:02 lr 0.000200	time 0.2496 (0.2501)	loss 0.3636 (0.3648)	grad_norm 150437.2656 (159238.7344)	mem 14543MB
[2023-10-11 10:32:47 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][2000/6787]	eta 0:19:56 lr 0.000200	time 0.2459 (0.2499)	loss 0.3548 (0.3644)	grad_norm 159439.0312 (173485.6719)	mem 14543MB
[2023-10-11 10:34:52 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][2500/6787]	eta 0:17:51 lr 0.000200	time 0.2466 (0.2498)	loss 0.3418 (0.3641)	grad_norm 197232.2656 (185502.4844)	mem 14543MB
[2023-10-11 10:36:57 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][3000/6787]	eta 0:15:45 lr 0.000200	time 0.2555 (0.2498)	loss 0.3732 (0.3640)	grad_norm 190845.1562 (195342.1094)	mem 14543MB
[2023-10-11 10:39:01 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][3500/6787]	eta 0:13:40 lr 0.000200	time 0.2495 (0.2497)	loss 0.3524 (0.3637)	grad_norm 325907.9688 (226250.8594)	mem 14543MB
[2023-10-11 10:41:06 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][4000/6787]	eta 0:11:35 lr 0.000200	time 0.2471 (0.2496)	loss 0.3473 (0.3635)	grad_norm 502769.1875 (248052.8438)	mem 14543MB
[2023-10-11 10:43:10 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][4500/6787]	eta 0:09:30 lr 0.000200	time 0.2482 (0.2495)	loss 0.3539 (0.3632)	grad_norm 220479.4688 (271358.7188)	mem 14543MB
[2023-10-11 10:45:14 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][5000/6787]	eta 0:07:25 lr 0.000200	time 0.2476 (0.2494)	loss 0.3722 (0.3632)	grad_norm 346645.1250 (inf)	mem 14543MB
[2023-10-11 10:47:19 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][5500/6787]	eta 0:05:20 lr 0.000200	time 0.2514 (0.2493)	loss 0.3609 (0.3632)	grad_norm 247438.4531 (inf)	mem 14543MB
[2023-10-11 10:49:23 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2494 (0.2493)	loss 0.3428 (0.3633)	grad_norm 363803.6250 (inf)	mem 14543MB
[2023-10-11 10:51:27 simmim_pretrain](main_simmim.py 218): INFO Train: [66/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2486 (0.2492)	loss 0.3598 (0.3633)	grad_norm 322327.1875 (inf)	mem 14543MB
[2023-10-11 10:52:39 simmim_pretrain](main_simmim.py 228): INFO EPOCH 66 training takes 0:28:11
[2023-10-11 10:52:40 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][0/6787]	eta 2:44:39 lr 0.000200	time 1.4557 (1.4557)	loss 0.3438 (0.3438)	grad_norm 455356.1875 (455356.1875)	mem 14543MB
[2023-10-11 10:54:44 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][500/6787]	eta 0:26:13 lr 0.000200	time 0.2496 (0.2502)	loss 0.3794 (0.3621)	grad_norm 349354.0312 (348277.7188)	mem 14543MB
[2023-10-11 10:56:48 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][1000/6787]	eta 0:24:02 lr 0.000200	time 0.2464 (0.2492)	loss 0.3691 (0.3619)	grad_norm 512163.8750 (414587.6875)	mem 14543MB
[2023-10-11 10:58:52 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][1500/6787]	eta 0:21:56 lr 0.000200	time 0.2564 (0.2490)	loss 0.3868 (0.3621)	grad_norm 383947.5938 (463544.0312)	mem 14543MB
[2023-10-11 11:00:57 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][2000/6787]	eta 0:19:51 lr 0.000200	time 0.2466 (0.2489)	loss 0.3638 (0.3620)	grad_norm 250414.6094 (inf)	mem 14543MB
[2023-10-11 11:03:01 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][2500/6787]	eta 0:17:46 lr 0.000200	time 0.2545 (0.2489)	loss 0.3390 (0.3623)	grad_norm 149120.5625 (inf)	mem 14543MB
[2023-10-11 11:05:06 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][3000/6787]	eta 0:15:42 lr 0.000200	time 0.2526 (0.2489)	loss 0.3642 (0.3624)	grad_norm 260623.2969 (inf)	mem 14543MB
[2023-10-11 11:07:11 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][3500/6787]	eta 0:13:38 lr 0.000200	time 0.2499 (0.2491)	loss 0.3849 (0.3625)	grad_norm 246417.0781 (inf)	mem 14543MB
[2023-10-11 11:09:16 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][4000/6787]	eta 0:11:34 lr 0.000200	time 0.2515 (0.2491)	loss 0.3563 (0.3626)	grad_norm 372839.0312 (inf)	mem 14543MB
[2023-10-11 11:11:20 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][4500/6787]	eta 0:09:29 lr 0.000200	time 0.2491 (0.2492)	loss 0.3512 (0.3625)	grad_norm 336771.3438 (inf)	mem 14543MB
[2023-10-11 11:13:25 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][5000/6787]	eta 0:07:25 lr 0.000200	time 0.2505 (0.2493)	loss 0.3544 (0.3624)	grad_norm 608553.5625 (inf)	mem 14543MB
[2023-10-11 11:15:30 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][5500/6787]	eta 0:05:20 lr 0.000200	time 0.2592 (0.2493)	loss 0.3731 (0.3624)	grad_norm 258384.6094 (inf)	mem 14543MB
[2023-10-11 11:17:35 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2536 (0.2493)	loss 0.3622 (0.3624)	grad_norm 183729.2500 (inf)	mem 14543MB
[2023-10-11 11:19:40 simmim_pretrain](main_simmim.py 218): INFO Train: [67/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2547 (0.2493)	loss 0.3247 (0.3625)	grad_norm 233729.1250 (inf)	mem 14543MB
[2023-10-11 11:20:52 simmim_pretrain](main_simmim.py 228): INFO EPOCH 67 training takes 0:28:13
[2023-10-11 11:20:53 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][0/6787]	eta 2:44:58 lr 0.000200	time 1.4584 (1.4584)	loss 0.3734 (0.3734)	grad_norm 218391.2656 (218391.2656)	mem 14543MB
[2023-10-11 11:22:58 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][500/6787]	eta 0:26:23 lr 0.000200	time 0.2456 (0.2519)	loss 0.3428 (0.3631)	grad_norm 305564.8125 (303168.0938)	mem 14543MB
[2023-10-11 11:25:03 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2591 (0.2508)	loss 0.3522 (0.3626)	grad_norm 286851.2188 (331284.9062)	mem 14543MB
[2023-10-11 11:27:08 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2527 (0.2505)	loss 0.3554 (0.3625)	grad_norm 615308.8125 (358500.2812)	mem 14543MB
[2023-10-11 11:29:13 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2484 (0.2503)	loss 0.3669 (0.3625)	grad_norm 664551.8750 (379617.9688)	mem 14543MB
[2023-10-11 11:31:18 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2596 (0.2501)	loss 0.3807 (0.3625)	grad_norm 158800.7656 (inf)	mem 14543MB
[2023-10-11 11:33:23 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2462 (0.2501)	loss 0.3644 (0.3627)	grad_norm 270241.2500 (inf)	mem 14543MB
[2023-10-11 11:35:27 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2468 (0.2500)	loss 0.3699 (0.3629)	grad_norm 259157.4375 (inf)	mem 14543MB
[2023-10-11 11:37:32 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2455 (0.2500)	loss 0.3699 (0.3630)	grad_norm 234691.3281 (inf)	mem 14543MB
[2023-10-11 11:39:37 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2459 (0.2500)	loss 0.3725 (0.3630)	grad_norm 355270.2812 (inf)	mem 14543MB
[2023-10-11 11:41:42 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2464 (0.2500)	loss 0.3569 (0.3630)	grad_norm 305011.2188 (inf)	mem 14543MB
[2023-10-11 11:43:47 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2519 (0.2499)	loss 0.3695 (0.3630)	grad_norm 280601.3750 (inf)	mem 14543MB
[2023-10-11 11:45:52 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2517 (0.2499)	loss 0.3858 (0.3630)	grad_norm 334819.2500 (inf)	mem 14543MB
[2023-10-11 11:47:56 simmim_pretrain](main_simmim.py 218): INFO Train: [68/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2488 (0.2499)	loss 0.3354 (0.3630)	grad_norm 458634.2812 (inf)	mem 14543MB
[2023-10-11 11:49:09 simmim_pretrain](main_simmim.py 228): INFO EPOCH 68 training takes 0:28:16
[2023-10-11 11:49:10 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][0/6787]	eta 2:46:54 lr 0.000200	time 1.4756 (1.4756)	loss 0.3376 (0.3376)	grad_norm 326984.8750 (326984.8750)	mem 14543MB
[2023-10-11 11:51:15 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][500/6787]	eta 0:26:23 lr 0.000200	time 0.2489 (0.2519)	loss 0.3692 (0.3630)	grad_norm 339139.3750 (inf)	mem 14543MB
[2023-10-11 11:53:20 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][1000/6787]	eta 0:24:12 lr 0.000200	time 0.2495 (0.2509)	loss 0.3601 (0.3627)	grad_norm 287679.7188 (inf)	mem 14543MB
[2023-10-11 11:55:25 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2519 (0.2506)	loss 0.3744 (0.3630)	grad_norm 275359.9375 (inf)	mem 14543MB
[2023-10-11 11:57:30 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2461 (0.2504)	loss 0.3774 (0.3628)	grad_norm 267005.1250 (inf)	mem 14543MB
[2023-10-11 11:59:34 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2532 (0.2502)	loss 0.3667 (0.3628)	grad_norm 445587.9062 (inf)	mem 14543MB
[2023-10-11 12:01:39 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2493 (0.2502)	loss 0.3638 (0.3627)	grad_norm 191623.6562 (inf)	mem 14543MB
[2023-10-11 12:03:44 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2500 (0.2502)	loss 0.3533 (0.3627)	grad_norm 283179.1875 (inf)	mem 14543MB
[2023-10-11 12:05:49 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2476 (0.2501)	loss 0.3727 (0.3627)	grad_norm 287005.5312 (inf)	mem 14543MB
[2023-10-11 12:07:54 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2481 (0.2501)	loss 0.3441 (0.3629)	grad_norm 260419.6875 (inf)	mem 14543MB
[2023-10-11 12:09:59 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2496 (0.2501)	loss 0.3788 (0.3628)	grad_norm 252886.3125 (inf)	mem 14543MB
[2023-10-11 12:12:04 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2516 (0.2501)	loss 0.3720 (0.3628)	grad_norm 431046.2188 (inf)	mem 14543MB
[2023-10-11 12:14:09 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2523 (0.2501)	loss 0.3665 (0.3627)	grad_norm 295240.2188 (inf)	mem 14543MB
[2023-10-11 12:16:14 simmim_pretrain](main_simmim.py 218): INFO Train: [69/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2463 (0.2501)	loss 0.3838 (0.3625)	grad_norm 358034.8750 (inf)	mem 14543MB
[2023-10-11 12:17:27 simmim_pretrain](main_simmim.py 228): INFO EPOCH 69 training takes 0:28:18
[2023-10-11 12:17:28 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][0/6787]	eta 2:55:12 lr 0.000200	time 1.5490 (1.5490)	loss 0.3655 (0.3655)	grad_norm 379997.3750 (379997.3750)	mem 14543MB
[2023-10-11 12:19:33 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][500/6787]	eta 0:26:25 lr 0.000200	time 0.2501 (0.2522)	loss 0.3458 (0.3645)	grad_norm 241836.0000 (290924.5625)	mem 14543MB
[2023-10-11 12:21:38 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][1000/6787]	eta 0:24:12 lr 0.000200	time 0.2478 (0.2510)	loss 0.3679 (0.3634)	grad_norm 198858.2188 (292619.5312)	mem 14543MB
[2023-10-11 12:23:43 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][1500/6787]	eta 0:22:05 lr 0.000200	time 0.2523 (0.2506)	loss 0.3650 (0.3639)	grad_norm 248836.2031 (293684.5938)	mem 14543MB
[2023-10-11 12:25:48 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2516 (0.2504)	loss 0.3665 (0.3634)	grad_norm 403359.8438 (346234.5938)	mem 14543MB
[2023-10-11 12:27:53 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][2500/6787]	eta 0:17:53 lr 0.000200	time 0.2492 (0.2503)	loss 0.3832 (0.3632)	grad_norm 183216.5312 (362120.5000)	mem 14543MB
[2023-10-11 12:29:58 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2467 (0.2503)	loss 0.3655 (0.3630)	grad_norm 340075.1250 (inf)	mem 14543MB
[2023-10-11 12:32:03 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2526 (0.2502)	loss 0.3470 (0.3632)	grad_norm 477674.0625 (inf)	mem 14543MB
[2023-10-11 12:34:08 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2484 (0.2502)	loss 0.3536 (0.3631)	grad_norm 222605.5938 (inf)	mem 14543MB
[2023-10-11 12:36:13 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2517 (0.2502)	loss 0.3599 (0.3630)	grad_norm 337199.7812 (inf)	mem 14543MB
[2023-10-11 12:38:18 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2482 (0.2502)	loss 0.3541 (0.3630)	grad_norm 366515.6250 (inf)	mem 14543MB
[2023-10-11 12:40:23 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2463 (0.2501)	loss 0.3852 (0.3630)	grad_norm 438358.9062 (inf)	mem 14543MB
[2023-10-11 12:42:28 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2500 (0.2501)	loss 0.3463 (0.3629)	grad_norm 425843.0938 (inf)	mem 14543MB
[2023-10-11 12:44:33 simmim_pretrain](main_simmim.py 218): INFO Train: [70/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2494 (0.2501)	loss 0.5558 (0.3640)	grad_norm 16006.6729 (inf)	mem 14543MB
[2023-10-11 12:45:45 simmim_pretrain](main_simmim.py 228): INFO EPOCH 70 training takes 0:28:17
[2023-10-11 12:45:46 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][0/6787]	eta 3:00:56 lr 0.000200	time 1.5996 (1.5996)	loss 0.4845 (0.4845)	grad_norm 17869.7910 (17869.7910)	mem 14543MB
[2023-10-11 12:47:51 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][500/6787]	eta 0:26:24 lr 0.000200	time 0.2475 (0.2520)	loss 0.4192 (0.4687)	grad_norm 71428.1094 (47209.5977)	mem 14543MB
[2023-10-11 12:49:56 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2485 (0.2508)	loss 0.3748 (0.4274)	grad_norm 35970.5273 (44199.7617)	mem 14543MB
[2023-10-11 12:52:01 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2548 (0.2505)	loss 0.3567 (0.4093)	grad_norm 24828.1074 (40550.5078)	mem 14543MB
[2023-10-11 12:54:05 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2469 (0.2503)	loss 0.3760 (0.3992)	grad_norm 43446.0703 (40208.3281)	mem 14543MB
[2023-10-11 12:56:10 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2465 (0.2502)	loss 0.3934 (0.3927)	grad_norm 68785.9688 (42080.1523)	mem 14543MB
[2023-10-11 12:58:15 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2448 (0.2501)	loss 0.3601 (0.3883)	grad_norm 51108.8906 (44841.0234)	mem 14543MB
[2023-10-11 13:00:20 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2484 (0.2500)	loss 0.3635 (0.3851)	grad_norm 54616.0352 (46022.2930)	mem 14543MB
[2023-10-11 13:02:25 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2482 (0.2500)	loss 0.3467 (0.3828)	grad_norm 110293.1016 (48538.6172)	mem 14543MB
[2023-10-11 13:04:30 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2532 (0.2500)	loss 0.3648 (0.3807)	grad_norm 121720.9609 (52467.9844)	mem 14543MB
[2023-10-11 13:06:34 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2463 (0.2499)	loss 0.3804 (0.3790)	grad_norm 52323.6992 (56691.4531)	mem 14543MB
[2023-10-11 13:08:39 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2500 (0.2498)	loss 0.3665 (0.3776)	grad_norm 74710.8516 (60506.1133)	mem 14543MB
[2023-10-11 13:10:43 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2496 (0.2498)	loss 0.3732 (0.3764)	grad_norm 128692.6875 (66529.7109)	mem 14543MB
[2023-10-11 13:12:48 simmim_pretrain](main_simmim.py 218): INFO Train: [71/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2502 (0.2498)	loss 0.3521 (0.3753)	grad_norm 196150.9531 (72503.0625)	mem 14543MB
[2023-10-11 13:14:00 simmim_pretrain](main_simmim.py 228): INFO EPOCH 71 training takes 0:28:15
[2023-10-11 13:14:02 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][0/6787]	eta 2:51:26 lr 0.000200	time 1.5156 (1.5156)	loss 0.3558 (0.3558)	grad_norm 125773.7266 (125773.7266)	mem 14543MB
[2023-10-11 13:16:07 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][500/6787]	eta 0:26:25 lr 0.000200	time 0.2576 (0.2522)	loss 0.3832 (0.3619)	grad_norm 137979.9688 (182666.3594)	mem 14543MB
[2023-10-11 13:18:12 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2500 (0.2509)	loss 0.3589 (0.3622)	grad_norm 172224.1250 (199330.5469)	mem 14543MB
[2023-10-11 13:20:17 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2550 (0.2506)	loss 0.3438 (0.3615)	grad_norm 447376.9062 (245628.9531)	mem 14543MB
[2023-10-11 13:22:22 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2496 (0.2504)	loss 0.3485 (0.3612)	grad_norm 164869.8125 (273051.0938)	mem 14543MB
[2023-10-11 13:24:27 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][2500/6787]	eta 0:17:53 lr 0.000200	time 0.2474 (0.2503)	loss 0.3672 (0.3611)	grad_norm 458103.4062 (312458.3750)	mem 14543MB
[2023-10-11 13:26:32 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2455 (0.2503)	loss 0.3961 (0.3611)	grad_norm 334672.4688 (321120.7500)	mem 14543MB
[2023-10-11 13:28:37 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2546 (0.2502)	loss 0.3627 (0.3610)	grad_norm 455840.0312 (342745.6250)	mem 14543MB
[2023-10-11 13:30:42 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2516 (0.2502)	loss 0.3711 (0.3611)	grad_norm 275151.7500 (inf)	mem 14543MB
[2023-10-11 13:32:47 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2538 (0.2502)	loss 0.3518 (0.3612)	grad_norm 230955.5625 (inf)	mem 14543MB
[2023-10-11 13:34:52 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2515 (0.2502)	loss 0.3756 (0.3614)	grad_norm 113382.4375 (inf)	mem 14543MB
[2023-10-11 13:36:57 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2464 (0.2502)	loss 0.3721 (0.3617)	grad_norm 202803.6406 (inf)	mem 14543MB
[2023-10-11 13:39:02 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2514 (0.2502)	loss 0.3502 (0.3617)	grad_norm 164396.1094 (inf)	mem 14543MB
[2023-10-11 13:41:07 simmim_pretrain](main_simmim.py 218): INFO Train: [72/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2455 (0.2502)	loss 0.3586 (0.3617)	grad_norm 372818.0000 (inf)	mem 14543MB
[2023-10-11 13:42:19 simmim_pretrain](main_simmim.py 228): INFO EPOCH 72 training takes 0:28:18
[2023-10-11 13:42:20 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][0/6787]	eta 2:51:43 lr 0.000200	time 1.5182 (1.5182)	loss 0.3679 (0.3679)	grad_norm 403169.1250 (403169.1250)	mem 14543MB
[2023-10-11 13:44:25 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][500/6787]	eta 0:26:19 lr 0.000200	time 0.2459 (0.2512)	loss 0.3514 (0.3614)	grad_norm 358541.9688 (354899.9375)	mem 14543MB
[2023-10-11 13:46:29 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][1000/6787]	eta 0:24:08 lr 0.000200	time 0.2499 (0.2502)	loss 0.3513 (0.3611)	grad_norm 309928.3125 (368312.7500)	mem 14543MB
[2023-10-11 13:48:34 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][1500/6787]	eta 0:22:01 lr 0.000200	time 0.2463 (0.2499)	loss 0.3622 (0.3611)	grad_norm 474251.8750 (inf)	mem 14543MB
[2023-10-11 13:50:39 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][2000/6787]	eta 0:19:56 lr 0.000200	time 0.2446 (0.2498)	loss 0.3790 (0.3612)	grad_norm 607006.0625 (inf)	mem 14543MB
[2023-10-11 13:52:44 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][2500/6787]	eta 0:17:51 lr 0.000200	time 0.2465 (0.2498)	loss 0.3406 (0.3610)	grad_norm 487118.5625 (inf)	mem 14543MB
[2023-10-11 13:54:49 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][3000/6787]	eta 0:15:46 lr 0.000200	time 0.2529 (0.2498)	loss 0.3560 (0.3611)	grad_norm 320547.8125 (inf)	mem 14543MB
[2023-10-11 13:56:54 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2462 (0.2499)	loss 0.3710 (0.3611)	grad_norm 330880.5625 (inf)	mem 14543MB
[2023-10-11 13:58:59 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2487 (0.2499)	loss 0.3595 (0.3612)	grad_norm 297180.5000 (inf)	mem 14543MB
[2023-10-11 14:01:03 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2498 (0.2498)	loss 0.3578 (0.3614)	grad_norm 346602.9062 (inf)	mem 14543MB
[2023-10-11 14:03:08 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2470 (0.2498)	loss 0.3749 (0.3615)	grad_norm 308222.3438 (inf)	mem 14543MB
[2023-10-11 14:05:13 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2469 (0.2498)	loss 0.3708 (0.3614)	grad_norm 141277.2344 (inf)	mem 14543MB
[2023-10-11 14:07:18 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2520 (0.2498)	loss 0.3703 (0.3614)	grad_norm 304034.0000 (inf)	mem 14543MB
[2023-10-11 14:09:23 simmim_pretrain](main_simmim.py 218): INFO Train: [73/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2463 (0.2498)	loss 0.3370 (0.3617)	grad_norm 178278.9375 (inf)	mem 14543MB
[2023-10-11 14:10:35 simmim_pretrain](main_simmim.py 228): INFO EPOCH 73 training takes 0:28:16
[2023-10-11 14:10:37 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][0/6787]	eta 2:51:53 lr 0.000200	time 1.5196 (1.5196)	loss 0.3592 (0.3592)	grad_norm 235316.8281 (235316.8281)	mem 14543MB
[2023-10-11 14:12:41 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][500/6787]	eta 0:26:23 lr 0.000200	time 0.2501 (0.2519)	loss 0.3644 (0.3642)	grad_norm 147381.8281 (135425.0625)	mem 14543MB
[2023-10-11 14:14:46 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2467 (0.2509)	loss 0.3613 (0.3641)	grad_norm 91527.8516 (130933.0547)	mem 14543MB
[2023-10-11 14:16:51 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2453 (0.2505)	loss 0.3784 (0.3643)	grad_norm 211484.9688 (130610.3516)	mem 14543MB
[2023-10-11 14:18:56 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2489 (0.2504)	loss 0.3523 (0.3640)	grad_norm 190343.1406 (143885.9219)	mem 14543MB
[2023-10-11 14:21:01 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2468 (0.2503)	loss 0.3489 (0.3636)	grad_norm 287275.7188 (160661.9062)	mem 14543MB
[2023-10-11 14:23:06 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2482 (0.2503)	loss 0.3685 (0.3633)	grad_norm 210228.7812 (166119.8281)	mem 14543MB
[2023-10-11 14:25:11 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2468 (0.2502)	loss 0.3684 (0.3634)	grad_norm 177964.5312 (171908.0000)	mem 14543MB
[2023-10-11 14:27:16 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2500 (0.2502)	loss 0.3702 (0.3631)	grad_norm 448338.3125 (184502.0312)	mem 14543MB
[2023-10-11 14:29:21 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2509 (0.2501)	loss 0.3485 (0.3628)	grad_norm 389904.9375 (201466.6719)	mem 14543MB
[2023-10-11 14:31:26 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2487 (0.2501)	loss 0.3738 (0.3627)	grad_norm 589308.5000 (217718.3750)	mem 14543MB
[2023-10-11 14:33:31 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2469 (0.2501)	loss 0.3685 (0.3627)	grad_norm 362302.9688 (inf)	mem 14543MB
[2023-10-11 14:35:36 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2499 (0.2501)	loss 0.3837 (0.3625)	grad_norm 462494.1250 (inf)	mem 14543MB
[2023-10-11 14:37:41 simmim_pretrain](main_simmim.py 218): INFO Train: [74/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2487 (0.2501)	loss 0.3586 (0.3623)	grad_norm 214753.9531 (inf)	mem 14543MB
[2023-10-11 14:38:53 simmim_pretrain](main_simmim.py 228): INFO EPOCH 74 training takes 0:28:18
[2023-10-11 14:38:55 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][0/6787]	eta 2:49:56 lr 0.000200	time 1.5023 (1.5023)	loss 0.3743 (0.3743)	grad_norm 473136.8438 (473136.8438)	mem 14543MB
[2023-10-11 14:41:00 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][500/6787]	eta 0:26:24 lr 0.000200	time 0.2530 (0.2519)	loss 0.3643 (0.3612)	grad_norm 401562.3438 (498453.3750)	mem 14543MB
[2023-10-11 14:43:05 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][1000/6787]	eta 0:24:12 lr 0.000200	time 0.2492 (0.2509)	loss 0.3621 (0.3613)	grad_norm 355571.7812 (inf)	mem 14543MB
[2023-10-11 14:45:10 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2489 (0.2506)	loss 0.3686 (0.3616)	grad_norm 374324.2500 (inf)	mem 14543MB
[2023-10-11 14:47:15 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2504 (0.2505)	loss 0.3440 (0.3618)	grad_norm 224979.5312 (inf)	mem 14543MB
[2023-10-11 14:49:19 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2508 (0.2503)	loss 0.3786 (0.3620)	grad_norm 132924.9219 (inf)	mem 14543MB
[2023-10-11 14:51:24 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2468 (0.2503)	loss 0.3687 (0.3621)	grad_norm 161180.7188 (inf)	mem 14543MB
[2023-10-11 14:53:30 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2582 (0.2502)	loss 0.3826 (0.3620)	grad_norm 627796.8125 (inf)	mem 14543MB
[2023-10-11 14:55:34 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2449 (0.2502)	loss 0.3509 (0.3619)	grad_norm 363978.8438 (inf)	mem 14543MB
[2023-10-11 14:57:39 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2460 (0.2502)	loss 0.3666 (0.3620)	grad_norm 219696.4219 (inf)	mem 14543MB
[2023-10-11 14:59:44 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2466 (0.2502)	loss 0.3493 (0.3619)	grad_norm 174469.9375 (inf)	mem 14543MB
[2023-10-11 15:01:49 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2589 (0.2501)	loss 0.3502 (0.3619)	grad_norm 237777.6875 (inf)	mem 14543MB
[2023-10-11 15:03:54 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2489 (0.2501)	loss 0.3609 (0.3619)	grad_norm 240592.1250 (inf)	mem 14543MB
[2023-10-11 15:05:59 simmim_pretrain](main_simmim.py 218): INFO Train: [75/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2515 (0.2501)	loss 0.3725 (0.3618)	grad_norm 801763.3750 (inf)	mem 14543MB
[2023-10-11 15:07:12 simmim_pretrain](main_simmim.py 228): INFO EPOCH 75 training takes 0:28:18
[2023-10-11 15:07:13 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][0/6787]	eta 2:58:29 lr 0.000200	time 1.5780 (1.5780)	loss 0.3845 (0.3845)	grad_norm 392027.3438 (392027.3438)	mem 14543MB
[2023-10-11 15:09:18 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][500/6787]	eta 0:26:24 lr 0.000200	time 0.2538 (0.2521)	loss 0.3667 (0.3606)	grad_norm 292784.3750 (387393.4688)	mem 14543MB
[2023-10-11 15:11:23 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][1000/6787]	eta 0:24:12 lr 0.000200	time 0.2473 (0.2509)	loss 0.3499 (0.3613)	grad_norm 184588.2656 (inf)	mem 14543MB
[2023-10-11 15:13:28 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2499 (0.2505)	loss 0.3435 (0.3616)	grad_norm 166362.0312 (inf)	mem 14543MB
[2023-10-11 15:15:33 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2532 (0.2503)	loss 0.3577 (0.3616)	grad_norm 220921.1094 (inf)	mem 14543MB
[2023-10-11 15:17:38 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2529 (0.2502)	loss 0.3761 (0.3617)	grad_norm 278814.4688 (inf)	mem 14543MB
[2023-10-11 15:19:43 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2559 (0.2502)	loss 0.3649 (0.3618)	grad_norm 548531.9375 (inf)	mem 14543MB
[2023-10-11 15:21:47 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2506 (0.2501)	loss 0.3596 (0.3619)	grad_norm 196466.1094 (inf)	mem 14543MB
[2023-10-11 15:23:52 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2468 (0.2501)	loss 0.3490 (0.3621)	grad_norm 236983.8281 (inf)	mem 14543MB
[2023-10-11 15:25:57 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2493 (0.2500)	loss 0.3691 (0.3621)	grad_norm 183180.9531 (inf)	mem 14543MB
[2023-10-11 15:28:02 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2472 (0.2500)	loss 0.3562 (0.3622)	grad_norm 276836.8438 (inf)	mem 14543MB
[2023-10-11 15:30:07 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2479 (0.2500)	loss 0.3625 (0.3621)	grad_norm 195489.7031 (inf)	mem 14543MB
[2023-10-11 15:32:12 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2506 (0.2500)	loss 0.3577 (0.3621)	grad_norm 350405.1250 (inf)	mem 14543MB
[2023-10-11 15:34:17 simmim_pretrain](main_simmim.py 218): INFO Train: [76/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2529 (0.2500)	loss 0.3712 (0.3621)	grad_norm 190940.9375 (inf)	mem 14543MB
[2023-10-11 15:35:29 simmim_pretrain](main_simmim.py 228): INFO EPOCH 76 training takes 0:28:17
[2023-10-11 15:35:31 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][0/6787]	eta 3:01:30 lr 0.000200	time 1.6046 (1.6046)	loss 0.3636 (0.3636)	grad_norm 181944.9688 (181944.9688)	mem 14543MB
[2023-10-11 15:37:36 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][500/6787]	eta 0:26:25 lr 0.000200	time 0.2520 (0.2521)	loss 0.3796 (0.3618)	grad_norm 189700.7812 (nan)	mem 14543MB
[2023-10-11 15:39:40 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2547 (0.2508)	loss 0.3549 (0.3621)	grad_norm 240478.3594 (nan)	mem 14543MB
[2023-10-11 15:41:45 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2499 (0.2505)	loss 0.3316 (0.3623)	grad_norm 131342.3906 (nan)	mem 14543MB
[2023-10-11 15:43:50 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][2000/6787]	eta 0:19:58 lr 0.000200	time 0.2473 (0.2504)	loss 0.3599 (0.3622)	grad_norm 176176.1406 (nan)	mem 14543MB
[2023-10-11 15:45:55 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2463 (0.2503)	loss 0.3551 (0.3621)	grad_norm 196923.6250 (nan)	mem 14543MB
[2023-10-11 15:48:00 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2537 (0.2502)	loss 0.3863 (0.3617)	grad_norm 781097.8125 (nan)	mem 14543MB
[2023-10-11 15:50:05 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2472 (0.2502)	loss 0.3788 (0.3616)	grad_norm 429625.0000 (nan)	mem 14543MB
[2023-10-11 15:52:10 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2477 (0.2502)	loss 0.3408 (0.3615)	grad_norm 366762.7812 (nan)	mem 14543MB
[2023-10-11 15:54:15 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2521 (0.2502)	loss 0.3799 (0.3617)	grad_norm 168418.0938 (nan)	mem 14543MB
[2023-10-11 15:56:20 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2461 (0.2501)	loss 0.3514 (0.3620)	grad_norm 160842.2031 (nan)	mem 14543MB
[2023-10-11 15:58:25 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][5500/6787]	eta 0:05:21 lr 0.000200	time 0.2466 (0.2500)	loss 0.3614 (0.3622)	grad_norm 74557.4062 (nan)	mem 14543MB
[2023-10-11 16:00:29 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2482 (0.2499)	loss 0.3413 (0.3625)	grad_norm 72795.3281 (nan)	mem 14543MB
[2023-10-11 16:02:33 simmim_pretrain](main_simmim.py 218): INFO Train: [77/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2488 (0.2498)	loss 0.3692 (0.3626)	grad_norm 208724.7188 (nan)	mem 14543MB
[2023-10-11 16:03:45 simmim_pretrain](main_simmim.py 228): INFO EPOCH 77 training takes 0:28:16
[2023-10-11 16:03:47 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][0/6787]	eta 2:39:15 lr 0.000200	time 1.4079 (1.4079)	loss 0.3440 (0.3440)	grad_norm 234052.7656 (234052.7656)	mem 14543MB
[2023-10-11 16:05:51 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][500/6787]	eta 0:26:22 lr 0.000200	time 0.2493 (0.2517)	loss 0.3596 (0.3609)	grad_norm 225183.4375 (201117.8125)	mem 14543MB
[2023-10-11 16:07:57 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][1000/6787]	eta 0:24:15 lr 0.000200	time 0.2542 (0.2516)	loss 0.3324 (0.3614)	grad_norm 243454.3906 (214886.5156)	mem 14543MB
[2023-10-11 16:10:04 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][1500/6787]	eta 0:22:12 lr 0.000200	time 0.2487 (0.2521)	loss 0.3631 (0.3613)	grad_norm 205800.1094 (225255.0000)	mem 14543MB
[2023-10-11 16:12:11 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][2000/6787]	eta 0:20:09 lr 0.000200	time 0.2551 (0.2526)	loss 0.3501 (0.3612)	grad_norm 332029.8125 (243493.6094)	mem 14543MB
[2023-10-11 16:14:19 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][2500/6787]	eta 0:18:06 lr 0.000200	time 0.2589 (0.2534)	loss 0.3330 (0.3613)	grad_norm 560723.2500 (273898.3125)	mem 14543MB
[2023-10-11 16:16:27 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][3000/6787]	eta 0:16:00 lr 0.000200	time 0.2519 (0.2537)	loss 0.3506 (0.3612)	grad_norm 176057.0625 (292745.9062)	mem 14543MB
[2023-10-11 16:18:35 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][3500/6787]	eta 0:13:55 lr 0.000200	time 0.2577 (0.2541)	loss 0.3642 (0.3610)	grad_norm 426102.3438 (311127.1562)	mem 14543MB
[2023-10-11 16:20:43 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][4000/6787]	eta 0:11:49 lr 0.000200	time 0.2540 (0.2545)	loss 0.3668 (0.3611)	grad_norm 453320.5000 (inf)	mem 14543MB
[2023-10-11 16:22:52 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][4500/6787]	eta 0:09:42 lr 0.000200	time 0.2584 (0.2547)	loss 0.3489 (0.3614)	grad_norm 162307.7500 (inf)	mem 14543MB
[2023-10-11 16:25:00 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][5000/6787]	eta 0:07:35 lr 0.000200	time 0.2564 (0.2549)	loss 0.3603 (0.3615)	grad_norm 173276.1094 (inf)	mem 14543MB
[2023-10-11 16:27:10 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][5500/6787]	eta 0:05:28 lr 0.000200	time 0.2601 (0.2553)	loss 0.3583 (0.3615)	grad_norm 251165.3125 (inf)	mem 14543MB
[2023-10-11 16:29:20 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2543 (0.2557)	loss 0.3738 (0.3615)	grad_norm 341415.2500 (inf)	mem 14543MB
[2023-10-11 16:31:30 simmim_pretrain](main_simmim.py 218): INFO Train: [78/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2512 (0.2560)	loss 0.3524 (0.3615)	grad_norm 320658.1250 (inf)	mem 14543MB
[2023-10-11 16:32:45 simmim_pretrain](main_simmim.py 228): INFO EPOCH 78 training takes 0:28:59
[2023-10-11 16:32:47 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][0/6787]	eta 2:58:46 lr 0.000200	time 1.5805 (1.5805)	loss 0.3542 (0.3542)	grad_norm 284096.3125 (284096.3125)	mem 14543MB
[2023-10-11 16:34:53 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][500/6787]	eta 0:26:40 lr 0.000200	time 0.2592 (0.2546)	loss 0.3562 (0.3602)	grad_norm 598060.8125 (441873.5312)	mem 14543MB
[2023-10-11 16:36:59 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][1000/6787]	eta 0:24:26 lr 0.000200	time 0.2484 (0.2534)	loss 0.3736 (0.3604)	grad_norm 376229.7188 (inf)	mem 14543MB
[2023-10-11 16:39:05 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][1500/6787]	eta 0:22:17 lr 0.000200	time 0.2519 (0.2530)	loss 0.3801 (0.3607)	grad_norm 369283.5312 (inf)	mem 14543MB
[2023-10-11 16:41:12 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][2000/6787]	eta 0:20:13 lr 0.000200	time 0.2545 (0.2535)	loss 0.3681 (0.3610)	grad_norm 221120.5469 (inf)	mem 14543MB
[2023-10-11 16:43:19 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][2500/6787]	eta 0:18:07 lr 0.000200	time 0.2511 (0.2536)	loss 0.3588 (0.3612)	grad_norm 348191.0938 (inf)	mem 14543MB
[2023-10-11 16:45:26 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][3000/6787]	eta 0:15:59 lr 0.000200	time 0.2567 (0.2534)	loss 0.3691 (0.3613)	grad_norm 258462.2188 (inf)	mem 14543MB
[2023-10-11 16:47:32 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][3500/6787]	eta 0:13:52 lr 0.000200	time 0.2536 (0.2533)	loss 0.3645 (0.3610)	grad_norm 322938.9688 (inf)	mem 14543MB
[2023-10-11 16:49:38 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][4000/6787]	eta 0:11:45 lr 0.000200	time 0.2478 (0.2532)	loss 0.3653 (0.3613)	grad_norm 166447.4531 (inf)	mem 14543MB
[2023-10-11 16:51:45 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][4500/6787]	eta 0:09:39 lr 0.000200	time 0.2506 (0.2533)	loss 0.3666 (0.3615)	grad_norm 354756.0625 (inf)	mem 14543MB
[2023-10-11 16:53:51 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][5000/6787]	eta 0:07:32 lr 0.000200	time 0.2529 (0.2532)	loss 0.3596 (0.3616)	grad_norm 384136.1875 (inf)	mem 14543MB
[2023-10-11 16:55:58 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2511 (0.2532)	loss 0.3690 (0.3617)	grad_norm 499219.9688 (inf)	mem 14543MB
[2023-10-11 16:58:04 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2516 (0.2531)	loss 0.3602 (0.3615)	grad_norm 352363.7500 (inf)	mem 14543MB
[2023-10-11 17:00:10 simmim_pretrain](main_simmim.py 218): INFO Train: [79/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2600 (0.2531)	loss 0.3549 (0.3615)	grad_norm 362080.4688 (inf)	mem 14543MB
[2023-10-11 17:01:24 simmim_pretrain](main_simmim.py 228): INFO EPOCH 79 training takes 0:28:38
[2023-10-11 17:01:25 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][0/6787]	eta 2:49:58 lr 0.000200	time 1.5027 (1.5027)	loss 0.3561 (0.3561)	grad_norm 392068.9062 (392068.9062)	mem 14543MB
[2023-10-11 17:03:31 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][500/6787]	eta 0:26:40 lr 0.000200	time 0.2542 (0.2546)	loss 0.3543 (0.3606)	grad_norm 386334.5625 (inf)	mem 14543MB
[2023-10-11 17:05:38 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][1000/6787]	eta 0:24:29 lr 0.000200	time 0.2489 (0.2538)	loss 0.4944 (0.4158)	grad_norm 41777.4336 (inf)	mem 14543MB
[2023-10-11 17:07:46 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][1500/6787]	eta 0:22:27 lr 0.000200	time 0.2578 (0.2549)	loss 0.3775 (0.4177)	grad_norm 29608.2852 (inf)	mem 14543MB
[2023-10-11 17:09:56 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][2000/6787]	eta 0:20:25 lr 0.000200	time 0.2609 (0.2559)	loss 0.3715 (0.4066)	grad_norm 34911.1953 (inf)	mem 14543MB
[2023-10-11 17:12:05 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][2500/6787]	eta 0:18:19 lr 0.000200	time 0.2522 (0.2564)	loss 0.3555 (0.3991)	grad_norm 30530.7637 (inf)	mem 14543MB
[2023-10-11 17:14:13 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][3000/6787]	eta 0:16:11 lr 0.000200	time 0.2571 (0.2565)	loss 0.3648 (0.3939)	grad_norm 49212.6211 (inf)	mem 14543MB
[2023-10-11 17:16:22 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][3500/6787]	eta 0:14:03 lr 0.000200	time 0.2583 (0.2567)	loss 0.3896 (0.3898)	grad_norm 43617.4805 (inf)	mem 14543MB
[2023-10-11 17:18:31 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][4000/6787]	eta 0:11:55 lr 0.000200	time 0.2573 (0.2567)	loss 0.3550 (0.3868)	grad_norm 53002.8789 (inf)	mem 14543MB
[2023-10-11 17:20:38 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][4500/6787]	eta 0:09:46 lr 0.000200	time 0.2511 (0.2564)	loss 0.3633 (0.3843)	grad_norm 44977.1523 (inf)	mem 14543MB
[2023-10-11 17:22:44 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][5000/6787]	eta 0:07:37 lr 0.000200	time 0.2477 (0.2561)	loss 0.3480 (0.3823)	grad_norm 46885.5469 (inf)	mem 14543MB
[2023-10-11 17:24:52 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][5500/6787]	eta 0:05:29 lr 0.000200	time 0.2513 (0.2560)	loss 0.3505 (0.3804)	grad_norm 72134.4531 (inf)	mem 14543MB
[2023-10-11 17:27:00 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2508 (0.2559)	loss 0.3730 (0.3790)	grad_norm 192133.0469 (inf)	mem 14543MB
[2023-10-11 17:29:07 simmim_pretrain](main_simmim.py 218): INFO Train: [80/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2571 (0.2558)	loss 0.3550 (0.3778)	grad_norm 133953.7812 (inf)	mem 14543MB
[2023-10-11 17:30:22 simmim_pretrain](main_simmim.py 228): INFO EPOCH 80 training takes 0:28:58
[2023-10-11 17:30:22 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_80.pth saving......
[2023-10-11 17:30:23 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_80.pth saved !!!
[2023-10-11 17:30:24 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][0/6787]	eta 2:48:38 lr 0.000200	time 1.4909 (1.4909)	loss 0.3771 (0.3771)	grad_norm 214235.6719 (214235.6719)	mem 14543MB
[2023-10-11 17:32:31 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][500/6787]	eta 0:26:55 lr 0.000200	time 0.2536 (0.2569)	loss 0.3627 (0.3618)	grad_norm 281367.5625 (138115.6875)	mem 14543MB
[2023-10-11 17:34:39 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][1000/6787]	eta 0:24:43 lr 0.000200	time 0.2565 (0.2563)	loss 0.3433 (0.3618)	grad_norm 121110.8594 (144462.2812)	mem 14543MB
[2023-10-11 17:36:47 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][1500/6787]	eta 0:22:33 lr 0.000200	time 0.2591 (0.2561)	loss 0.3675 (0.3615)	grad_norm 192743.3750 (167388.7969)	mem 14543MB
[2023-10-11 17:38:54 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][2000/6787]	eta 0:20:24 lr 0.000200	time 0.2534 (0.2557)	loss 0.3458 (0.3615)	grad_norm 216679.9688 (169846.1562)	mem 14543MB
[2023-10-11 17:41:03 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][2500/6787]	eta 0:18:18 lr 0.000200	time 0.2609 (0.2563)	loss 0.3658 (0.3613)	grad_norm 210193.6250 (188988.0156)	mem 14543MB
[2023-10-11 17:43:14 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][3000/6787]	eta 0:16:13 lr 0.000200	time 0.2609 (0.2569)	loss 0.3578 (0.3612)	grad_norm 224940.8750 (202727.4219)	mem 14543MB
[2023-10-11 17:45:24 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][3500/6787]	eta 0:14:06 lr 0.000200	time 0.2610 (0.2574)	loss 0.3432 (0.3611)	grad_norm 385088.5000 (219961.5938)	mem 14543MB
[2023-10-11 17:47:34 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][4000/6787]	eta 0:11:58 lr 0.000200	time 0.2607 (0.2578)	loss 0.3515 (0.3608)	grad_norm 248427.4375 (234672.3750)	mem 14543MB
[2023-10-11 17:49:44 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][4500/6787]	eta 0:09:50 lr 0.000200	time 0.2610 (0.2581)	loss 0.3676 (0.3608)	grad_norm 588371.0000 (inf)	mem 14543MB
[2023-10-11 17:51:52 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][5000/6787]	eta 0:07:40 lr 0.000200	time 0.2614 (0.2578)	loss 0.3413 (0.3606)	grad_norm 172051.9375 (inf)	mem 14543MB
[2023-10-11 17:54:00 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][5500/6787]	eta 0:05:31 lr 0.000200	time 0.2612 (0.2577)	loss 0.3598 (0.3605)	grad_norm 481040.5312 (inf)	mem 14543MB
[2023-10-11 17:56:08 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2521 (0.2576)	loss 0.3589 (0.3605)	grad_norm 402359.4375 (inf)	mem 14543MB
[2023-10-11 17:58:15 simmim_pretrain](main_simmim.py 218): INFO Train: [81/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2574 (0.2573)	loss 0.3493 (0.3604)	grad_norm 186054.0469 (inf)	mem 14543MB
[2023-10-11 17:59:29 simmim_pretrain](main_simmim.py 228): INFO EPOCH 81 training takes 0:29:06
[2023-10-11 17:59:30 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][0/6787]	eta 2:57:24 lr 0.000200	time 1.5684 (1.5684)	loss 0.3604 (0.3604)	grad_norm 511990.7500 (511990.7500)	mem 14543MB
[2023-10-11 18:01:38 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][500/6787]	eta 0:27:00 lr 0.000200	time 0.2607 (0.2577)	loss 0.3459 (0.3604)	grad_norm 247524.6094 (inf)	mem 14543MB
[2023-10-11 18:03:48 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][1000/6787]	eta 0:24:58 lr 0.000200	time 0.2607 (0.2589)	loss 0.3563 (0.3606)	grad_norm 138009.5312 (inf)	mem 14543MB
[2023-10-11 18:05:58 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][1500/6787]	eta 0:22:50 lr 0.000200	time 0.2604 (0.2593)	loss 0.3378 (0.3610)	grad_norm 162408.1406 (inf)	mem 14543MB
[2023-10-11 18:08:08 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][2000/6787]	eta 0:20:42 lr 0.000200	time 0.2608 (0.2595)	loss 0.3687 (0.3619)	grad_norm 86026.9688 (inf)	mem 14543MB
[2023-10-11 18:10:18 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][2500/6787]	eta 0:18:32 lr 0.000200	time 0.2605 (0.2596)	loss 0.3531 (0.3621)	grad_norm 142472.1250 (inf)	mem 14543MB
[2023-10-11 18:12:28 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][3000/6787]	eta 0:16:23 lr 0.000200	time 0.2611 (0.2597)	loss 0.3376 (0.3621)	grad_norm 96795.3359 (inf)	mem 14543MB
[2023-10-11 18:14:38 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][3500/6787]	eta 0:14:13 lr 0.000200	time 0.2625 (0.2598)	loss 0.3624 (0.3623)	grad_norm 117470.1875 (inf)	mem 14543MB
[2023-10-11 18:16:48 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][4000/6787]	eta 0:12:04 lr 0.000200	time 0.2615 (0.2598)	loss 0.3521 (0.3623)	grad_norm 137257.2812 (inf)	mem 14543MB
[2023-10-11 18:18:58 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][4500/6787]	eta 0:09:54 lr 0.000200	time 0.2612 (0.2599)	loss 0.3631 (0.3622)	grad_norm 346034.4062 (inf)	mem 14543MB
[2023-10-11 18:21:09 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][5000/6787]	eta 0:07:44 lr 0.000200	time 0.2611 (0.2600)	loss 0.3672 (0.3621)	grad_norm 239760.8906 (inf)	mem 14543MB
[2023-10-11 18:23:19 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][5500/6787]	eta 0:05:34 lr 0.000200	time 0.2610 (0.2600)	loss 0.3961 (0.3621)	grad_norm 140626.7812 (inf)	mem 14543MB
[2023-10-11 18:25:29 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][6000/6787]	eta 0:03:24 lr 0.000200	time 0.2611 (0.2600)	loss 0.3755 (0.3620)	grad_norm 170600.2188 (inf)	mem 14543MB
[2023-10-11 18:27:39 simmim_pretrain](main_simmim.py 218): INFO Train: [82/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2602 (0.2601)	loss 0.3622 (0.3618)	grad_norm 550202.6250 (inf)	mem 14543MB
[2023-10-11 18:28:55 simmim_pretrain](main_simmim.py 228): INFO EPOCH 82 training takes 0:29:26
[2023-10-11 18:28:56 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][0/6787]	eta 2:48:42 lr 0.000200	time 1.4914 (1.4914)	loss 0.3392 (0.3392)	grad_norm 215142.2188 (215142.2188)	mem 14543MB
[2023-10-11 18:31:03 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][500/6787]	eta 0:26:56 lr 0.000200	time 0.2585 (0.2572)	loss 0.3776 (0.3601)	grad_norm 395189.3750 (380096.2188)	mem 14543MB
[2023-10-11 18:33:11 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][1000/6787]	eta 0:24:43 lr 0.000200	time 0.2471 (0.2563)	loss 0.3595 (0.3602)	grad_norm 392986.3438 (380368.7188)	mem 14543MB
[2023-10-11 18:35:18 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][1500/6787]	eta 0:22:31 lr 0.000200	time 0.2552 (0.2557)	loss 0.3519 (0.3599)	grad_norm 473086.0000 (inf)	mem 14543MB
[2023-10-11 18:37:26 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][2000/6787]	eta 0:20:23 lr 0.000200	time 0.2553 (0.2557)	loss 0.3864 (0.3597)	grad_norm 414694.6250 (inf)	mem 14543MB
[2023-10-11 18:39:34 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][2500/6787]	eta 0:18:16 lr 0.000200	time 0.2553 (0.2557)	loss 0.3424 (0.3596)	grad_norm 778571.1250 (inf)	mem 14543MB
[2023-10-11 18:41:42 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][3000/6787]	eta 0:16:08 lr 0.000200	time 0.2551 (0.2558)	loss 0.3450 (0.3598)	grad_norm 249816.1406 (inf)	mem 14543MB
[2023-10-11 18:43:50 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][3500/6787]	eta 0:14:00 lr 0.000200	time 0.2557 (0.2558)	loss 0.3611 (0.3599)	grad_norm 411463.0000 (inf)	mem 14543MB
[2023-10-11 18:45:58 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][4000/6787]	eta 0:11:52 lr 0.000200	time 0.2506 (0.2557)	loss 0.3607 (0.3599)	grad_norm 333321.7500 (inf)	mem 14543MB
[2023-10-11 18:48:05 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][4500/6787]	eta 0:09:44 lr 0.000200	time 0.2550 (0.2555)	loss 0.3612 (0.3600)	grad_norm 231394.6562 (inf)	mem 14543MB
[2023-10-11 18:50:12 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][5000/6787]	eta 0:07:36 lr 0.000200	time 0.2563 (0.2555)	loss 0.3775 (0.3602)	grad_norm 284874.9375 (inf)	mem 14543MB
[2023-10-11 18:52:20 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][5500/6787]	eta 0:05:28 lr 0.000200	time 0.2531 (0.2554)	loss 0.3680 (0.3604)	grad_norm 291277.3750 (inf)	mem 14543MB
[2023-10-11 18:54:27 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2527 (0.2554)	loss 0.3421 (0.3605)	grad_norm 224829.9062 (inf)	mem 14543MB
[2023-10-11 18:56:35 simmim_pretrain](main_simmim.py 218): INFO Train: [83/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2537 (0.2554)	loss 0.3562 (0.3605)	grad_norm 302924.4688 (inf)	mem 14543MB
[2023-10-11 18:57:48 simmim_pretrain](main_simmim.py 228): INFO EPOCH 83 training takes 0:28:53
[2023-10-11 18:57:50 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][0/6787]	eta 3:00:49 lr 0.000200	time 1.5986 (1.5986)	loss 0.3934 (0.3934)	grad_norm 218183.4844 (218183.4844)	mem 14543MB
[2023-10-11 18:59:56 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][500/6787]	eta 0:26:44 lr 0.000200	time 0.2492 (0.2552)	loss 0.3576 (0.3597)	grad_norm 283566.3750 (inf)	mem 14543MB
[2023-10-11 19:02:02 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][1000/6787]	eta 0:24:29 lr 0.000200	time 0.2540 (0.2538)	loss 0.3536 (0.3601)	grad_norm 286184.2812 (inf)	mem 14543MB
[2023-10-11 19:04:09 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][1500/6787]	eta 0:22:18 lr 0.000200	time 0.2571 (0.2532)	loss 0.3668 (0.3605)	grad_norm 231786.2188 (inf)	mem 14543MB
[2023-10-11 19:06:14 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][2000/6787]	eta 0:20:10 lr 0.000200	time 0.2495 (0.2528)	loss 0.3863 (0.3608)	grad_norm 166839.6875 (inf)	mem 14543MB
[2023-10-11 19:08:20 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][2500/6787]	eta 0:18:02 lr 0.000200	time 0.2489 (0.2524)	loss 0.3650 (0.3609)	grad_norm 162355.9219 (inf)	mem 14543MB
[2023-10-11 19:10:25 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][3000/6787]	eta 0:15:54 lr 0.000200	time 0.2509 (0.2521)	loss 0.3648 (0.3606)	grad_norm 345335.5625 (inf)	mem 14543MB
[2023-10-11 19:12:30 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2489 (0.2519)	loss 0.3722 (0.3606)	grad_norm 677765.6250 (inf)	mem 14543MB
[2023-10-11 19:14:35 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2461 (0.2516)	loss 0.3652 (0.3606)	grad_norm 385948.4062 (inf)	mem 14543MB
[2023-10-11 19:16:40 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2461 (0.2514)	loss 0.3781 (0.3605)	grad_norm 368063.0000 (inf)	mem 14543MB
[2023-10-11 19:18:45 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2504 (0.2512)	loss 0.3653 (0.3605)	grad_norm 210457.3281 (inf)	mem 14543MB
[2023-10-11 19:20:50 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2463 (0.2511)	loss 0.3665 (0.3604)	grad_norm 213639.8438 (inf)	mem 14543MB
[2023-10-11 19:22:55 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2473 (0.2510)	loss 0.3867 (0.3603)	grad_norm 284046.3125 (inf)	mem 14543MB
[2023-10-11 19:25:00 simmim_pretrain](main_simmim.py 218): INFO Train: [84/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2533 (0.2509)	loss 0.3559 (0.3603)	grad_norm 346463.3750 (inf)	mem 14543MB
[2023-10-11 19:26:12 simmim_pretrain](main_simmim.py 228): INFO EPOCH 84 training takes 0:28:23
[2023-10-11 19:26:13 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][0/6787]	eta 2:52:16 lr 0.000200	time 1.5229 (1.5229)	loss 0.3701 (0.3701)	grad_norm 231430.0469 (231430.0469)	mem 14543MB
[2023-10-11 19:28:18 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][500/6787]	eta 0:26:27 lr 0.000200	time 0.2488 (0.2526)	loss 0.3522 (0.3620)	grad_norm 272557.3125 (250176.9062)	mem 14543MB
[2023-10-11 19:30:23 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][1000/6787]	eta 0:24:13 lr 0.000200	time 0.2470 (0.2512)	loss 0.3777 (0.3619)	grad_norm 284231.1250 (244329.8750)	mem 14543MB
[2023-10-11 19:32:28 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][1500/6787]	eta 0:22:06 lr 0.000200	time 0.2463 (0.2508)	loss 0.3492 (0.3613)	grad_norm 226388.4062 (249174.1719)	mem 14543MB
[2023-10-11 19:34:34 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][2000/6787]	eta 0:20:00 lr 0.000200	time 0.2501 (0.2507)	loss 0.3615 (0.3610)	grad_norm 441312.4688 (267987.4688)	mem 14543MB
[2023-10-11 19:36:39 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][2500/6787]	eta 0:17:54 lr 0.000200	time 0.2510 (0.2507)	loss 0.3541 (0.3609)	grad_norm 245185.4375 (inf)	mem 14543MB
[2023-10-11 19:38:44 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][3000/6787]	eta 0:15:49 lr 0.000200	time 0.2533 (0.2508)	loss 0.3656 (0.3612)	grad_norm 243705.8594 (inf)	mem 14543MB
[2023-10-11 19:40:50 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][3500/6787]	eta 0:13:44 lr 0.000200	time 0.2491 (0.2508)	loss 0.3729 (0.3610)	grad_norm 229829.5469 (inf)	mem 14543MB
[2023-10-11 19:42:56 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2560 (0.2509)	loss 0.3640 (0.3609)	grad_norm 227095.2344 (inf)	mem 14543MB
[2023-10-11 19:45:01 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2498 (0.2509)	loss 0.3661 (0.3608)	grad_norm 178129.6250 (inf)	mem 14543MB
[2023-10-11 19:47:07 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2462 (0.2509)	loss 0.3586 (0.3606)	grad_norm 253679.6719 (inf)	mem 14543MB
[2023-10-11 19:49:12 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2463 (0.2509)	loss 0.3660 (0.3606)	grad_norm 396014.1562 (inf)	mem 14543MB
[2023-10-11 19:51:18 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2516 (0.2509)	loss 0.3699 (0.3605)	grad_norm 486671.0938 (inf)	mem 14543MB
[2023-10-11 19:53:23 simmim_pretrain](main_simmim.py 218): INFO Train: [85/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2506 (0.2509)	loss 0.3733 (0.3604)	grad_norm 221600.2031 (inf)	mem 14543MB
[2023-10-11 19:54:36 simmim_pretrain](main_simmim.py 228): INFO EPOCH 85 training takes 0:28:23
[2023-10-11 19:54:37 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][0/6787]	eta 2:47:26 lr 0.000200	time 1.4803 (1.4803)	loss 0.3559 (0.3559)	grad_norm 373023.6562 (373023.6562)	mem 14543MB
[2023-10-11 19:56:42 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][500/6787]	eta 0:26:28 lr 0.000200	time 0.2570 (0.2527)	loss 0.3705 (0.3608)	grad_norm 274661.5312 (263276.8125)	mem 14543MB
[2023-10-11 19:58:47 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][1000/6787]	eta 0:24:14 lr 0.000200	time 0.2516 (0.2513)	loss 0.3515 (0.3604)	grad_norm 292293.8750 (261800.0312)	mem 14543MB
[2023-10-11 20:00:52 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][1500/6787]	eta 0:22:05 lr 0.000200	time 0.2536 (0.2508)	loss 0.3623 (0.3608)	grad_norm 316428.7500 (257527.7188)	mem 14543MB
[2023-10-11 20:02:57 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][2000/6787]	eta 0:19:59 lr 0.000200	time 0.2489 (0.2505)	loss 0.3681 (0.3609)	grad_norm 447697.5938 (269637.5625)	mem 14543MB
[2023-10-11 20:05:02 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][2500/6787]	eta 0:17:53 lr 0.000200	time 0.2509 (0.2504)	loss 0.3650 (0.3609)	grad_norm 243482.3594 (inf)	mem 14543MB
[2023-10-11 20:07:07 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][3000/6787]	eta 0:15:48 lr 0.000200	time 0.2478 (0.2503)	loss 0.3643 (0.3610)	grad_norm 221536.2500 (inf)	mem 14543MB
[2023-10-11 20:09:12 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][3500/6787]	eta 0:13:42 lr 0.000200	time 0.2533 (0.2503)	loss 0.3673 (0.3610)	grad_norm 199322.9219 (inf)	mem 14543MB
[2023-10-11 20:11:17 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2463 (0.2503)	loss 0.3743 (0.3612)	grad_norm 195014.1094 (inf)	mem 14543MB
[2023-10-11 20:13:22 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2511 (0.2502)	loss 0.3910 (0.3610)	grad_norm 244593.2031 (inf)	mem 14543MB
[2023-10-11 20:15:27 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2461 (0.2502)	loss 0.3568 (0.3609)	grad_norm 317116.0000 (inf)	mem 14543MB
[2023-10-11 20:17:32 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2464 (0.2503)	loss 0.3654 (0.3609)	grad_norm 265173.1250 (inf)	mem 14543MB
[2023-10-11 20:19:38 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2503 (0.2503)	loss 0.3632 (0.3610)	grad_norm 371299.0625 (inf)	mem 14543MB
[2023-10-11 20:21:43 simmim_pretrain](main_simmim.py 218): INFO Train: [86/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2511 (0.2503)	loss 0.3729 (0.3609)	grad_norm 340506.0625 (inf)	mem 14543MB
[2023-10-11 20:22:56 simmim_pretrain](main_simmim.py 228): INFO EPOCH 86 training takes 0:28:20
[2023-10-11 20:22:57 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][0/6787]	eta 2:54:11 lr 0.000200	time 1.5400 (1.5400)	loss 0.3515 (0.3515)	grad_norm 261586.7969 (261586.7969)	mem 14543MB
[2023-10-11 20:25:02 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][500/6787]	eta 0:26:29 lr 0.000200	time 0.2472 (0.2528)	loss 0.3369 (0.3603)	grad_norm 282509.0312 (283270.1562)	mem 14543MB
[2023-10-11 20:27:08 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2496 (0.2519)	loss 0.3476 (0.3604)	grad_norm 320019.9688 (325104.2500)	mem 14543MB
[2023-10-11 20:29:13 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][1500/6787]	eta 0:22:09 lr 0.000200	time 0.2510 (0.2515)	loss 0.3502 (0.3604)	grad_norm 477013.1875 (350222.0625)	mem 14543MB
[2023-10-11 20:31:18 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][2000/6787]	eta 0:20:03 lr 0.000200	time 0.2462 (0.2513)	loss 0.3574 (0.3602)	grad_norm 289423.2188 (375225.8438)	mem 14543MB
[2023-10-11 20:33:24 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][2500/6787]	eta 0:17:57 lr 0.000200	time 0.2538 (0.2513)	loss 0.3684 (0.3604)	grad_norm 387449.8125 (inf)	mem 14543MB
[2023-10-11 20:35:29 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][3000/6787]	eta 0:15:51 lr 0.000200	time 0.2521 (0.2512)	loss 0.3710 (0.3604)	grad_norm 315114.2188 (inf)	mem 14543MB
[2023-10-11 20:37:35 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2503 (0.2511)	loss 0.3631 (0.3606)	grad_norm 272360.9375 (inf)	mem 14543MB
[2023-10-11 20:39:40 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2483 (0.2510)	loss 0.3713 (0.3605)	grad_norm 260816.7656 (inf)	mem 14543MB
[2023-10-11 20:41:45 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2463 (0.2509)	loss 0.3785 (0.3607)	grad_norm 167021.7188 (inf)	mem 14543MB
[2023-10-11 20:43:50 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2466 (0.2508)	loss 0.3553 (0.3609)	grad_norm 387843.6875 (inf)	mem 14543MB
[2023-10-11 20:45:55 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2468 (0.2508)	loss 0.3530 (0.3609)	grad_norm 240784.5781 (inf)	mem 14543MB
[2023-10-11 20:48:00 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2526 (0.2508)	loss 0.3655 (0.3608)	grad_norm 350282.4375 (inf)	mem 14543MB
[2023-10-11 20:50:06 simmim_pretrain](main_simmim.py 218): INFO Train: [87/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2460 (0.2507)	loss 0.3839 (0.3610)	grad_norm 172207.4375 (inf)	mem 14543MB
[2023-10-11 20:51:18 simmim_pretrain](main_simmim.py 228): INFO EPOCH 87 training takes 0:28:22
[2023-10-11 20:51:20 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][0/6787]	eta 2:59:01 lr 0.000200	time 1.5827 (1.5827)	loss 0.3547 (0.3547)	grad_norm 227045.6562 (227045.6562)	mem 14543MB
[2023-10-11 20:53:25 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][500/6787]	eta 0:26:28 lr 0.000200	time 0.2552 (0.2527)	loss 0.3458 (0.3622)	grad_norm 160340.3438 (257354.3281)	mem 14543MB
[2023-10-11 20:55:30 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][1000/6787]	eta 0:24:16 lr 0.000200	time 0.2488 (0.2517)	loss 0.3636 (0.3614)	grad_norm 298845.7812 (259312.7812)	mem 14543MB
[2023-10-11 20:57:35 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][1500/6787]	eta 0:22:07 lr 0.000200	time 0.2520 (0.2512)	loss 0.4119 (0.3970)	grad_norm 56660.4883 (inf)	mem 14543MB
[2023-10-11 20:59:40 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][2000/6787]	eta 0:20:01 lr 0.000200	time 0.2495 (0.2511)	loss 0.3587 (0.3927)	grad_norm 34838.4766 (inf)	mem 14543MB
[2023-10-11 21:01:46 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2513 (0.2510)	loss 0.3521 (0.3880)	grad_norm 30103.2676 (inf)	mem 14543MB
[2023-10-11 21:03:51 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2517 (0.2510)	loss 0.3868 (0.3848)	grad_norm 24777.1641 (inf)	mem 14543MB
[2023-10-11 21:05:57 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2518 (0.2510)	loss 0.3731 (0.3819)	grad_norm 57457.0273 (inf)	mem 14543MB
[2023-10-11 21:08:02 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2495 (0.2510)	loss 0.3543 (0.3798)	grad_norm 33334.3750 (inf)	mem 14543MB
[2023-10-11 21:10:08 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2524 (0.2510)	loss 0.3466 (0.3780)	grad_norm 49983.0938 (inf)	mem 14543MB
[2023-10-11 21:12:13 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2505 (0.2510)	loss 0.3361 (0.3767)	grad_norm 35029.6875 (inf)	mem 14543MB
[2023-10-11 21:14:18 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2463 (0.2509)	loss 0.3874 (0.3754)	grad_norm 62630.1875 (inf)	mem 14543MB
[2023-10-11 21:16:23 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2557 (0.2508)	loss 0.3653 (0.3743)	grad_norm 85851.2734 (inf)	mem 14543MB
[2023-10-11 21:18:28 simmim_pretrain](main_simmim.py 218): INFO Train: [88/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2517 (0.2508)	loss 0.3529 (0.3734)	grad_norm 68912.6094 (inf)	mem 14543MB
[2023-10-11 21:19:40 simmim_pretrain](main_simmim.py 228): INFO EPOCH 88 training takes 0:28:22
[2023-10-11 21:19:42 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][0/6787]	eta 2:50:25 lr 0.000200	time 1.5067 (1.5067)	loss 0.3623 (0.3623)	grad_norm 91225.9297 (91225.9297)	mem 14543MB
[2023-10-11 21:21:47 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][500/6787]	eta 0:26:25 lr 0.000200	time 0.2455 (0.2522)	loss 0.3705 (0.3607)	grad_norm 68872.0234 (99398.5938)	mem 14543MB
[2023-10-11 21:23:52 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][1000/6787]	eta 0:24:14 lr 0.000200	time 0.2544 (0.2513)	loss 0.3696 (0.3612)	grad_norm 98099.3047 (115776.9297)	mem 14543MB
[2023-10-11 21:25:57 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][1500/6787]	eta 0:22:07 lr 0.000200	time 0.2497 (0.2510)	loss 0.3465 (0.3612)	grad_norm 196062.1094 (136350.5938)	mem 14543MB
[2023-10-11 21:28:03 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][2000/6787]	eta 0:20:01 lr 0.000200	time 0.2492 (0.2510)	loss 0.3600 (0.3610)	grad_norm 161352.8125 (143979.5469)	mem 14543MB
[2023-10-11 21:30:08 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2591 (0.2510)	loss 0.3673 (0.3609)	grad_norm 251705.7188 (155916.9219)	mem 14543MB
[2023-10-11 21:32:14 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2528 (0.2510)	loss 0.3481 (0.3606)	grad_norm 197844.5938 (175195.7656)	mem 14543MB
[2023-10-11 21:34:19 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2502 (0.2510)	loss 0.3600 (0.3604)	grad_norm 647859.2500 (195491.0781)	mem 14543MB
[2023-10-11 21:36:25 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2488 (0.2511)	loss 0.3541 (0.3603)	grad_norm 447311.7812 (229069.8125)	mem 14543MB
[2023-10-11 21:38:31 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2518 (0.2511)	loss 0.3644 (0.3602)	grad_norm 410143.4375 (inf)	mem 14543MB
[2023-10-11 21:40:37 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2484 (0.2512)	loss 0.3442 (0.3601)	grad_norm 408016.3438 (inf)	mem 14543MB
[2023-10-11 21:42:41 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2463 (0.2510)	loss 0.3622 (0.3600)	grad_norm 446225.4688 (inf)	mem 14543MB
[2023-10-11 21:44:44 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2455 (0.2506)	loss 0.3564 (0.3599)	grad_norm 261182.1094 (inf)	mem 14543MB
[2023-10-11 21:46:47 simmim_pretrain](main_simmim.py 218): INFO Train: [89/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2442 (0.2502)	loss 0.3668 (0.3598)	grad_norm 386898.7188 (inf)	mem 14543MB
[2023-10-11 21:47:58 simmim_pretrain](main_simmim.py 228): INFO EPOCH 89 training takes 0:28:17
[2023-10-11 21:47:59 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][0/6787]	eta 2:22:38 lr 0.000200	time 1.2610 (1.2610)	loss 0.3760 (0.3760)	grad_norm 170557.5000 (170557.5000)	mem 14543MB
[2023-10-11 21:50:01 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][500/6787]	eta 0:25:48 lr 0.000200	time 0.2442 (0.2463)	loss 0.3660 (0.3600)	grad_norm 168590.0938 (240454.4844)	mem 14543MB
[2023-10-11 21:52:03 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][1000/6787]	eta 0:23:38 lr 0.000200	time 0.2438 (0.2452)	loss 0.3698 (0.3605)	grad_norm 240785.2344 (231088.2344)	mem 14543MB
[2023-10-11 21:54:05 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][1500/6787]	eta 0:21:34 lr 0.000200	time 0.2437 (0.2448)	loss 0.3605 (0.3607)	grad_norm 224320.6719 (225170.1719)	mem 14543MB
[2023-10-11 21:56:07 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][2000/6787]	eta 0:19:31 lr 0.000200	time 0.2442 (0.2446)	loss 0.3573 (0.3609)	grad_norm 482738.2812 (220991.0312)	mem 14543MB
[2023-10-11 21:58:09 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][2500/6787]	eta 0:17:28 lr 0.000200	time 0.2442 (0.2445)	loss 0.3836 (0.3607)	grad_norm 305034.9062 (237426.5625)	mem 14543MB
[2023-10-11 22:00:11 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][3000/6787]	eta 0:15:25 lr 0.000200	time 0.2436 (0.2444)	loss 0.3755 (0.3606)	grad_norm 305304.8750 (254154.1406)	mem 14543MB
[2023-10-11 22:02:13 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][3500/6787]	eta 0:13:23 lr 0.000200	time 0.2437 (0.2444)	loss 0.3746 (0.3604)	grad_norm 227178.0000 (280693.0938)	mem 14543MB
[2023-10-11 22:04:15 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][4000/6787]	eta 0:11:20 lr 0.000200	time 0.2437 (0.2443)	loss 0.3537 (0.3604)	grad_norm 447759.7500 (287622.4688)	mem 14543MB
[2023-10-11 22:06:17 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][4500/6787]	eta 0:09:18 lr 0.000200	time 0.2442 (0.2443)	loss 0.3510 (0.3602)	grad_norm 285604.6250 (inf)	mem 14543MB
[2023-10-11 22:08:19 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][5000/6787]	eta 0:07:16 lr 0.000200	time 0.2443 (0.2443)	loss 0.3486 (0.3604)	grad_norm 331259.1875 (inf)	mem 14543MB
[2023-10-11 22:10:21 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][5500/6787]	eta 0:05:14 lr 0.000200	time 0.2439 (0.2442)	loss 0.3699 (0.3604)	grad_norm 276170.1250 (inf)	mem 14543MB
[2023-10-11 22:12:23 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][6000/6787]	eta 0:03:12 lr 0.000200	time 0.2440 (0.2442)	loss 0.3365 (0.3603)	grad_norm 278261.8750 (inf)	mem 14543MB
[2023-10-11 22:14:25 simmim_pretrain](main_simmim.py 218): INFO Train: [90/200][6500/6787]	eta 0:01:10 lr 0.000200	time 0.2441 (0.2442)	loss 0.3590 (0.3604)	grad_norm 334744.2812 (inf)	mem 14543MB
[2023-10-11 22:15:36 simmim_pretrain](main_simmim.py 228): INFO EPOCH 90 training takes 0:27:38
[2023-10-11 22:15:37 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][0/6787]	eta 2:23:35 lr 0.000200	time 1.2693 (1.2693)	loss 0.3623 (0.3623)	grad_norm 191644.7969 (191644.7969)	mem 14543MB
[2023-10-11 22:17:39 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][500/6787]	eta 0:25:47 lr 0.000200	time 0.2442 (0.2462)	loss 0.3624 (0.3594)	grad_norm 487173.9375 (310834.7812)	mem 14543MB
[2023-10-11 22:19:41 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][1000/6787]	eta 0:23:38 lr 0.000200	time 0.2443 (0.2451)	loss 0.3755 (0.3593)	grad_norm 414266.3750 (338198.0625)	mem 14543MB
[2023-10-11 22:21:43 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][1500/6787]	eta 0:21:34 lr 0.000200	time 0.2440 (0.2448)	loss 0.3474 (0.3596)	grad_norm 473233.6562 (340883.9062)	mem 14543MB
[2023-10-11 22:23:45 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][2000/6787]	eta 0:19:30 lr 0.000200	time 0.2442 (0.2446)	loss 0.3799 (0.3592)	grad_norm 416249.3750 (inf)	mem 14543MB
[2023-10-11 22:25:47 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][2500/6787]	eta 0:17:28 lr 0.000200	time 0.2443 (0.2445)	loss 0.3519 (0.3591)	grad_norm 516312.1562 (inf)	mem 14543MB
[2023-10-11 22:27:49 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][3000/6787]	eta 0:15:25 lr 0.000200	time 0.2444 (0.2444)	loss 0.3723 (0.3593)	grad_norm 633295.6875 (inf)	mem 14543MB
[2023-10-11 22:29:52 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][3500/6787]	eta 0:13:23 lr 0.000200	time 0.2441 (0.2444)	loss 0.3532 (0.3594)	grad_norm 445285.3125 (inf)	mem 14543MB
[2023-10-11 22:31:54 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][4000/6787]	eta 0:11:20 lr 0.000200	time 0.2438 (0.2443)	loss 0.3451 (0.3594)	grad_norm 415215.3438 (inf)	mem 14543MB
[2023-10-11 22:33:56 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][4500/6787]	eta 0:09:18 lr 0.000200	time 0.2444 (0.2443)	loss 0.3935 (0.3597)	grad_norm 307076.5625 (inf)	mem 14543MB
[2023-10-11 22:35:58 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][5000/6787]	eta 0:07:16 lr 0.000200	time 0.2442 (0.2443)	loss 0.3607 (0.3598)	grad_norm 282594.4375 (inf)	mem 14543MB
[2023-10-11 22:38:00 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][5500/6787]	eta 0:05:14 lr 0.000200	time 0.2437 (0.2442)	loss 0.3528 (0.3600)	grad_norm 171084.9219 (inf)	mem 14543MB
[2023-10-11 22:40:02 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][6000/6787]	eta 0:03:12 lr 0.000200	time 0.2445 (0.2442)	loss 0.3498 (0.3601)	grad_norm 258422.8750 (inf)	mem 14543MB
[2023-10-11 22:42:04 simmim_pretrain](main_simmim.py 218): INFO Train: [91/200][6500/6787]	eta 0:01:10 lr 0.000200	time 0.2439 (0.2442)	loss 0.3478 (0.3601)	grad_norm 315594.7500 (inf)	mem 14543MB
[2023-10-11 22:43:14 simmim_pretrain](main_simmim.py 228): INFO EPOCH 91 training takes 0:27:38
[2023-10-11 22:43:15 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][0/6787]	eta 2:23:13 lr 0.000200	time 1.2662 (1.2662)	loss 0.3728 (0.3728)	grad_norm 404795.1562 (404795.1562)	mem 14543MB
[2023-10-11 22:45:18 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][500/6787]	eta 0:25:47 lr 0.000200	time 0.2442 (0.2462)	loss 0.3567 (0.3595)	grad_norm 295807.7500 (349724.4688)	mem 14543MB
[2023-10-11 22:47:20 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][1000/6787]	eta 0:23:38 lr 0.000200	time 0.2437 (0.2451)	loss 0.3405 (0.3593)	grad_norm 251234.4375 (364011.5000)	mem 14543MB
[2023-10-11 22:49:22 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][1500/6787]	eta 0:21:33 lr 0.000200	time 0.2441 (0.2447)	loss 0.3476 (0.3590)	grad_norm 234071.4375 (inf)	mem 14543MB
[2023-10-11 22:51:24 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][2000/6787]	eta 0:19:30 lr 0.000200	time 0.2444 (0.2446)	loss 0.3648 (0.3591)	grad_norm 249882.7656 (inf)	mem 14543MB
[2023-10-11 22:53:26 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][2500/6787]	eta 0:17:28 lr 0.000200	time 0.2438 (0.2445)	loss 0.3571 (0.3595)	grad_norm 260261.1719 (inf)	mem 14543MB
[2023-10-11 22:55:28 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][3000/6787]	eta 0:15:25 lr 0.000200	time 0.2444 (0.2444)	loss 0.3584 (0.3596)	grad_norm 249233.6406 (inf)	mem 14543MB
[2023-10-11 22:57:30 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][3500/6787]	eta 0:13:23 lr 0.000200	time 0.2437 (0.2443)	loss 0.3658 (0.3597)	grad_norm 335225.8750 (inf)	mem 14543MB
[2023-10-11 22:59:32 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][4000/6787]	eta 0:11:20 lr 0.000200	time 0.2437 (0.2443)	loss 0.3524 (0.3596)	grad_norm 342623.4375 (inf)	mem 14543MB
[2023-10-11 23:01:34 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][4500/6787]	eta 0:09:18 lr 0.000200	time 0.2437 (0.2443)	loss 0.3663 (0.3595)	grad_norm 245564.4375 (inf)	mem 14543MB
[2023-10-11 23:03:36 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][5000/6787]	eta 0:07:16 lr 0.000200	time 0.2437 (0.2442)	loss 0.3655 (0.3595)	grad_norm 225061.4688 (inf)	mem 14543MB
[2023-10-11 23:05:38 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][5500/6787]	eta 0:05:14 lr 0.000200	time 0.2439 (0.2442)	loss 0.3683 (0.3598)	grad_norm 179358.0625 (inf)	mem 14543MB
[2023-10-11 23:07:40 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][6000/6787]	eta 0:03:12 lr 0.000200	time 0.2442 (0.2442)	loss 0.3419 (0.3601)	grad_norm 158925.0312 (inf)	mem 14543MB
[2023-10-11 23:09:42 simmim_pretrain](main_simmim.py 218): INFO Train: [92/200][6500/6787]	eta 0:01:10 lr 0.000200	time 0.2441 (0.2442)	loss 0.3405 (0.3604)	grad_norm 106705.7812 (inf)	mem 14543MB
[2023-10-11 23:10:52 simmim_pretrain](main_simmim.py 228): INFO EPOCH 92 training takes 0:27:37
[2023-10-11 23:10:53 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][0/6787]	eta 2:25:57 lr 0.000200	time 1.2904 (1.2904)	loss 0.3629 (0.3629)	grad_norm 127502.2109 (127502.2109)	mem 14543MB
[2023-10-11 23:12:55 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][500/6787]	eta 0:25:47 lr 0.000200	time 0.2440 (0.2461)	loss 0.3568 (0.3615)	grad_norm 104398.9219 (139989.8125)	mem 14543MB
[2023-10-11 23:14:58 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][1000/6787]	eta 0:23:38 lr 0.000200	time 0.2438 (0.2451)	loss 0.3605 (0.3616)	grad_norm 172516.2344 (156020.9219)	mem 14543MB
[2023-10-11 23:17:00 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][1500/6787]	eta 0:21:35 lr 0.000200	time 0.2511 (0.2451)	loss 0.3330 (0.3615)	grad_norm 134507.4219 (169800.7969)	mem 14543MB
[2023-10-11 23:19:04 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][2000/6787]	eta 0:19:35 lr 0.000200	time 0.2500 (0.2457)	loss 0.3781 (0.3612)	grad_norm 489067.6562 (177929.1562)	mem 14543MB
[2023-10-11 23:21:09 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][2500/6787]	eta 0:17:36 lr 0.000200	time 0.2508 (0.2465)	loss 0.3498 (0.3610)	grad_norm 274301.0625 (192479.8750)	mem 14543MB
[2023-10-11 23:23:14 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][3000/6787]	eta 0:15:35 lr 0.000200	time 0.2497 (0.2471)	loss 0.3493 (0.3605)	grad_norm 194772.6875 (209354.0156)	mem 14543MB
[2023-10-11 23:25:19 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][3500/6787]	eta 0:13:33 lr 0.000200	time 0.2512 (0.2476)	loss 0.3668 (0.3604)	grad_norm 350475.1875 (231430.6406)	mem 14543MB
[2023-10-11 23:27:25 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][4000/6787]	eta 0:11:31 lr 0.000200	time 0.2496 (0.2480)	loss 0.3527 (0.3601)	grad_norm 927230.5625 (250409.8125)	mem 14543MB
[2023-10-11 23:29:30 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][4500/6787]	eta 0:09:27 lr 0.000200	time 0.2495 (0.2483)	loss 0.3624 (0.3599)	grad_norm 475389.3438 (inf)	mem 14543MB
[2023-10-11 23:31:36 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][5000/6787]	eta 0:07:24 lr 0.000200	time 0.2547 (0.2487)	loss 0.3646 (0.3599)	grad_norm 502091.1875 (inf)	mem 14543MB
[2023-10-11 23:33:42 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][5500/6787]	eta 0:05:20 lr 0.000200	time 0.2567 (0.2491)	loss 0.3861 (0.3598)	grad_norm 338733.1875 (inf)	mem 14543MB
[2023-10-11 23:35:50 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][6000/6787]	eta 0:03:16 lr 0.000200	time 0.2562 (0.2497)	loss 0.3481 (0.3598)	grad_norm 450744.2500 (inf)	mem 14543MB
[2023-10-11 23:37:59 simmim_pretrain](main_simmim.py 218): INFO Train: [93/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2571 (0.2502)	loss 0.3701 (0.3599)	grad_norm 252458.0781 (inf)	mem 14543MB
[2023-10-11 23:39:13 simmim_pretrain](main_simmim.py 228): INFO EPOCH 93 training takes 0:28:20
[2023-10-11 23:39:14 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][0/6787]	eta 2:33:10 lr 0.000200	time 1.3542 (1.3542)	loss 0.3598 (0.3598)	grad_norm 195948.2500 (195948.2500)	mem 14543MB
[2023-10-11 23:41:19 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2515 (0.2530)	loss 0.3767 (0.3613)	grad_norm 239986.7188 (278015.4688)	mem 14543MB
[2023-10-11 23:43:25 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][1000/6787]	eta 0:24:20 lr 0.000200	time 0.2534 (0.2523)	loss 0.3650 (0.3616)	grad_norm 243425.3594 (254542.3594)	mem 14543MB
[2023-10-11 23:45:31 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][1500/6787]	eta 0:22:12 lr 0.000200	time 0.2472 (0.2521)	loss 0.3584 (0.3610)	grad_norm 338258.1250 (259721.9219)	mem 14543MB
[2023-10-11 23:47:37 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][2000/6787]	eta 0:20:05 lr 0.000200	time 0.2514 (0.2519)	loss 0.3427 (0.3605)	grad_norm 242770.8281 (276487.8438)	mem 14543MB
[2023-10-11 23:49:42 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][2500/6787]	eta 0:17:59 lr 0.000200	time 0.2465 (0.2517)	loss 0.3694 (0.3604)	grad_norm 280177.0000 (inf)	mem 14543MB
[2023-10-11 23:51:48 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2500 (0.2516)	loss 0.3510 (0.3604)	grad_norm 322366.2188 (inf)	mem 14543MB
[2023-10-11 23:53:53 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2501 (0.2515)	loss 0.3643 (0.3605)	grad_norm 267451.7500 (inf)	mem 14543MB
[2023-10-11 23:55:59 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2521 (0.2514)	loss 0.3388 (0.3605)	grad_norm 349595.1250 (inf)	mem 14543MB
[2023-10-11 23:58:04 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2538 (0.2514)	loss 0.3665 (0.3605)	grad_norm 487705.5938 (inf)	mem 14543MB
[2023-10-12 00:00:10 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2485 (0.2513)	loss 0.3733 (0.3604)	grad_norm 241284.5156 (inf)	mem 14543MB
[2023-10-12 00:02:15 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2593 (0.2513)	loss 0.3442 (0.3603)	grad_norm 681812.5625 (inf)	mem 14543MB
[2023-10-12 00:04:21 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2503 (0.2513)	loss 0.3487 (0.3602)	grad_norm 261522.1719 (inf)	mem 14543MB
[2023-10-12 00:06:26 simmim_pretrain](main_simmim.py 218): INFO Train: [94/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2518 (0.2512)	loss 0.3639 (0.3602)	grad_norm 314174.4688 (inf)	mem 14543MB
[2023-10-12 00:07:38 simmim_pretrain](main_simmim.py 228): INFO EPOCH 94 training takes 0:28:25
[2023-10-12 00:07:40 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][0/6787]	eta 3:01:26 lr 0.000200	time 1.6040 (1.6040)	loss 0.3612 (0.3612)	grad_norm 330066.4688 (330066.4688)	mem 14543MB
[2023-10-12 00:09:45 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2519 (0.2530)	loss 0.3535 (0.3590)	grad_norm 338333.1562 (inf)	mem 14543MB
[2023-10-12 00:11:51 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2521 (0.2519)	loss 0.3642 (0.3598)	grad_norm 342719.0938 (inf)	mem 14543MB
[2023-10-12 00:13:56 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2489 (0.2516)	loss 0.3549 (0.3603)	grad_norm 198139.5781 (inf)	mem 14543MB
[2023-10-12 00:16:02 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][2000/6787]	eta 0:20:03 lr 0.000200	time 0.2553 (0.2514)	loss 0.3507 (0.3603)	grad_norm 303251.9062 (inf)	mem 14543MB
[2023-10-12 00:18:07 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][2500/6787]	eta 0:17:57 lr 0.000200	time 0.2485 (0.2513)	loss 0.3645 (0.3604)	grad_norm 269514.3125 (inf)	mem 14543MB
[2023-10-12 00:20:12 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][3000/6787]	eta 0:15:51 lr 0.000200	time 0.2492 (0.2512)	loss 0.3571 (0.3603)	grad_norm 459835.5938 (inf)	mem 14543MB
[2023-10-12 00:22:18 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2531 (0.2512)	loss 0.3537 (0.3601)	grad_norm 290855.5625 (inf)	mem 14543MB
[2023-10-12 00:24:23 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2593 (0.2512)	loss 0.3527 (0.3600)	grad_norm 662410.2500 (inf)	mem 14543MB
[2023-10-12 00:26:29 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2458 (0.2512)	loss 0.3524 (0.3602)	grad_norm 312092.1250 (inf)	mem 14543MB
[2023-10-12 00:28:34 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2584 (0.2511)	loss 0.3704 (0.3602)	grad_norm 263137.7812 (inf)	mem 14543MB
[2023-10-12 00:30:40 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2488 (0.2511)	loss 0.3380 (0.3602)	grad_norm 217898.2188 (inf)	mem 14543MB
[2023-10-12 00:32:45 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2481 (0.2511)	loss 0.3524 (0.3602)	grad_norm 187770.5312 (inf)	mem 14543MB
[2023-10-12 00:34:51 simmim_pretrain](main_simmim.py 218): INFO Train: [95/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2498 (0.2511)	loss 0.3603 (0.3602)	grad_norm 239238.5156 (nan)	mem 14543MB
[2023-10-12 00:36:03 simmim_pretrain](main_simmim.py 228): INFO EPOCH 95 training takes 0:28:24
[2023-10-12 00:36:05 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][0/6787]	eta 2:35:28 lr 0.000200	time 1.3745 (1.3745)	loss 0.3515 (0.3515)	grad_norm 338666.8125 (338666.8125)	mem 14543MB
[2023-10-12 00:38:10 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][500/6787]	eta 0:26:31 lr 0.000200	time 0.2483 (0.2532)	loss 0.3654 (0.3613)	grad_norm 269618.0312 (263035.4062)	mem 14543MB
[2023-10-12 00:40:16 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][1000/6787]	eta 0:24:19 lr 0.000200	time 0.2553 (0.2522)	loss 0.3493 (0.3618)	grad_norm 159350.4844 (inf)	mem 14543MB
[2023-10-12 00:42:21 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][1500/6787]	eta 0:22:11 lr 0.000200	time 0.2522 (0.2519)	loss 0.3694 (0.3623)	grad_norm 143001.4844 (inf)	mem 14543MB
[2023-10-12 00:44:27 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][2000/6787]	eta 0:20:05 lr 0.000200	time 0.2546 (0.2518)	loss 0.3682 (0.3624)	grad_norm 126866.6172 (inf)	mem 14543MB
[2023-10-12 00:46:33 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][2500/6787]	eta 0:17:59 lr 0.000200	time 0.2510 (0.2518)	loss 0.3668 (0.3626)	grad_norm 86701.1094 (inf)	mem 14543MB
[2023-10-12 00:48:39 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][3000/6787]	eta 0:15:53 lr 0.000200	time 0.2472 (0.2518)	loss 0.3802 (0.3624)	grad_norm 99419.3984 (inf)	mem 14543MB
[2023-10-12 00:50:45 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2505 (0.2518)	loss 0.3649 (0.3621)	grad_norm 203786.1250 (inf)	mem 14543MB
[2023-10-12 00:52:51 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2538 (0.2518)	loss 0.3304 (0.3620)	grad_norm 193049.5000 (inf)	mem 14543MB
[2023-10-12 00:54:57 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2587 (0.2518)	loss 0.3694 (0.3618)	grad_norm 285247.9688 (inf)	mem 14543MB
[2023-10-12 00:57:02 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2504 (0.2518)	loss 0.3561 (0.3617)	grad_norm 334870.4375 (inf)	mem 14543MB
[2023-10-12 00:59:08 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2472 (0.2517)	loss 0.3654 (0.3615)	grad_norm 336901.1250 (inf)	mem 14543MB
[2023-10-12 01:01:14 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2558 (0.2517)	loss 0.3631 (0.3614)	grad_norm 312311.0938 (inf)	mem 14543MB
[2023-10-12 01:03:20 simmim_pretrain](main_simmim.py 218): INFO Train: [96/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2701 (0.2517)	loss 0.3649 (0.3612)	grad_norm 531862.7500 (inf)	mem 14543MB
[2023-10-12 01:04:32 simmim_pretrain](main_simmim.py 228): INFO EPOCH 96 training takes 0:28:28
[2023-10-12 01:04:34 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][0/6787]	eta 2:53:17 lr 0.000200	time 1.5319 (1.5319)	loss 0.3422 (0.3422)	grad_norm 364519.9062 (364519.9062)	mem 14543MB
[2023-10-12 01:06:39 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][500/6787]	eta 0:26:33 lr 0.000200	time 0.2500 (0.2535)	loss 0.3498 (0.3588)	grad_norm 413153.1562 (inf)	mem 14543MB
[2023-10-12 01:08:45 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][1000/6787]	eta 0:24:20 lr 0.000200	time 0.2476 (0.2524)	loss 0.3515 (0.3593)	grad_norm 416699.2812 (inf)	mem 14543MB
[2023-10-12 01:10:50 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][1500/6787]	eta 0:22:12 lr 0.000200	time 0.2503 (0.2521)	loss 0.3595 (0.3601)	grad_norm 188335.2656 (inf)	mem 14543MB
[2023-10-12 01:12:56 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][2000/6787]	eta 0:20:05 lr 0.000200	time 0.2513 (0.2518)	loss 0.3605 (0.3608)	grad_norm 159172.7031 (inf)	mem 14543MB
[2023-10-12 01:15:01 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2498 (0.2516)	loss 0.3568 (0.3612)	grad_norm 163809.4844 (inf)	mem 14543MB
[2023-10-12 01:17:07 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2538 (0.2515)	loss 0.3545 (0.3615)	grad_norm 129363.6953 (inf)	mem 14543MB
[2023-10-12 01:19:12 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2490 (0.2514)	loss 0.3679 (0.3617)	grad_norm 84584.1016 (inf)	mem 14543MB
[2023-10-12 01:21:18 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2564 (0.2513)	loss 0.3545 (0.3617)	grad_norm 236204.7031 (inf)	mem 14543MB
[2023-10-12 01:23:23 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2520 (0.2513)	loss 0.3555 (0.3616)	grad_norm 91257.7031 (inf)	mem 14543MB
[2023-10-12 01:25:28 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2459 (0.2512)	loss 0.3821 (0.3614)	grad_norm 192299.5156 (inf)	mem 14543MB
[2023-10-12 01:27:34 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2520 (0.2512)	loss 0.3765 (0.3613)	grad_norm 231435.8125 (inf)	mem 14543MB
[2023-10-12 01:29:40 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2518 (0.2512)	loss 0.3583 (0.3612)	grad_norm 230838.4219 (inf)	mem 14543MB
[2023-10-12 01:31:46 simmim_pretrain](main_simmim.py 218): INFO Train: [97/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2509 (0.2513)	loss 0.3828 (0.3611)	grad_norm 249152.5312 (inf)	mem 14543MB
[2023-10-12 01:32:59 simmim_pretrain](main_simmim.py 228): INFO EPOCH 97 training takes 0:28:26
[2023-10-12 01:33:00 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][0/6787]	eta 2:45:34 lr 0.000200	time 1.4638 (1.4638)	loss 0.3622 (0.3622)	grad_norm 291276.5938 (291276.5938)	mem 14543MB
[2023-10-12 01:35:06 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][500/6787]	eta 0:26:32 lr 0.000200	time 0.2512 (0.2534)	loss 0.3479 (0.3611)	grad_norm 338077.3750 (237961.6562)	mem 14543MB
[2023-10-12 01:37:12 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][1000/6787]	eta 0:24:22 lr 0.000200	time 0.2493 (0.2527)	loss 0.3441 (0.3609)	grad_norm 278081.3750 (243458.1406)	mem 14543MB
[2023-10-12 01:39:18 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][1500/6787]	eta 0:22:15 lr 0.000200	time 0.2590 (0.2526)	loss 0.3558 (0.3603)	grad_norm 653827.8125 (276654.0625)	mem 14543MB
[2023-10-12 01:41:24 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][2000/6787]	eta 0:20:08 lr 0.000200	time 0.2488 (0.2525)	loss 0.3495 (0.3601)	grad_norm 178403.3125 (inf)	mem 14543MB
[2023-10-12 01:43:30 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][2500/6787]	eta 0:18:02 lr 0.000200	time 0.2530 (0.2525)	loss 0.3604 (0.3601)	grad_norm 339051.9375 (inf)	mem 14543MB
[2023-10-12 01:45:37 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][3000/6787]	eta 0:15:56 lr 0.000200	time 0.2593 (0.2525)	loss 0.3737 (0.3600)	grad_norm 275548.2500 (inf)	mem 14543MB
[2023-10-12 01:47:43 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][3500/6787]	eta 0:13:50 lr 0.000200	time 0.2503 (0.2526)	loss 0.3631 (0.3600)	grad_norm 264094.0625 (inf)	mem 14543MB
[2023-10-12 01:49:49 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][4000/6787]	eta 0:11:43 lr 0.000200	time 0.2482 (0.2525)	loss 0.3779 (0.3600)	grad_norm 299249.4062 (inf)	mem 14543MB
[2023-10-12 01:51:55 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][4500/6787]	eta 0:09:37 lr 0.000200	time 0.2539 (0.2525)	loss 0.3538 (0.3602)	grad_norm 153941.1875 (nan)	mem 14543MB
[2023-10-12 01:54:03 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][5000/6787]	eta 0:07:31 lr 0.000200	time 0.2573 (0.2529)	loss 0.3554 (0.3605)	grad_norm 181709.2031 (nan)	mem 14543MB
[2023-10-12 01:56:12 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2581 (0.2533)	loss 0.3563 (0.3608)	grad_norm 181319.8750 (nan)	mem 14543MB
[2023-10-12 01:58:21 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2573 (0.2536)	loss 0.3728 (0.3612)	grad_norm 75110.2344 (nan)	mem 14543MB
[2023-10-12 02:00:30 simmim_pretrain](main_simmim.py 218): INFO Train: [98/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2578 (0.2539)	loss 0.3759 (0.3617)	grad_norm 73465.4375 (nan)	mem 14543MB
[2023-10-12 02:01:44 simmim_pretrain](main_simmim.py 228): INFO EPOCH 98 training takes 0:28:45
[2023-10-12 02:01:45 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][0/6787]	eta 2:55:50 lr 0.000200	time 1.5545 (1.5545)	loss 0.3537 (0.3537)	grad_norm 65805.4844 (65805.4844)	mem 14543MB
[2023-10-12 02:03:51 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][500/6787]	eta 0:26:31 lr 0.000200	time 0.2534 (0.2531)	loss 0.3779 (0.3640)	grad_norm 57297.2031 (64116.5977)	mem 14543MB
[2023-10-12 02:05:57 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][1000/6787]	eta 0:24:20 lr 0.000200	time 0.2533 (0.2524)	loss 0.3790 (0.3651)	grad_norm 70941.5391 (64241.7031)	mem 14543MB
[2023-10-12 02:08:02 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][1500/6787]	eta 0:22:13 lr 0.000200	time 0.2526 (0.2522)	loss 0.3404 (0.3641)	grad_norm 89075.2422 (69660.6641)	mem 14543MB
[2023-10-12 02:10:08 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][2000/6787]	eta 0:20:06 lr 0.000200	time 0.2496 (0.2521)	loss 0.3739 (0.3636)	grad_norm 75972.2344 (76073.1953)	mem 14543MB
[2023-10-12 02:12:14 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][2500/6787]	eta 0:18:00 lr 0.000200	time 0.2523 (0.2520)	loss 0.3731 (0.3634)	grad_norm 62650.6758 (81671.0547)	mem 14543MB
[2023-10-12 02:14:20 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][3000/6787]	eta 0:15:54 lr 0.000200	time 0.2512 (0.2520)	loss 0.3580 (0.3632)	grad_norm 137453.0781 (85854.5703)	mem 14543MB
[2023-10-12 02:16:26 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][3500/6787]	eta 0:13:48 lr 0.000200	time 0.2500 (0.2520)	loss 0.3592 (0.3628)	grad_norm 276063.9062 (93401.7188)	mem 14543MB
[2023-10-12 02:18:32 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2504 (0.2520)	loss 0.3813 (0.3625)	grad_norm 192551.4375 (103270.8281)	mem 14543MB
[2023-10-12 02:20:38 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2540 (0.2520)	loss 0.3612 (0.3623)	grad_norm 157966.5938 (inf)	mem 14543MB
[2023-10-12 02:22:44 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2591 (0.2520)	loss 0.3608 (0.3623)	grad_norm 126726.2969 (inf)	mem 14543MB
[2023-10-12 02:24:50 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2490 (0.2520)	loss 0.3756 (0.3622)	grad_norm 124848.4609 (inf)	mem 14543MB
[2023-10-12 02:26:57 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2599 (0.2521)	loss 0.3770 (0.3623)	grad_norm 144055.2500 (inf)	mem 14543MB
[2023-10-12 02:29:03 simmim_pretrain](main_simmim.py 218): INFO Train: [99/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2597 (0.2521)	loss 0.3378 (0.3622)	grad_norm 181633.9844 (inf)	mem 14543MB
[2023-10-12 02:30:16 simmim_pretrain](main_simmim.py 228): INFO EPOCH 99 training takes 0:28:31
[2023-10-12 02:30:17 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][0/6787]	eta 2:41:47 lr 0.000200	time 1.4303 (1.4303)	loss 0.3415 (0.3415)	grad_norm 178395.6406 (178395.6406)	mem 14543MB
[2023-10-12 02:32:23 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][500/6787]	eta 0:26:32 lr 0.000200	time 0.2483 (0.2533)	loss 0.3766 (0.3603)	grad_norm 277789.6875 (171691.6094)	mem 14543MB
[2023-10-12 02:34:28 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][1000/6787]	eta 0:24:20 lr 0.000200	time 0.2527 (0.2524)	loss 0.3692 (0.3605)	grad_norm 183919.0781 (181329.0156)	mem 14543MB
[2023-10-12 02:36:34 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][1500/6787]	eta 0:22:12 lr 0.000200	time 0.2463 (0.2520)	loss 0.3559 (0.3600)	grad_norm 154250.5781 (208835.6094)	mem 14543MB
[2023-10-12 02:38:39 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][2000/6787]	eta 0:20:05 lr 0.000200	time 0.2529 (0.2517)	loss 0.3514 (0.3597)	grad_norm 241654.4219 (221784.2344)	mem 14543MB
[2023-10-12 02:40:45 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2483 (0.2516)	loss 0.3692 (0.3592)	grad_norm 243274.0000 (243056.1094)	mem 14543MB
[2023-10-12 02:42:50 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2517 (0.2514)	loss 0.3677 (0.3593)	grad_norm 377185.2188 (255469.4688)	mem 14543MB
[2023-10-12 02:44:56 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2503 (0.2514)	loss 0.3582 (0.3592)	grad_norm 296182.0938 (inf)	mem 14543MB
[2023-10-12 02:47:02 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2520 (0.2514)	loss 0.3682 (0.3592)	grad_norm 281465.1562 (inf)	mem 14543MB
[2023-10-12 02:49:07 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2464 (0.2514)	loss 0.3634 (0.3592)	grad_norm 170077.6562 (inf)	mem 14543MB
[2023-10-12 02:51:13 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2512 (0.2514)	loss 0.3968 (0.3593)	grad_norm 97890.8047 (inf)	mem 14543MB
[2023-10-12 02:53:19 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2502 (0.2514)	loss 0.3701 (0.3593)	grad_norm 229536.2969 (inf)	mem 14543MB
[2023-10-12 02:55:25 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2537 (0.2514)	loss 0.3568 (0.3593)	grad_norm 325122.0625 (inf)	mem 14543MB
[2023-10-12 02:57:33 simmim_pretrain](main_simmim.py 218): INFO Train: [100/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2569 (0.2518)	loss 0.3482 (0.3593)	grad_norm 341409.8438 (inf)	mem 14543MB
[2023-10-12 02:58:47 simmim_pretrain](main_simmim.py 228): INFO EPOCH 100 training takes 0:28:31
[2023-10-12 02:58:47 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_100.pth saving......
[2023-10-12 02:58:48 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_100.pth saved !!!
[2023-10-12 02:58:49 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][0/6787]	eta 2:30:44 lr 0.000200	time 1.3327 (1.3327)	loss 0.3659 (0.3659)	grad_norm 277496.2500 (277496.2500)	mem 14543MB
[2023-10-12 03:00:55 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][500/6787]	eta 0:26:33 lr 0.000200	time 0.2546 (0.2535)	loss 0.3800 (0.3581)	grad_norm 271890.7812 (374255.9688)	mem 14543MB
[2023-10-12 03:03:01 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][1000/6787]	eta 0:24:22 lr 0.000200	time 0.2483 (0.2527)	loss 0.3794 (0.3588)	grad_norm 330771.1562 (inf)	mem 14543MB
[2023-10-12 03:05:08 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][1500/6787]	eta 0:22:18 lr 0.000200	time 0.2548 (0.2531)	loss 0.3560 (0.3586)	grad_norm 174398.2344 (inf)	mem 14543MB
[2023-10-12 03:07:15 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][2000/6787]	eta 0:20:12 lr 0.000200	time 0.2535 (0.2533)	loss 0.3580 (0.3588)	grad_norm 265289.6562 (inf)	mem 14543MB
[2023-10-12 03:09:22 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][2500/6787]	eta 0:18:06 lr 0.000200	time 0.2548 (0.2534)	loss 0.3587 (0.3592)	grad_norm 203074.8594 (inf)	mem 14543MB
[2023-10-12 03:11:29 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][3000/6787]	eta 0:16:00 lr 0.000200	time 0.2545 (0.2535)	loss 0.3532 (0.3594)	grad_norm 335170.5625 (inf)	mem 14543MB
[2023-10-12 03:13:35 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][3500/6787]	eta 0:13:53 lr 0.000200	time 0.2531 (0.2535)	loss 0.3747 (0.3595)	grad_norm 210431.0156 (inf)	mem 14543MB
[2023-10-12 03:15:43 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][4000/6787]	eta 0:11:46 lr 0.000200	time 0.2533 (0.2536)	loss 0.3657 (0.3595)	grad_norm 286953.2188 (inf)	mem 14543MB
[2023-10-12 03:17:49 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][4500/6787]	eta 0:09:40 lr 0.000200	time 0.2526 (0.2536)	loss 0.3536 (0.3594)	grad_norm 355317.6562 (inf)	mem 14543MB
[2023-10-12 03:19:56 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][5000/6787]	eta 0:07:33 lr 0.000200	time 0.2541 (0.2537)	loss 0.3372 (0.3593)	grad_norm 365518.5312 (inf)	mem 14543MB
[2023-10-12 03:22:03 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2524 (0.2537)	loss 0.3708 (0.3595)	grad_norm 208737.4062 (inf)	mem 14543MB
[2023-10-12 03:24:10 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2541 (0.2537)	loss 0.3531 (0.3595)	grad_norm 82415.5078 (inf)	mem 14543MB
[2023-10-12 03:26:17 simmim_pretrain](main_simmim.py 218): INFO Train: [101/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2535 (0.2537)	loss 0.3573 (0.3596)	grad_norm 162724.8438 (inf)	mem 14543MB
[2023-10-12 03:27:30 simmim_pretrain](main_simmim.py 228): INFO EPOCH 101 training takes 0:28:42
[2023-10-12 03:27:32 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][0/6787]	eta 2:47:31 lr 0.000200	time 1.4810 (1.4810)	loss 0.3605 (0.3605)	grad_norm 239233.9844 (239233.9844)	mem 14543MB
[2023-10-12 03:29:37 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][500/6787]	eta 0:26:31 lr 0.000200	time 0.2485 (0.2531)	loss 0.3649 (0.3589)	grad_norm 235283.1406 (283245.0938)	mem 14543MB
[2023-10-12 03:31:42 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2515 (0.2519)	loss 0.3581 (0.3584)	grad_norm 713913.6250 (330579.7812)	mem 14543MB
[2023-10-12 03:33:48 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2515 (0.2516)	loss 0.3636 (0.3587)	grad_norm 139662.3594 (inf)	mem 14543MB
[2023-10-12 03:35:54 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][2000/6787]	eta 0:20:04 lr 0.000200	time 0.2500 (0.2515)	loss 0.3528 (0.3598)	grad_norm 173560.1562 (inf)	mem 14543MB
[2023-10-12 03:37:59 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][2500/6787]	eta 0:17:57 lr 0.000200	time 0.2527 (0.2515)	loss 0.3590 (0.3602)	grad_norm 130914.5703 (inf)	mem 14543MB
[2023-10-12 03:40:05 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2551 (0.2514)	loss 0.3533 (0.3607)	grad_norm 103083.4766 (inf)	mem 14543MB
[2023-10-12 03:42:12 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2571 (0.2517)	loss 0.3387 (0.3608)	grad_norm 133232.7812 (inf)	mem 14543MB
[2023-10-12 03:44:20 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][4000/6787]	eta 0:11:43 lr 0.000200	time 0.2510 (0.2523)	loss 0.3599 (0.3608)	grad_norm 233490.5938 (inf)	mem 14543MB
[2023-10-12 03:46:28 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][4500/6787]	eta 0:09:37 lr 0.000200	time 0.2579 (0.2527)	loss 0.3705 (0.3607)	grad_norm 205447.2500 (inf)	mem 14543MB
[2023-10-12 03:48:36 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][5000/6787]	eta 0:07:32 lr 0.000200	time 0.2500 (0.2530)	loss 0.3592 (0.3606)	grad_norm 286590.4375 (inf)	mem 14543MB
[2023-10-12 03:50:44 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2504 (0.2533)	loss 0.3661 (0.3605)	grad_norm 182781.5938 (inf)	mem 14543MB
[2023-10-12 03:52:52 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2547 (0.2535)	loss 0.3656 (0.3603)	grad_norm 478015.0312 (inf)	mem 14543MB
[2023-10-12 03:55:00 simmim_pretrain](main_simmim.py 218): INFO Train: [102/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2554 (0.2537)	loss 0.3759 (0.3602)	grad_norm 283926.3750 (inf)	mem 14543MB
[2023-10-12 03:56:14 simmim_pretrain](main_simmim.py 228): INFO EPOCH 102 training takes 0:28:43
[2023-10-12 03:56:15 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][0/6787]	eta 2:45:59 lr 0.000200	time 1.4675 (1.4675)	loss 0.3634 (0.3634)	grad_norm 388951.9062 (388951.9062)	mem 14543MB
[2023-10-12 03:58:20 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][500/6787]	eta 0:26:32 lr 0.000200	time 0.2503 (0.2532)	loss 0.3666 (0.3591)	grad_norm 154496.8594 (246824.7188)	mem 14543MB
[2023-10-12 04:00:26 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][1000/6787]	eta 0:24:19 lr 0.000200	time 0.2494 (0.2521)	loss 0.3690 (0.3599)	grad_norm 312323.1875 (240409.6250)	mem 14543MB
[2023-10-12 04:02:32 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][1500/6787]	eta 0:22:11 lr 0.000200	time 0.2484 (0.2518)	loss 0.3775 (0.3602)	grad_norm 263561.6250 (236388.0312)	mem 14543MB
[2023-10-12 04:04:37 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][2000/6787]	eta 0:20:04 lr 0.000200	time 0.2511 (0.2517)	loss 0.3555 (0.3601)	grad_norm 306334.1875 (261472.4531)	mem 14543MB
[2023-10-12 04:06:43 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2511 (0.2517)	loss 0.3403 (0.3596)	grad_norm 410641.6875 (280779.8125)	mem 14543MB
[2023-10-12 04:08:49 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2567 (0.2516)	loss 0.3648 (0.3594)	grad_norm 538252.2500 (299305.2188)	mem 14543MB
[2023-10-12 04:10:54 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2521 (0.2515)	loss 0.3670 (0.3592)	grad_norm 327268.6875 (312771.9062)	mem 14543MB
[2023-10-12 04:13:00 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2463 (0.2515)	loss 0.3620 (0.3591)	grad_norm 502099.7500 (inf)	mem 14543MB
[2023-10-12 04:15:05 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2498 (0.2514)	loss 0.3493 (0.3592)	grad_norm 372024.2812 (inf)	mem 14543MB
[2023-10-12 04:17:11 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2508 (0.2513)	loss 0.3617 (0.3590)	grad_norm 334053.9688 (inf)	mem 14543MB
[2023-10-12 04:19:16 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2471 (0.2513)	loss 0.3563 (0.3589)	grad_norm 511195.5938 (inf)	mem 14543MB
[2023-10-12 04:21:21 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2466 (0.2513)	loss 0.3725 (0.3589)	grad_norm 328542.8750 (inf)	mem 14543MB
[2023-10-12 04:23:27 simmim_pretrain](main_simmim.py 218): INFO Train: [103/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2521 (0.2513)	loss 0.3769 (0.3589)	grad_norm 317993.0938 (inf)	mem 14543MB
[2023-10-12 04:24:40 simmim_pretrain](main_simmim.py 228): INFO EPOCH 103 training takes 0:28:26
[2023-10-12 04:24:41 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][0/6787]	eta 2:45:45 lr 0.000200	time 1.4653 (1.4653)	loss 0.3562 (0.3562)	grad_norm 331690.6875 (331690.6875)	mem 14543MB
[2023-10-12 04:26:46 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][500/6787]	eta 0:26:29 lr 0.000200	time 0.2495 (0.2528)	loss 0.3557 (0.3609)	grad_norm 312228.6562 (253819.3906)	mem 14543MB
[2023-10-12 04:28:52 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2522 (0.2518)	loss 0.3658 (0.3600)	grad_norm 129873.7891 (247006.0625)	mem 14543MB
[2023-10-12 04:30:57 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2526 (0.2516)	loss 0.3589 (0.3598)	grad_norm 264976.5000 (inf)	mem 14543MB
[2023-10-12 04:33:03 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][2000/6787]	eta 0:20:03 lr 0.000200	time 0.2498 (0.2514)	loss 0.3463 (0.3599)	grad_norm 259917.6719 (inf)	mem 14543MB
[2023-10-12 04:35:08 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][2500/6787]	eta 0:17:57 lr 0.000200	time 0.2497 (0.2514)	loss 0.3566 (0.3600)	grad_norm 278851.9375 (inf)	mem 14543MB
[2023-10-12 04:37:14 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2457 (0.2515)	loss 0.3486 (0.3601)	grad_norm 412786.8125 (inf)	mem 14543MB
[2023-10-12 04:39:20 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2509 (0.2515)	loss 0.3594 (0.3602)	grad_norm 536714.4375 (inf)	mem 14543MB
[2023-10-12 04:41:26 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2519 (0.2515)	loss 0.3548 (0.3600)	grad_norm 200400.7500 (inf)	mem 14543MB
[2023-10-12 04:43:32 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2588 (0.2515)	loss 0.3731 (0.3600)	grad_norm 433506.9062 (inf)	mem 14543MB
[2023-10-12 04:45:37 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2452 (0.2514)	loss 0.3589 (0.3597)	grad_norm 257062.3594 (inf)	mem 14543MB
[2023-10-12 04:47:42 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2592 (0.2513)	loss 0.3514 (0.3596)	grad_norm 586824.7500 (inf)	mem 14543MB
[2023-10-12 04:49:47 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2457 (0.2513)	loss 0.3551 (0.3596)	grad_norm 272321.3750 (inf)	mem 14543MB
[2023-10-12 04:51:53 simmim_pretrain](main_simmim.py 218): INFO Train: [104/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2519 (0.2512)	loss 0.3628 (0.3596)	grad_norm 282600.7188 (inf)	mem 14543MB
[2023-10-12 04:53:05 simmim_pretrain](main_simmim.py 228): INFO EPOCH 104 training takes 0:28:25
[2023-10-12 04:53:06 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][0/6787]	eta 2:54:23 lr 0.000200	time 1.5417 (1.5417)	loss 0.5384 (0.5384)	grad_norm 2427.8015 (2427.8015)	mem 14543MB
[2023-10-12 04:55:11 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][500/6787]	eta 0:26:23 lr 0.000200	time 0.2588 (0.2518)	loss 0.4678 (0.5064)	grad_norm 18258.2773 (14356.2832)	mem 14543MB
[2023-10-12 04:57:16 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2500 (0.2509)	loss 0.4496 (0.4927)	grad_norm 28690.3828 (19231.4727)	mem 14543MB
[2023-10-12 04:59:21 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][1500/6787]	eta 0:22:05 lr 0.000200	time 0.2470 (0.2506)	loss 0.4636 (0.4832)	grad_norm 27178.0293 (21687.2891)	mem 14543MB
[2023-10-12 05:01:26 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][2000/6787]	eta 0:19:59 lr 0.000200	time 0.2515 (0.2506)	loss 0.3869 (0.4685)	grad_norm 17513.5566 (22290.4648)	mem 14543MB
[2023-10-12 05:03:31 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][2500/6787]	eta 0:17:54 lr 0.000200	time 0.2479 (0.2505)	loss 0.3787 (0.4520)	grad_norm 40133.2852 (23639.5371)	mem 14543MB
[2023-10-12 05:05:37 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][3000/6787]	eta 0:15:49 lr 0.000200	time 0.2528 (0.2506)	loss 0.3680 (0.4389)	grad_norm 22285.3926 (24396.3906)	mem 14543MB
[2023-10-12 05:07:42 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][3500/6787]	eta 0:13:43 lr 0.000200	time 0.2498 (0.2506)	loss 0.3663 (0.4291)	grad_norm 34334.0352 (24714.7715)	mem 14543MB
[2023-10-12 05:09:48 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2502 (0.2507)	loss 0.3597 (0.4215)	grad_norm 32990.3320 (25432.3164)	mem 14543MB
[2023-10-12 05:11:53 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2489 (0.2507)	loss 0.3578 (0.4151)	grad_norm 43911.1484 (26786.4238)	mem 14543MB
[2023-10-12 05:13:59 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2501 (0.2508)	loss 0.3374 (0.4100)	grad_norm 35386.1406 (28362.8418)	mem 14543MB
[2023-10-12 05:16:04 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2518 (0.2508)	loss 0.3786 (0.4059)	grad_norm 35993.1016 (29983.7969)	mem 14543MB
[2023-10-12 05:18:10 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2540 (0.2508)	loss 0.3670 (0.4023)	grad_norm 40629.6562 (31884.3008)	mem 14543MB
[2023-10-12 05:20:16 simmim_pretrain](main_simmim.py 218): INFO Train: [105/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2541 (0.2509)	loss 0.3624 (0.3993)	grad_norm 142373.7188 (35564.3711)	mem 14543MB
[2023-10-12 05:21:28 simmim_pretrain](main_simmim.py 228): INFO EPOCH 105 training takes 0:28:23
[2023-10-12 05:21:29 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][0/6787]	eta 2:34:57 lr 0.000200	time 1.3699 (1.3699)	loss 0.3637 (0.3637)	grad_norm 107006.6250 (107006.6250)	mem 14543MB
[2023-10-12 05:23:35 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2496 (0.2529)	loss 0.3541 (0.3615)	grad_norm 70954.7500 (79706.2109)	mem 14543MB
[2023-10-12 05:25:40 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2501 (0.2519)	loss 0.3731 (0.3618)	grad_norm 82121.7578 (81669.6719)	mem 14543MB
[2023-10-12 05:27:45 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][1500/6787]	eta 0:22:09 lr 0.000200	time 0.2522 (0.2514)	loss 0.3672 (0.3614)	grad_norm 98132.1172 (92123.9922)	mem 14543MB
[2023-10-12 05:29:51 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2461 (0.2512)	loss 0.3619 (0.3611)	grad_norm 108209.9219 (103156.9297)	mem 14543MB
[2023-10-12 05:31:56 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2487 (0.2510)	loss 0.3692 (0.3606)	grad_norm 156429.3594 (120361.1094)	mem 14543MB
[2023-10-12 05:34:01 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2536 (0.2509)	loss 0.3554 (0.3604)	grad_norm 113663.1094 (126584.4766)	mem 14543MB
[2023-10-12 05:36:06 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][3500/6787]	eta 0:13:44 lr 0.000200	time 0.2474 (0.2509)	loss 0.3676 (0.3603)	grad_norm 152326.6094 (139064.1719)	mem 14543MB
[2023-10-12 05:38:12 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2495 (0.2508)	loss 0.3594 (0.3600)	grad_norm 213698.9375 (152384.1719)	mem 14543MB
[2023-10-12 05:40:17 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2524 (0.2508)	loss 0.3544 (0.3599)	grad_norm 368539.8125 (166747.6250)	mem 14543MB
[2023-10-12 05:42:22 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2535 (0.2508)	loss 0.3537 (0.3597)	grad_norm 456558.5938 (182570.6094)	mem 14543MB
[2023-10-12 05:44:28 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2543 (0.2508)	loss 0.3507 (0.3596)	grad_norm 244715.2031 (inf)	mem 14543MB
[2023-10-12 05:46:33 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2484 (0.2508)	loss 0.3396 (0.3594)	grad_norm 326379.0938 (inf)	mem 14543MB
[2023-10-12 05:48:38 simmim_pretrain](main_simmim.py 218): INFO Train: [106/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2486 (0.2507)	loss 0.3535 (0.3593)	grad_norm 285244.6250 (inf)	mem 14543MB
[2023-10-12 05:49:51 simmim_pretrain](main_simmim.py 228): INFO EPOCH 106 training takes 0:28:22
[2023-10-12 05:49:52 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][0/6787]	eta 2:49:51 lr 0.000200	time 1.5015 (1.5015)	loss 0.3506 (0.3506)	grad_norm 316355.0625 (316355.0625)	mem 14543MB
[2023-10-12 05:51:57 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][500/6787]	eta 0:26:28 lr 0.000200	time 0.2463 (0.2526)	loss 0.3558 (0.3577)	grad_norm 578327.2500 (inf)	mem 14543MB
[2023-10-12 05:54:02 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][1000/6787]	eta 0:24:16 lr 0.000200	time 0.2483 (0.2517)	loss 0.3654 (0.3587)	grad_norm 231278.6250 (inf)	mem 14543MB
[2023-10-12 05:56:08 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][1500/6787]	eta 0:22:07 lr 0.000200	time 0.2510 (0.2512)	loss 0.3700 (0.3591)	grad_norm 187624.9844 (inf)	mem 14543MB
[2023-10-12 05:58:13 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][2000/6787]	eta 0:20:01 lr 0.000200	time 0.2550 (0.2510)	loss 0.3776 (0.3596)	grad_norm 314052.6562 (inf)	mem 14543MB
[2023-10-12 06:00:18 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2494 (0.2509)	loss 0.3720 (0.3596)	grad_norm 129498.7891 (inf)	mem 14543MB
[2023-10-12 06:02:23 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][3000/6787]	eta 0:15:49 lr 0.000200	time 0.2510 (0.2508)	loss 0.3557 (0.3596)	grad_norm 204868.2344 (inf)	mem 14543MB
[2023-10-12 06:04:28 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][3500/6787]	eta 0:13:43 lr 0.000200	time 0.2475 (0.2507)	loss 0.3616 (0.3596)	grad_norm 200137.6562 (inf)	mem 14543MB
[2023-10-12 06:06:33 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2499 (0.2507)	loss 0.3693 (0.3596)	grad_norm 111547.7109 (inf)	mem 14543MB
[2023-10-12 06:08:39 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2448 (0.2507)	loss 0.3844 (0.3597)	grad_norm 409323.9375 (inf)	mem 14543MB
[2023-10-12 06:10:44 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2502 (0.2506)	loss 0.3459 (0.3598)	grad_norm 171679.5156 (inf)	mem 14543MB
[2023-10-12 06:12:49 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2484 (0.2507)	loss 0.3553 (0.3597)	grad_norm 234578.7031 (inf)	mem 14543MB
[2023-10-12 06:14:55 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2516 (0.2507)	loss 0.3621 (0.3596)	grad_norm 414758.6250 (inf)	mem 14543MB
[2023-10-12 06:17:00 simmim_pretrain](main_simmim.py 218): INFO Train: [107/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2508 (0.2507)	loss 0.3619 (0.3594)	grad_norm 418682.9375 (inf)	mem 14543MB
[2023-10-12 06:18:13 simmim_pretrain](main_simmim.py 228): INFO EPOCH 107 training takes 0:28:22
[2023-10-12 06:18:14 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][0/6787]	eta 2:47:03 lr 0.000200	time 1.4769 (1.4769)	loss 0.3466 (0.3466)	grad_norm 216161.0469 (216161.0469)	mem 14543MB
[2023-10-12 06:20:20 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][500/6787]	eta 0:26:31 lr 0.000200	time 0.2471 (0.2531)	loss 0.3505 (0.3572)	grad_norm 317402.1250 (435890.6250)	mem 14543MB
[2023-10-12 06:22:25 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2541 (0.2519)	loss 0.3769 (0.3583)	grad_norm 199202.3281 (inf)	mem 14543MB
[2023-10-12 06:24:30 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][1500/6787]	eta 0:22:09 lr 0.000200	time 0.2504 (0.2515)	loss 0.3549 (0.3586)	grad_norm 323367.7188 (inf)	mem 14543MB
[2023-10-12 06:26:36 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2494 (0.2513)	loss 0.3648 (0.3591)	grad_norm 212898.8438 (inf)	mem 14543MB
[2023-10-12 06:28:41 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2504 (0.2511)	loss 0.3701 (0.3591)	grad_norm 251535.2812 (inf)	mem 14543MB
[2023-10-12 06:30:46 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2509 (0.2511)	loss 0.3601 (0.3589)	grad_norm 176810.5938 (inf)	mem 14543MB
[2023-10-12 06:32:51 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2554 (0.2510)	loss 0.3537 (0.3589)	grad_norm 206705.0938 (inf)	mem 14543MB
[2023-10-12 06:34:57 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2590 (0.2509)	loss 0.3576 (0.3587)	grad_norm 494662.0938 (inf)	mem 14543MB
[2023-10-12 06:37:02 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2505 (0.2509)	loss 0.3723 (0.3587)	grad_norm 213262.2031 (inf)	mem 14543MB
[2023-10-12 06:39:07 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2511 (0.2508)	loss 0.3730 (0.3586)	grad_norm 352535.3750 (inf)	mem 14543MB
[2023-10-12 06:41:12 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2485 (0.2508)	loss 0.3594 (0.3585)	grad_norm 414309.1875 (inf)	mem 14543MB
[2023-10-12 06:43:17 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2512 (0.2507)	loss 0.3724 (0.3585)	grad_norm 244333.7656 (inf)	mem 14543MB
[2023-10-12 06:45:23 simmim_pretrain](main_simmim.py 218): INFO Train: [108/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2468 (0.2507)	loss 0.3579 (0.3585)	grad_norm 219809.8594 (inf)	mem 14543MB
[2023-10-12 06:46:35 simmim_pretrain](main_simmim.py 228): INFO EPOCH 108 training takes 0:28:21
[2023-10-12 06:46:36 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][0/6787]	eta 2:41:43 lr 0.000200	time 1.4297 (1.4297)	loss 0.3473 (0.3473)	grad_norm 258234.1094 (258234.1094)	mem 14543MB
[2023-10-12 06:48:41 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][500/6787]	eta 0:26:26 lr 0.000200	time 0.2482 (0.2523)	loss 0.3687 (0.3605)	grad_norm 356237.1875 (215263.0781)	mem 14543MB
[2023-10-12 06:50:46 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][1000/6787]	eta 0:24:13 lr 0.000200	time 0.2487 (0.2512)	loss 0.3492 (0.3602)	grad_norm 235034.3906 (225949.5469)	mem 14543MB
[2023-10-12 06:52:51 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][1500/6787]	eta 0:22:06 lr 0.000200	time 0.2459 (0.2509)	loss 0.3704 (0.3602)	grad_norm 202601.5469 (inf)	mem 14543MB
[2023-10-12 06:54:56 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][2000/6787]	eta 0:20:00 lr 0.000200	time 0.2496 (0.2507)	loss 0.3417 (0.3603)	grad_norm 274599.2188 (inf)	mem 14543MB
[2023-10-12 06:57:02 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][2500/6787]	eta 0:17:54 lr 0.000200	time 0.2581 (0.2507)	loss 0.3493 (0.3604)	grad_norm 163099.1562 (inf)	mem 14543MB
[2023-10-12 06:59:07 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][3000/6787]	eta 0:15:48 lr 0.000200	time 0.2528 (0.2506)	loss 0.3497 (0.3603)	grad_norm 240821.7969 (inf)	mem 14543MB
[2023-10-12 07:01:12 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][3500/6787]	eta 0:13:43 lr 0.000200	time 0.2484 (0.2505)	loss 0.3735 (0.3602)	grad_norm 322012.6250 (inf)	mem 14543MB
[2023-10-12 07:03:17 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2524 (0.2506)	loss 0.3626 (0.3600)	grad_norm 196154.6875 (inf)	mem 14543MB
[2023-10-12 07:05:23 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2559 (0.2506)	loss 0.3628 (0.3597)	grad_norm 362395.7188 (inf)	mem 14543MB
[2023-10-12 07:07:28 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2537 (0.2506)	loss 0.3495 (0.3595)	grad_norm 383274.4062 (inf)	mem 14543MB
[2023-10-12 07:09:33 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2546 (0.2506)	loss 0.3635 (0.3594)	grad_norm 354818.5938 (inf)	mem 14543MB
[2023-10-12 07:11:39 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2589 (0.2506)	loss 0.3711 (0.3593)	grad_norm 598589.8750 (inf)	mem 14543MB
[2023-10-12 07:13:44 simmim_pretrain](main_simmim.py 218): INFO Train: [109/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2480 (0.2506)	loss 0.3491 (0.3591)	grad_norm 368270.1875 (inf)	mem 14543MB
[2023-10-12 07:14:56 simmim_pretrain](main_simmim.py 228): INFO EPOCH 109 training takes 0:28:21
[2023-10-12 07:14:58 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][0/6787]	eta 2:40:02 lr 0.000200	time 1.4149 (1.4149)	loss 0.3750 (0.3750)	grad_norm 858921.2500 (858921.2500)	mem 14543MB
[2023-10-12 07:17:03 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][500/6787]	eta 0:26:26 lr 0.000200	time 0.2588 (0.2524)	loss 0.3347 (0.3577)	grad_norm 551103.6875 (433006.8438)	mem 14543MB
[2023-10-12 07:19:08 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][1000/6787]	eta 0:24:14 lr 0.000200	time 0.2511 (0.2513)	loss 0.3618 (0.3576)	grad_norm 418321.0938 (421670.2500)	mem 14543MB
[2023-10-12 07:21:13 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][1500/6787]	eta 0:22:06 lr 0.000200	time 0.2461 (0.2509)	loss 0.3757 (0.3577)	grad_norm 719537.0625 (inf)	mem 14543MB
[2023-10-12 07:23:18 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][2000/6787]	eta 0:20:00 lr 0.000200	time 0.2482 (0.2508)	loss 0.3536 (0.3580)	grad_norm 291218.4688 (inf)	mem 14543MB
[2023-10-12 07:25:23 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][2500/6787]	eta 0:17:54 lr 0.000200	time 0.2469 (0.2507)	loss 0.3558 (0.3586)	grad_norm 141681.6250 (inf)	mem 14543MB
[2023-10-12 07:27:28 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][3000/6787]	eta 0:15:49 lr 0.000200	time 0.2459 (0.2506)	loss 0.3619 (0.3588)	grad_norm 186532.3594 (inf)	mem 14543MB
[2023-10-12 07:29:34 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][3500/6787]	eta 0:13:43 lr 0.000200	time 0.2591 (0.2506)	loss 0.3370 (0.3589)	grad_norm 225808.6250 (inf)	mem 14543MB
[2023-10-12 07:31:39 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2473 (0.2506)	loss 0.3567 (0.3590)	grad_norm 679506.2500 (inf)	mem 14543MB
[2023-10-12 07:33:44 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2451 (0.2505)	loss 0.3643 (0.3591)	grad_norm 210184.6406 (inf)	mem 14543MB
[2023-10-12 07:35:49 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2460 (0.2505)	loss 0.3540 (0.3590)	grad_norm 498058.8750 (inf)	mem 14543MB
[2023-10-12 07:37:54 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2467 (0.2505)	loss 0.3488 (0.3590)	grad_norm 514772.0938 (inf)	mem 14543MB
[2023-10-12 07:39:59 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2523 (0.2505)	loss 0.3823 (0.3590)	grad_norm 313216.3438 (inf)	mem 14543MB
[2023-10-12 07:42:05 simmim_pretrain](main_simmim.py 218): INFO Train: [110/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2509 (0.2505)	loss 0.3571 (0.3590)	grad_norm 228159.7500 (inf)	mem 14543MB
[2023-10-12 07:43:17 simmim_pretrain](main_simmim.py 228): INFO EPOCH 110 training takes 0:28:20
[2023-10-12 07:43:18 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][0/6787]	eta 2:44:51 lr 0.000200	time 1.4574 (1.4574)	loss 0.3666 (0.3666)	grad_norm 255650.8281 (255650.8281)	mem 14543MB
[2023-10-12 07:45:23 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][500/6787]	eta 0:26:25 lr 0.000200	time 0.2515 (0.2523)	loss 0.3599 (0.3585)	grad_norm 255126.9375 (251659.5156)	mem 14543MB
[2023-10-12 07:47:28 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][1000/6787]	eta 0:24:12 lr 0.000200	time 0.2556 (0.2511)	loss 0.3324 (0.3592)	grad_norm 223996.7031 (244435.8281)	mem 14543MB
[2023-10-12 07:49:33 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][1500/6787]	eta 0:22:05 lr 0.000200	time 0.2468 (0.2508)	loss 0.3531 (0.3593)	grad_norm 177591.2188 (254222.7969)	mem 14543MB
[2023-10-12 07:51:38 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][2000/6787]	eta 0:19:59 lr 0.000200	time 0.2447 (0.2505)	loss 0.3572 (0.3590)	grad_norm 293143.2500 (279598.5312)	mem 14543MB
[2023-10-12 07:53:43 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][2500/6787]	eta 0:17:53 lr 0.000200	time 0.2485 (0.2504)	loss 0.3643 (0.3590)	grad_norm 393097.0625 (293700.0938)	mem 14543MB
[2023-10-12 07:55:48 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][3000/6787]	eta 0:15:48 lr 0.000200	time 0.2476 (0.2504)	loss 0.3497 (0.3586)	grad_norm 633481.9375 (315096.1250)	mem 14543MB
[2023-10-12 07:57:54 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][3500/6787]	eta 0:13:43 lr 0.000200	time 0.2511 (0.2504)	loss 0.3391 (0.3584)	grad_norm 891781.8750 (inf)	mem 14543MB
[2023-10-12 07:59:59 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][4000/6787]	eta 0:11:37 lr 0.000200	time 0.2486 (0.2504)	loss 0.3593 (0.3584)	grad_norm 750587.6875 (inf)	mem 14543MB
[2023-10-12 08:02:04 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2475 (0.2504)	loss 0.3471 (0.3586)	grad_norm 156999.4844 (inf)	mem 14543MB
[2023-10-12 08:04:09 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2505 (0.2504)	loss 0.3499 (0.3587)	grad_norm 231542.8906 (inf)	mem 14543MB
[2023-10-12 08:06:14 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2502 (0.2504)	loss 0.3472 (0.3589)	grad_norm 91620.5469 (inf)	mem 14543MB
[2023-10-12 08:08:20 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2483 (0.2504)	loss 0.3683 (0.3593)	grad_norm 152272.5156 (inf)	mem 14543MB
[2023-10-12 08:10:27 simmim_pretrain](main_simmim.py 218): INFO Train: [111/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2547 (0.2508)	loss 0.3408 (0.3595)	grad_norm 132867.4844 (inf)	mem 14543MB
[2023-10-12 08:11:41 simmim_pretrain](main_simmim.py 228): INFO EPOCH 111 training takes 0:28:24
[2023-10-12 08:11:42 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][0/6787]	eta 2:56:52 lr 0.000200	time 1.5637 (1.5637)	loss 0.3633 (0.3633)	grad_norm 182611.2969 (182611.2969)	mem 14543MB
[2023-10-12 08:13:48 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2501 (0.2530)	loss 0.3850 (0.3622)	grad_norm 93117.5859 (130352.5156)	mem 14543MB
[2023-10-12 08:15:53 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][1000/6787]	eta 0:24:16 lr 0.000200	time 0.2466 (0.2517)	loss 0.3696 (0.3615)	grad_norm 152613.9219 (145454.0000)	mem 14543MB
[2023-10-12 08:17:58 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][1500/6787]	eta 0:22:08 lr 0.000200	time 0.2592 (0.2512)	loss 0.3352 (0.3608)	grad_norm 114691.8047 (161896.9688)	mem 14543MB
[2023-10-12 08:20:03 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][2000/6787]	eta 0:20:01 lr 0.000200	time 0.2521 (0.2510)	loss 0.3617 (0.3604)	grad_norm 90712.2188 (173063.3438)	mem 14543MB
[2023-10-12 08:22:08 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2506 (0.2509)	loss 0.3653 (0.3605)	grad_norm 216577.2812 (183540.7500)	mem 14543MB
[2023-10-12 08:24:13 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][3000/6787]	eta 0:15:49 lr 0.000200	time 0.2542 (0.2508)	loss 0.3580 (0.3600)	grad_norm 311077.3438 (207840.5312)	mem 14543MB
[2023-10-12 08:26:19 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][3500/6787]	eta 0:13:44 lr 0.000200	time 0.2507 (0.2507)	loss 0.3530 (0.3599)	grad_norm 330789.3125 (inf)	mem 14543MB
[2023-10-12 08:28:24 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2506 (0.2506)	loss 0.3390 (0.3600)	grad_norm 336085.7500 (inf)	mem 14543MB
[2023-10-12 08:30:29 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2491 (0.2506)	loss 0.3313 (0.3600)	grad_norm 129028.0703 (inf)	mem 14543MB
[2023-10-12 08:32:34 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2459 (0.2505)	loss 0.3515 (0.3600)	grad_norm 310883.1250 (inf)	mem 14543MB
[2023-10-12 08:34:39 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2533 (0.2505)	loss 0.3432 (0.3598)	grad_norm 216105.2969 (inf)	mem 14543MB
[2023-10-12 08:36:44 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2479 (0.2504)	loss 0.3561 (0.3597)	grad_norm 839788.4375 (inf)	mem 14543MB
[2023-10-12 08:38:49 simmim_pretrain](main_simmim.py 218): INFO Train: [112/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2493 (0.2504)	loss 0.3780 (0.3595)	grad_norm 408737.6875 (inf)	mem 14543MB
[2023-10-12 08:40:01 simmim_pretrain](main_simmim.py 228): INFO EPOCH 112 training takes 0:28:20
[2023-10-12 08:40:03 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][0/6787]	eta 2:46:54 lr 0.000200	time 1.4755 (1.4755)	loss 0.3513 (0.3513)	grad_norm 329901.4375 (329901.4375)	mem 14543MB
[2023-10-12 08:42:07 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][500/6787]	eta 0:26:24 lr 0.000200	time 0.2505 (0.2521)	loss 0.3721 (0.3577)	grad_norm 577443.4375 (inf)	mem 14543MB
[2023-10-12 08:44:13 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][1000/6787]	eta 0:24:13 lr 0.000200	time 0.2463 (0.2511)	loss 0.3770 (0.3599)	grad_norm 129677.6641 (inf)	mem 14543MB
[2023-10-12 08:46:18 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][1500/6787]	eta 0:22:05 lr 0.000200	time 0.2517 (0.2508)	loss 0.3528 (0.3611)	grad_norm 61757.3047 (inf)	mem 14543MB
[2023-10-12 08:48:23 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][2000/6787]	eta 0:19:59 lr 0.000200	time 0.2489 (0.2507)	loss 0.3716 (0.3611)	grad_norm 154113.6406 (inf)	mem 14543MB
[2023-10-12 08:50:28 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][2500/6787]	eta 0:17:54 lr 0.000200	time 0.2496 (0.2506)	loss 0.3638 (0.3614)	grad_norm 170958.3594 (inf)	mem 14543MB
[2023-10-12 08:52:33 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][3000/6787]	eta 0:15:48 lr 0.000200	time 0.2486 (0.2506)	loss 0.3563 (0.3614)	grad_norm 117938.3750 (inf)	mem 14543MB
[2023-10-12 08:54:38 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][3500/6787]	eta 0:13:43 lr 0.000200	time 0.2487 (0.2506)	loss 0.3387 (0.3612)	grad_norm 274557.0312 (inf)	mem 14543MB
[2023-10-12 08:56:44 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2486 (0.2506)	loss 0.3815 (0.3611)	grad_norm 223480.6719 (inf)	mem 14543MB
[2023-10-12 08:58:49 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2507 (0.2506)	loss 0.3564 (0.3609)	grad_norm 241623.5938 (inf)	mem 14543MB
[2023-10-12 09:00:55 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2496 (0.2507)	loss 0.3597 (0.3607)	grad_norm 591766.6250 (inf)	mem 14543MB
[2023-10-12 09:03:00 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2506 (0.2507)	loss 0.3603 (0.3604)	grad_norm 419936.9688 (inf)	mem 14543MB
[2023-10-12 09:05:05 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2463 (0.2506)	loss 0.3568 (0.3601)	grad_norm 455009.7812 (inf)	mem 14543MB
[2023-10-12 09:07:11 simmim_pretrain](main_simmim.py 218): INFO Train: [113/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2506 (0.2507)	loss 0.3535 (0.3600)	grad_norm 244303.5000 (inf)	mem 14543MB
[2023-10-12 09:08:23 simmim_pretrain](main_simmim.py 228): INFO EPOCH 113 training takes 0:28:21
[2023-10-12 09:08:25 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][0/6787]	eta 2:50:50 lr 0.000200	time 1.5103 (1.5103)	loss 0.3538 (0.3538)	grad_norm 175280.5000 (175280.5000)	mem 14543MB
[2023-10-12 09:10:30 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][500/6787]	eta 0:26:27 lr 0.000200	time 0.2485 (0.2526)	loss 0.3495 (0.3581)	grad_norm 204833.8125 (266115.7500)	mem 14543MB
[2023-10-12 09:12:35 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][1000/6787]	eta 0:24:14 lr 0.000200	time 0.2517 (0.2514)	loss 0.3674 (0.3593)	grad_norm 240993.4375 (254562.2188)	mem 14543MB
[2023-10-12 09:14:40 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][1500/6787]	eta 0:22:07 lr 0.000200	time 0.2472 (0.2511)	loss 0.3519 (0.3593)	grad_norm 103221.5703 (249725.1094)	mem 14543MB
[2023-10-12 09:16:45 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][2000/6787]	eta 0:20:01 lr 0.000200	time 0.2594 (0.2510)	loss 0.3436 (0.3593)	grad_norm 248129.5156 (261657.9531)	mem 14543MB
[2023-10-12 09:18:50 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2465 (0.2508)	loss 0.3801 (0.3589)	grad_norm 820611.7500 (278469.7812)	mem 14543MB
[2023-10-12 09:20:55 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][3000/6787]	eta 0:15:49 lr 0.000200	time 0.2513 (0.2506)	loss 0.3701 (0.3589)	grad_norm 341962.5625 (296981.6250)	mem 14543MB
[2023-10-12 09:23:00 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][3500/6787]	eta 0:13:43 lr 0.000200	time 0.2463 (0.2506)	loss 0.3522 (0.3588)	grad_norm 250905.0156 (312322.2812)	mem 14543MB
[2023-10-12 09:25:05 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2475 (0.2505)	loss 0.3636 (0.3587)	grad_norm 535936.0625 (inf)	mem 14543MB
[2023-10-12 09:27:11 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2470 (0.2505)	loss 0.3678 (0.3587)	grad_norm 444966.5625 (inf)	mem 14543MB
[2023-10-12 09:29:16 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2496 (0.2505)	loss 0.3703 (0.3588)	grad_norm 322821.4062 (inf)	mem 14543MB
[2023-10-12 09:31:21 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2487 (0.2504)	loss 0.3483 (0.3589)	grad_norm 278766.9375 (inf)	mem 14543MB
[2023-10-12 09:33:26 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2548 (0.2504)	loss 0.3624 (0.3589)	grad_norm 239693.4688 (inf)	mem 14543MB
[2023-10-12 09:35:31 simmim_pretrain](main_simmim.py 218): INFO Train: [114/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2540 (0.2504)	loss 0.3706 (0.3590)	grad_norm 258044.2656 (inf)	mem 14543MB
[2023-10-12 09:36:43 simmim_pretrain](main_simmim.py 228): INFO EPOCH 114 training takes 0:28:19
[2023-10-12 09:36:44 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][0/6787]	eta 2:36:17 lr 0.000200	time 1.3818 (1.3818)	loss 0.3531 (0.3531)	grad_norm 210865.9688 (210865.9688)	mem 14543MB
[2023-10-12 09:38:49 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][500/6787]	eta 0:26:27 lr 0.000200	time 0.2487 (0.2525)	loss 0.3548 (0.3584)	grad_norm 339419.5625 (376496.5938)	mem 14543MB
[2023-10-12 09:40:55 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][1000/6787]	eta 0:24:15 lr 0.000200	time 0.2588 (0.2515)	loss 0.3604 (0.3590)	grad_norm 173606.2500 (inf)	mem 14543MB
[2023-10-12 09:43:00 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][1500/6787]	eta 0:22:08 lr 0.000200	time 0.2502 (0.2512)	loss 0.3744 (0.3599)	grad_norm 266474.3125 (inf)	mem 14543MB
[2023-10-12 09:45:06 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2493 (0.2513)	loss 0.3431 (0.3601)	grad_norm 127611.3594 (inf)	mem 14543MB
[2023-10-12 09:47:11 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2473 (0.2512)	loss 0.3712 (0.3600)	grad_norm 246727.9531 (inf)	mem 14543MB
[2023-10-12 09:49:17 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][3000/6787]	eta 0:15:51 lr 0.000200	time 0.2464 (0.2512)	loss 0.3631 (0.3599)	grad_norm 286571.0938 (inf)	mem 14543MB
[2023-10-12 09:51:23 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2490 (0.2513)	loss 0.3531 (0.3596)	grad_norm 224341.6406 (inf)	mem 14543MB
[2023-10-12 09:53:29 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2512 (0.2514)	loss 0.3784 (0.3595)	grad_norm 241142.0156 (inf)	mem 14543MB
[2023-10-12 09:55:35 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2588 (0.2514)	loss 0.3394 (0.3595)	grad_norm 310090.0625 (inf)	mem 14543MB
[2023-10-12 09:57:42 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2558 (0.2518)	loss 0.3614 (0.3595)	grad_norm 313936.4375 (inf)	mem 14543MB
[2023-10-12 09:59:50 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2555 (0.2522)	loss 0.3758 (0.3594)	grad_norm 171392.4375 (inf)	mem 14543MB
[2023-10-12 10:01:58 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2563 (0.2525)	loss 0.3683 (0.3595)	grad_norm 220458.1562 (inf)	mem 14543MB
[2023-10-12 10:04:06 simmim_pretrain](main_simmim.py 218): INFO Train: [115/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2566 (0.2528)	loss 0.3747 (0.3595)	grad_norm 247485.9375 (inf)	mem 14543MB
[2023-10-12 10:05:20 simmim_pretrain](main_simmim.py 228): INFO EPOCH 115 training takes 0:28:37
[2023-10-12 10:05:21 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][0/6787]	eta 2:38:58 lr 0.000200	time 1.4054 (1.4054)	loss 0.3591 (0.3591)	grad_norm 340657.4062 (340657.4062)	mem 14543MB
[2023-10-12 10:07:27 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2597 (0.2530)	loss 0.3768 (0.3615)	grad_norm 166567.3438 (inf)	mem 14543MB
[2023-10-12 10:09:33 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][1000/6787]	eta 0:24:19 lr 0.000200	time 0.2516 (0.2523)	loss 0.3670 (0.3624)	grad_norm 170281.6406 (inf)	mem 14543MB
[2023-10-12 10:11:38 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][1500/6787]	eta 0:22:11 lr 0.000200	time 0.2476 (0.2518)	loss 0.3635 (0.3622)	grad_norm 142595.0156 (inf)	mem 14543MB
[2023-10-12 10:13:43 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][2000/6787]	eta 0:20:03 lr 0.000200	time 0.2530 (0.2515)	loss 0.3620 (0.3622)	grad_norm 124172.9609 (inf)	mem 14543MB
[2023-10-12 10:15:49 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2495 (0.2515)	loss 0.3739 (0.3623)	grad_norm 115802.4453 (inf)	mem 14543MB
[2023-10-12 10:17:55 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2479 (0.2514)	loss 0.3479 (0.3618)	grad_norm 215588.7344 (inf)	mem 14543MB
[2023-10-12 10:20:00 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2540 (0.2514)	loss 0.3762 (0.3617)	grad_norm 253147.1562 (inf)	mem 14543MB
[2023-10-12 10:22:06 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2518 (0.2513)	loss 0.3870 (0.3618)	grad_norm 122639.5234 (inf)	mem 14543MB
[2023-10-12 10:24:11 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2492 (0.2513)	loss 0.3557 (0.3617)	grad_norm 148606.2188 (inf)	mem 14543MB
[2023-10-12 10:26:17 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2515 (0.2512)	loss 0.3549 (0.3618)	grad_norm 155689.3438 (inf)	mem 14543MB
[2023-10-12 10:28:22 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2540 (0.2512)	loss 0.3799 (0.3617)	grad_norm 104737.2344 (inf)	mem 14543MB
[2023-10-12 10:30:28 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2472 (0.2512)	loss 0.3333 (0.3615)	grad_norm 235232.8906 (inf)	mem 14543MB
[2023-10-12 10:32:33 simmim_pretrain](main_simmim.py 218): INFO Train: [116/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2526 (0.2512)	loss 0.3733 (0.3613)	grad_norm 281626.9062 (inf)	mem 14543MB
[2023-10-12 10:33:46 simmim_pretrain](main_simmim.py 228): INFO EPOCH 116 training takes 0:28:25
[2023-10-12 10:33:47 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][0/6787]	eta 2:31:54 lr 0.000200	time 1.3429 (1.3429)	loss 0.3385 (0.3385)	grad_norm 253518.2500 (253518.2500)	mem 14543MB
[2023-10-12 10:35:52 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][500/6787]	eta 0:26:26 lr 0.000200	time 0.2585 (0.2523)	loss 0.3521 (0.3591)	grad_norm 189912.4062 (250410.8281)	mem 14543MB
[2023-10-12 10:37:57 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][1000/6787]	eta 0:24:15 lr 0.000200	time 0.2514 (0.2515)	loss 0.3599 (0.3590)	grad_norm 323083.3438 (276954.4688)	mem 14543MB
[2023-10-12 10:40:03 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][1500/6787]	eta 0:22:08 lr 0.000200	time 0.2512 (0.2513)	loss 0.3668 (0.3588)	grad_norm 165663.0469 (311856.0000)	mem 14543MB
[2023-10-12 10:42:08 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2520 (0.2512)	loss 0.3472 (0.3586)	grad_norm 852972.3750 (329970.4688)	mem 14543MB
[2023-10-12 10:44:14 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2463 (0.2511)	loss 0.3635 (0.3586)	grad_norm 977080.9375 (368667.2812)	mem 14543MB
[2023-10-12 10:46:19 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][3000/6787]	eta 0:15:51 lr 0.000200	time 0.2490 (0.2512)	loss 0.3573 (0.3586)	grad_norm 283307.1875 (inf)	mem 14543MB
[2023-10-12 10:48:25 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2469 (0.2511)	loss 0.3647 (0.3586)	grad_norm 178685.5312 (inf)	mem 14543MB
[2023-10-12 10:50:30 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2589 (0.2511)	loss 0.3789 (0.3587)	grad_norm 321773.3438 (inf)	mem 14543MB
[2023-10-12 10:52:36 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2501 (0.2511)	loss 0.3397 (0.3587)	grad_norm 231608.6875 (inf)	mem 14543MB
[2023-10-12 10:54:41 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2486 (0.2511)	loss 0.3819 (0.3586)	grad_norm 189594.5781 (inf)	mem 14543MB
[2023-10-12 10:56:47 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2485 (0.2511)	loss 0.3445 (0.3586)	grad_norm 456327.1562 (inf)	mem 14543MB
[2023-10-12 10:58:52 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2463 (0.2511)	loss 0.3688 (0.3586)	grad_norm 246278.5000 (inf)	mem 14543MB
[2023-10-12 11:00:58 simmim_pretrain](main_simmim.py 218): INFO Train: [117/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2550 (0.2510)	loss 0.3754 (0.3586)	grad_norm 350821.0312 (inf)	mem 14543MB
[2023-10-12 11:02:10 simmim_pretrain](main_simmim.py 228): INFO EPOCH 117 training takes 0:28:24
[2023-10-12 11:02:12 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][0/6787]	eta 2:52:47 lr 0.000200	time 1.5276 (1.5276)	loss 0.3641 (0.3641)	grad_norm 383179.1875 (383179.1875)	mem 14543MB
[2023-10-12 11:04:17 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][500/6787]	eta 0:26:29 lr 0.000200	time 0.2500 (0.2528)	loss 0.3596 (0.3575)	grad_norm 445160.5000 (452606.3125)	mem 14543MB
[2023-10-12 11:06:22 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][1000/6787]	eta 0:24:16 lr 0.000200	time 0.2502 (0.2517)	loss 0.3585 (0.3570)	grad_norm 316984.0625 (456598.5938)	mem 14543MB
[2023-10-12 11:08:27 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][1500/6787]	eta 0:22:08 lr 0.000200	time 0.2469 (0.2514)	loss 0.3399 (0.3572)	grad_norm 541144.8125 (450720.5312)	mem 14543MB
[2023-10-12 11:10:33 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2526 (0.2512)	loss 0.3322 (0.3575)	grad_norm 436935.2812 (inf)	mem 14543MB
[2023-10-12 11:12:38 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2457 (0.2511)	loss 0.3800 (0.3581)	grad_norm 221044.7031 (inf)	mem 14543MB
[2023-10-12 11:14:43 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2469 (0.2510)	loss 0.3626 (0.3584)	grad_norm 279021.7188 (inf)	mem 14543MB
[2023-10-12 11:16:49 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][3500/6787]	eta 0:13:44 lr 0.000200	time 0.2538 (0.2510)	loss 0.3774 (0.3586)	grad_norm 280337.2188 (inf)	mem 14543MB
[2023-10-12 11:18:54 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2460 (0.2509)	loss 0.3675 (0.3588)	grad_norm 351947.3125 (inf)	mem 14543MB
[2023-10-12 11:20:59 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2465 (0.2508)	loss 0.3515 (0.3589)	grad_norm 241084.0781 (inf)	mem 14543MB
[2023-10-12 11:23:04 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2532 (0.2508)	loss 0.3487 (0.3588)	grad_norm 578943.7500 (inf)	mem 14543MB
[2023-10-12 11:25:09 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2462 (0.2507)	loss 0.3833 (0.3588)	grad_norm 547064.3125 (inf)	mem 14543MB
[2023-10-12 11:27:15 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2509 (0.2507)	loss 0.3533 (0.3588)	grad_norm 372251.4062 (inf)	mem 14543MB
[2023-10-12 11:29:20 simmim_pretrain](main_simmim.py 218): INFO Train: [118/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2539 (0.2507)	loss 0.3623 (0.3588)	grad_norm 190820.9062 (inf)	mem 14543MB
[2023-10-12 11:30:32 simmim_pretrain](main_simmim.py 228): INFO EPOCH 118 training takes 0:28:22
[2023-10-12 11:30:34 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][0/6787]	eta 2:46:24 lr 0.000200	time 1.4712 (1.4712)	loss 0.3501 (0.3501)	grad_norm 307389.3750 (307389.3750)	mem 14543MB
[2023-10-12 11:32:39 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2554 (0.2529)	loss 0.3696 (0.3601)	grad_norm 200718.2656 (252041.5938)	mem 14543MB
[2023-10-12 11:34:45 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][1000/6787]	eta 0:24:18 lr 0.000200	time 0.2514 (0.2520)	loss 0.3542 (0.3601)	grad_norm 283518.0625 (inf)	mem 14543MB
[2023-10-12 11:36:50 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2525 (0.2517)	loss 0.3896 (0.3597)	grad_norm 386525.5000 (inf)	mem 14543MB
[2023-10-12 11:38:56 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][2000/6787]	eta 0:20:04 lr 0.000200	time 0.2581 (0.2516)	loss 0.3781 (0.3598)	grad_norm 329257.7188 (inf)	mem 14543MB
[2023-10-12 11:41:02 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2525 (0.2516)	loss 0.3810 (0.3598)	grad_norm 271186.5312 (inf)	mem 14543MB
[2023-10-12 11:43:07 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2516 (0.2516)	loss 0.3477 (0.3604)	grad_norm 174199.8125 (inf)	mem 14543MB
[2023-10-12 11:45:13 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2486 (0.2517)	loss 0.3583 (0.3607)	grad_norm 129420.9297 (inf)	mem 14543MB
[2023-10-12 11:47:19 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2491 (0.2517)	loss 0.3555 (0.3609)	grad_norm 104844.6250 (inf)	mem 14543MB
[2023-10-12 11:49:25 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2495 (0.2517)	loss 0.3691 (0.3610)	grad_norm 201065.5781 (inf)	mem 14543MB
[2023-10-12 11:51:31 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2507 (0.2516)	loss 0.3626 (0.3609)	grad_norm 162001.1875 (inf)	mem 14543MB
[2023-10-12 11:53:36 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2529 (0.2516)	loss 0.3536 (0.3609)	grad_norm 192356.4375 (inf)	mem 14543MB
[2023-10-12 11:55:42 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2504 (0.2516)	loss 0.3830 (0.3607)	grad_norm 259239.2812 (inf)	mem 14543MB
[2023-10-12 11:57:48 simmim_pretrain](main_simmim.py 218): INFO Train: [119/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2496 (0.2516)	loss 0.3366 (0.3607)	grad_norm 240705.6719 (inf)	mem 14543MB
[2023-10-12 11:59:00 simmim_pretrain](main_simmim.py 228): INFO EPOCH 119 training takes 0:28:28
[2023-10-12 11:59:02 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][0/6787]	eta 2:52:51 lr 0.000200	time 1.5281 (1.5281)	loss 0.3496 (0.3496)	grad_norm 231375.3125 (231375.3125)	mem 14543MB
[2023-10-12 12:01:07 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][500/6787]	eta 0:26:27 lr 0.000200	time 0.2546 (0.2526)	loss 0.3425 (0.3579)	grad_norm 423830.3750 (328276.5312)	mem 14543MB
[2023-10-12 12:03:12 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][1000/6787]	eta 0:24:16 lr 0.000200	time 0.2579 (0.2516)	loss 0.3797 (0.3581)	grad_norm 281724.2500 (inf)	mem 14543MB
[2023-10-12 12:05:17 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][1500/6787]	eta 0:22:08 lr 0.000200	time 0.2510 (0.2513)	loss 0.3384 (0.3586)	grad_norm 320460.1250 (inf)	mem 14543MB
[2023-10-12 12:07:23 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][2000/6787]	eta 0:20:01 lr 0.000200	time 0.2488 (0.2510)	loss 0.3446 (0.3588)	grad_norm 195391.7656 (inf)	mem 14543MB
[2023-10-12 12:09:28 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2524 (0.2509)	loss 0.3684 (0.3588)	grad_norm 117798.2656 (inf)	mem 14543MB
[2023-10-12 12:11:33 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2523 (0.2509)	loss 0.3596 (0.3590)	grad_norm 382798.8125 (inf)	mem 14543MB
[2023-10-12 12:13:38 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][3500/6787]	eta 0:13:44 lr 0.000200	time 0.2521 (0.2508)	loss 0.3576 (0.3591)	grad_norm 227173.5000 (inf)	mem 14543MB
[2023-10-12 12:15:44 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2460 (0.2508)	loss 0.5095 (0.3653)	grad_norm 12666.9590 (inf)	mem 14543MB
[2023-10-12 12:17:49 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2538 (0.2507)	loss 0.3875 (0.3766)	grad_norm 30068.6680 (inf)	mem 14543MB
[2023-10-12 12:19:54 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2462 (0.2506)	loss 0.3677 (0.3764)	grad_norm 39233.9609 (inf)	mem 14543MB
[2023-10-12 12:21:59 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2486 (0.2506)	loss 0.3702 (0.3756)	grad_norm 36601.4844 (inf)	mem 14543MB
[2023-10-12 12:24:04 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2461 (0.2505)	loss 0.3816 (0.3748)	grad_norm 27358.3164 (inf)	mem 14543MB
[2023-10-12 12:26:09 simmim_pretrain](main_simmim.py 218): INFO Train: [120/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2507 (0.2505)	loss 0.3597 (0.3739)	grad_norm 42402.3398 (inf)	mem 14543MB
[2023-10-12 12:27:21 simmim_pretrain](main_simmim.py 228): INFO EPOCH 120 training takes 0:28:20
[2023-10-12 12:27:21 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_120.pth saving......
[2023-10-12 12:27:22 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_120.pth saved !!!
[2023-10-12 12:27:23 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][0/6787]	eta 2:27:56 lr 0.000200	time 1.3078 (1.3078)	loss 0.3718 (0.3718)	grad_norm 71027.0547 (71027.0547)	mem 14543MB
[2023-10-12 12:29:28 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][500/6787]	eta 0:26:21 lr 0.000200	time 0.2463 (0.2516)	loss 0.3743 (0.3628)	grad_norm 38354.6367 (48843.0352)	mem 14543MB
[2023-10-12 12:31:33 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][1000/6787]	eta 0:24:11 lr 0.000200	time 0.2471 (0.2508)	loss 0.3620 (0.3627)	grad_norm 44278.9961 (49520.5820)	mem 14543MB
[2023-10-12 12:33:38 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][1500/6787]	eta 0:22:05 lr 0.000200	time 0.2533 (0.2506)	loss 0.3683 (0.3624)	grad_norm 68510.8594 (54225.5430)	mem 14543MB
[2023-10-12 12:35:44 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][2000/6787]	eta 0:20:00 lr 0.000200	time 0.2530 (0.2507)	loss 0.3340 (0.3622)	grad_norm 63377.1953 (61776.0352)	mem 14543MB
[2023-10-12 12:37:49 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2497 (0.2508)	loss 0.3762 (0.3617)	grad_norm 68822.3906 (65922.7656)	mem 14543MB
[2023-10-12 12:39:55 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2508 (0.2509)	loss 0.3453 (0.3616)	grad_norm 99822.3438 (71108.1172)	mem 14543MB
[2023-10-12 12:42:00 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][3500/6787]	eta 0:13:44 lr 0.000200	time 0.2588 (0.2510)	loss 0.3587 (0.3613)	grad_norm 169144.6094 (80026.8047)	mem 14543MB
[2023-10-12 12:44:06 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2462 (0.2510)	loss 0.3525 (0.3611)	grad_norm 337837.2188 (87072.6328)	mem 14543MB
[2023-10-12 12:46:11 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2585 (0.2510)	loss 0.3491 (0.3609)	grad_norm 115191.3438 (103367.2500)	mem 14543MB
[2023-10-12 12:48:17 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2542 (0.2509)	loss 0.3565 (0.3607)	grad_norm 123019.7812 (109690.3438)	mem 14543MB
[2023-10-12 12:50:22 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2484 (0.2509)	loss 0.3653 (0.3605)	grad_norm 459930.1875 (125741.1562)	mem 14543MB
[2023-10-12 12:52:27 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2514 (0.2509)	loss 0.3556 (0.3602)	grad_norm 138118.7344 (141188.4531)	mem 14543MB
[2023-10-12 12:54:32 simmim_pretrain](main_simmim.py 218): INFO Train: [121/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2502 (0.2508)	loss 0.3535 (0.3600)	grad_norm 175545.0469 (158868.9531)	mem 14543MB
[2023-10-12 12:55:45 simmim_pretrain](main_simmim.py 228): INFO EPOCH 121 training takes 0:28:22
[2023-10-12 12:55:46 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][0/6787]	eta 2:44:05 lr 0.000200	time 1.4506 (1.4506)	loss 0.3513 (0.3513)	grad_norm 203051.9531 (203051.9531)	mem 14543MB
[2023-10-12 12:57:51 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][500/6787]	eta 0:26:27 lr 0.000200	time 0.2579 (0.2525)	loss 0.3467 (0.3568)	grad_norm 674823.3125 (inf)	mem 14543MB
[2023-10-12 12:59:56 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][1000/6787]	eta 0:24:15 lr 0.000200	time 0.2475 (0.2516)	loss 0.3458 (0.3574)	grad_norm 211274.0625 (inf)	mem 14543MB
[2023-10-12 13:02:02 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][1500/6787]	eta 0:22:07 lr 0.000200	time 0.2459 (0.2512)	loss 0.3865 (0.3575)	grad_norm 364379.0938 (inf)	mem 14543MB
[2023-10-12 13:04:07 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2589 (0.2511)	loss 0.3576 (0.3574)	grad_norm 215404.4219 (inf)	mem 14543MB
[2023-10-12 13:06:13 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2465 (0.2511)	loss 0.3417 (0.3576)	grad_norm 608808.3125 (inf)	mem 14543MB
[2023-10-12 13:08:18 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2474 (0.2511)	loss 0.3638 (0.3575)	grad_norm 402894.5625 (inf)	mem 14543MB
[2023-10-12 13:10:24 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2608 (0.2510)	loss 0.3583 (0.3575)	grad_norm 379572.6562 (inf)	mem 14543MB
[2023-10-12 13:12:29 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2524 (0.2511)	loss 0.3452 (0.3577)	grad_norm 552910.2500 (inf)	mem 14543MB
[2023-10-12 13:14:35 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2541 (0.2511)	loss 0.3673 (0.3578)	grad_norm 1043585.6875 (inf)	mem 14543MB
[2023-10-12 13:16:40 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2537 (0.2511)	loss 0.3662 (0.3576)	grad_norm 338792.8125 (inf)	mem 14543MB
[2023-10-12 13:18:46 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2544 (0.2512)	loss 0.3466 (0.3577)	grad_norm 247120.5781 (inf)	mem 14543MB
[2023-10-12 13:20:52 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2532 (0.2512)	loss 0.3596 (0.3578)	grad_norm 289515.0000 (inf)	mem 14543MB
[2023-10-12 13:23:01 simmim_pretrain](main_simmim.py 218): INFO Train: [122/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2586 (0.2517)	loss 0.3573 (0.3579)	grad_norm 113469.9141 (inf)	mem 14543MB
[2023-10-12 13:24:16 simmim_pretrain](main_simmim.py 228): INFO EPOCH 122 training takes 0:28:31
[2023-10-12 13:24:17 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][0/6787]	eta 2:31:49 lr 0.000200	time 1.3422 (1.3422)	loss 0.3680 (0.3680)	grad_norm 118650.3281 (118650.3281)	mem 14543MB
[2023-10-12 13:26:22 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][500/6787]	eta 0:26:28 lr 0.000200	time 0.2454 (0.2527)	loss 0.3673 (0.3596)	grad_norm 211398.9062 (245909.9375)	mem 14543MB
[2023-10-12 13:28:28 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][1000/6787]	eta 0:24:18 lr 0.000200	time 0.2510 (0.2520)	loss 0.3265 (0.3586)	grad_norm 542161.5625 (274465.7500)	mem 14543MB
[2023-10-12 13:30:34 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2478 (0.2517)	loss 0.3558 (0.3584)	grad_norm 278594.5625 (293624.6250)	mem 14543MB
[2023-10-12 13:32:39 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][2000/6787]	eta 0:20:03 lr 0.000200	time 0.2462 (0.2515)	loss 0.3367 (0.3582)	grad_norm 137553.5156 (310133.2812)	mem 14543MB
[2023-10-12 13:34:44 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][2500/6787]	eta 0:17:57 lr 0.000200	time 0.2466 (0.2513)	loss 0.3399 (0.3581)	grad_norm 281124.1250 (inf)	mem 14543MB
[2023-10-12 13:36:52 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][3000/6787]	eta 0:15:53 lr 0.000200	time 0.2610 (0.2519)	loss 0.3598 (0.3580)	grad_norm 429134.5000 (inf)	mem 14543MB
[2023-10-12 13:39:02 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][3500/6787]	eta 0:13:51 lr 0.000200	time 0.2611 (0.2530)	loss 0.3627 (0.3579)	grad_norm 350622.9375 (inf)	mem 14543MB
[2023-10-12 13:41:12 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][4000/6787]	eta 0:11:47 lr 0.000200	time 0.2608 (0.2539)	loss 0.3451 (0.3579)	grad_norm 447717.9688 (inf)	mem 14543MB
[2023-10-12 13:43:21 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][4500/6787]	eta 0:09:42 lr 0.000200	time 0.2592 (0.2545)	loss 0.3622 (0.3582)	grad_norm 181476.1094 (inf)	mem 14543MB
[2023-10-12 13:45:31 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][5000/6787]	eta 0:07:35 lr 0.000200	time 0.2607 (0.2550)	loss 0.3611 (0.3585)	grad_norm 122111.7656 (inf)	mem 14543MB
[2023-10-12 13:47:41 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][5500/6787]	eta 0:05:28 lr 0.000200	time 0.2611 (0.2555)	loss 0.3571 (0.3587)	grad_norm 123192.2656 (inf)	mem 14543MB
[2023-10-12 13:49:51 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2608 (0.2558)	loss 0.3611 (0.3589)	grad_norm 91571.2344 (inf)	mem 14543MB
[2023-10-12 13:52:01 simmim_pretrain](main_simmim.py 218): INFO Train: [123/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2608 (0.2561)	loss 0.3452 (0.3590)	grad_norm 80135.4453 (inf)	mem 14543MB
[2023-10-12 13:53:16 simmim_pretrain](main_simmim.py 228): INFO EPOCH 123 training takes 0:29:00
[2023-10-12 13:53:17 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][0/6787]	eta 2:34:55 lr 0.000200	time 1.3696 (1.3696)	loss 0.3626 (0.3626)	grad_norm 156864.5156 (156864.5156)	mem 14543MB
[2023-10-12 13:55:23 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2491 (0.2529)	loss 0.3368 (0.3599)	grad_norm 267711.9375 (176202.7031)	mem 14543MB
[2023-10-12 13:57:28 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2503 (0.2518)	loss 0.3514 (0.3597)	grad_norm 281073.4062 (179148.3594)	mem 14543MB
[2023-10-12 13:59:34 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2516 (0.2516)	loss 0.3491 (0.3592)	grad_norm 358753.0000 (189866.9688)	mem 14543MB
[2023-10-12 14:01:40 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][2000/6787]	eta 0:20:04 lr 0.000200	time 0.2538 (0.2516)	loss 0.3600 (0.3591)	grad_norm 228855.5781 (inf)	mem 14543MB
[2023-10-12 14:03:45 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2501 (0.2515)	loss 0.3596 (0.3589)	grad_norm 321817.8750 (inf)	mem 14543MB
[2023-10-12 14:05:51 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2576 (0.2516)	loss 0.3431 (0.3589)	grad_norm 93651.2969 (inf)	mem 14543MB
[2023-10-12 14:07:57 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2487 (0.2515)	loss 0.3771 (0.3588)	grad_norm 244422.4219 (inf)	mem 14543MB
[2023-10-12 14:10:02 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2469 (0.2515)	loss 0.3485 (0.3587)	grad_norm 178240.1875 (inf)	mem 14543MB
[2023-10-12 14:12:08 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2522 (0.2514)	loss 0.3608 (0.3587)	grad_norm 686672.7500 (inf)	mem 14543MB
[2023-10-12 14:14:13 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2462 (0.2514)	loss 0.3469 (0.3586)	grad_norm 214954.1719 (inf)	mem 14543MB
[2023-10-12 14:16:19 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2505 (0.2513)	loss 0.3625 (0.3584)	grad_norm 390392.6875 (inf)	mem 14543MB
[2023-10-12 14:18:24 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2536 (0.2513)	loss 0.3422 (0.3584)	grad_norm 432980.9062 (inf)	mem 14543MB
[2023-10-12 14:20:30 simmim_pretrain](main_simmim.py 218): INFO Train: [124/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2514 (0.2513)	loss 0.3644 (0.3582)	grad_norm 849666.8750 (inf)	mem 14543MB
[2023-10-12 14:21:43 simmim_pretrain](main_simmim.py 228): INFO EPOCH 124 training takes 0:28:26
[2023-10-12 14:21:44 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][0/6787]	eta 2:40:32 lr 0.000200	time 1.4193 (1.4193)	loss 0.3657 (0.3657)	grad_norm 323390.9688 (323390.9688)	mem 14543MB
[2023-10-12 14:23:50 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][500/6787]	eta 0:26:38 lr 0.000200	time 0.2490 (0.2543)	loss 0.3492 (0.3591)	grad_norm 211577.9062 (248741.5781)	mem 14543MB
[2023-10-12 14:25:56 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][1000/6787]	eta 0:24:26 lr 0.000200	time 0.2544 (0.2534)	loss 0.3683 (0.3593)	grad_norm 275156.5312 (240182.2656)	mem 14543MB
[2023-10-12 14:28:02 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][1500/6787]	eta 0:22:17 lr 0.000200	time 0.2540 (0.2529)	loss 0.3649 (0.3594)	grad_norm 152006.5156 (237202.6562)	mem 14543MB
[2023-10-12 14:30:08 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][2000/6787]	eta 0:20:09 lr 0.000200	time 0.2519 (0.2526)	loss 0.3559 (0.3595)	grad_norm 152184.3594 (247293.1094)	mem 14543MB
[2023-10-12 14:32:14 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][2500/6787]	eta 0:18:02 lr 0.000200	time 0.2499 (0.2525)	loss 0.3462 (0.3592)	grad_norm 254810.3906 (263619.9688)	mem 14543MB
[2023-10-12 14:34:20 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][3000/6787]	eta 0:15:55 lr 0.000200	time 0.2584 (0.2523)	loss 0.3735 (0.3591)	grad_norm 461938.6250 (279142.9375)	mem 14543MB
[2023-10-12 14:36:26 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][3500/6787]	eta 0:13:49 lr 0.000200	time 0.2493 (0.2523)	loss 0.3520 (0.3589)	grad_norm 379179.9062 (291557.3750)	mem 14543MB
[2023-10-12 14:38:32 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2551 (0.2522)	loss 0.3813 (0.3587)	grad_norm 473566.9062 (inf)	mem 14543MB
[2023-10-12 14:40:38 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2552 (0.2522)	loss 0.3638 (0.3585)	grad_norm 403850.5938 (inf)	mem 14543MB
[2023-10-12 14:42:44 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2515 (0.2522)	loss 0.3561 (0.3584)	grad_norm 376596.0625 (inf)	mem 14543MB
[2023-10-12 14:44:50 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2502 (0.2522)	loss 0.3579 (0.3583)	grad_norm 543785.5625 (inf)	mem 14543MB
[2023-10-12 14:46:57 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2566 (0.2523)	loss 0.3395 (0.3582)	grad_norm 456096.5312 (inf)	mem 14543MB
[2023-10-12 14:49:04 simmim_pretrain](main_simmim.py 218): INFO Train: [125/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2530 (0.2525)	loss 0.3846 (0.3582)	grad_norm 375934.6875 (inf)	mem 14543MB
[2023-10-12 14:50:18 simmim_pretrain](main_simmim.py 228): INFO EPOCH 125 training takes 0:28:35
[2023-10-12 14:50:20 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][0/6787]	eta 2:57:01 lr 0.000200	time 1.5649 (1.5649)	loss 0.3423 (0.3423)	grad_norm 253777.9531 (253777.9531)	mem 14543MB
[2023-10-12 14:52:29 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][500/6787]	eta 0:27:17 lr 0.000200	time 0.2594 (0.2605)	loss 0.3569 (0.3570)	grad_norm 363599.9375 (430049.2812)	mem 14543MB
[2023-10-12 14:54:38 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][1000/6787]	eta 0:25:00 lr 0.000200	time 0.2592 (0.2592)	loss 0.3401 (0.3577)	grad_norm 390369.9375 (inf)	mem 14543MB
[2023-10-12 14:56:46 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][1500/6787]	eta 0:22:46 lr 0.000200	time 0.2496 (0.2585)	loss 0.3606 (0.3579)	grad_norm 323866.9062 (inf)	mem 14543MB
[2023-10-12 14:58:55 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][2000/6787]	eta 0:20:35 lr 0.000200	time 0.2532 (0.2581)	loss 0.3431 (0.3581)	grad_norm 89422.7266 (inf)	mem 14543MB
[2023-10-12 15:01:02 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][2500/6787]	eta 0:18:24 lr 0.000200	time 0.2542 (0.2576)	loss 0.3604 (0.3583)	grad_norm 316622.4375 (inf)	mem 14543MB
[2023-10-12 15:03:10 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][3000/6787]	eta 0:16:14 lr 0.000200	time 0.2533 (0.2572)	loss 0.3762 (0.3583)	grad_norm 241167.0469 (inf)	mem 14543MB
[2023-10-12 15:05:18 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][3500/6787]	eta 0:14:04 lr 0.000200	time 0.2591 (0.2570)	loss 0.3535 (0.3583)	grad_norm 584936.5000 (inf)	mem 14543MB
[2023-10-12 15:07:27 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][4000/6787]	eta 0:11:56 lr 0.000200	time 0.2611 (0.2572)	loss 0.3591 (0.3582)	grad_norm 597492.1250 (inf)	mem 14543MB
[2023-10-12 15:09:36 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][4500/6787]	eta 0:09:48 lr 0.000200	time 0.2560 (0.2572)	loss 0.3579 (0.3582)	grad_norm 484591.1875 (inf)	mem 14543MB
[2023-10-12 15:11:46 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][5000/6787]	eta 0:07:39 lr 0.000200	time 0.2609 (0.2574)	loss 0.3429 (0.3582)	grad_norm 250718.5625 (inf)	mem 14543MB
[2023-10-12 15:13:56 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][5500/6787]	eta 0:05:31 lr 0.000200	time 0.2609 (0.2576)	loss 0.4048 (0.3583)	grad_norm 147934.5312 (inf)	mem 14543MB
[2023-10-12 15:16:06 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2609 (0.2578)	loss 0.3695 (0.3583)	grad_norm 273047.6250 (inf)	mem 14543MB
[2023-10-12 15:18:16 simmim_pretrain](main_simmim.py 218): INFO Train: [126/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2611 (0.2580)	loss 0.3589 (0.3585)	grad_norm 276722.5625 (inf)	mem 14543MB
[2023-10-12 15:19:31 simmim_pretrain](main_simmim.py 228): INFO EPOCH 126 training takes 0:29:12
[2023-10-12 15:19:32 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][0/6787]	eta 2:42:51 lr 0.000200	time 1.4397 (1.4397)	loss 0.3766 (0.3766)	grad_norm 373395.7812 (373395.7812)	mem 14543MB
[2023-10-12 15:21:38 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][500/6787]	eta 0:26:36 lr 0.000200	time 0.2450 (0.2540)	loss 0.3488 (0.3574)	grad_norm 219675.9375 (344170.9688)	mem 14543MB
[2023-10-12 15:23:44 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][1000/6787]	eta 0:24:24 lr 0.000200	time 0.2537 (0.2531)	loss 0.3344 (0.3581)	grad_norm 192416.8281 (404688.0938)	mem 14543MB
[2023-10-12 15:25:50 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][1500/6787]	eta 0:22:16 lr 0.000200	time 0.2504 (0.2528)	loss 0.3710 (0.3583)	grad_norm 512367.7500 (394950.2500)	mem 14543MB
[2023-10-12 15:27:56 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][2000/6787]	eta 0:20:08 lr 0.000200	time 0.2451 (0.2525)	loss 0.3821 (0.3580)	grad_norm 757513.3125 (inf)	mem 14543MB
[2023-10-12 15:30:02 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][2500/6787]	eta 0:18:01 lr 0.000200	time 0.2518 (0.2523)	loss 0.3453 (0.3579)	grad_norm 254295.4062 (inf)	mem 14543MB
[2023-10-12 15:32:07 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][3000/6787]	eta 0:15:54 lr 0.000200	time 0.2530 (0.2521)	loss 0.3657 (0.3578)	grad_norm 592169.8125 (inf)	mem 14543MB
[2023-10-12 15:34:13 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][3500/6787]	eta 0:13:48 lr 0.000200	time 0.2486 (0.2520)	loss 0.3401 (0.3579)	grad_norm 303716.9062 (inf)	mem 14543MB
[2023-10-12 15:36:19 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2478 (0.2519)	loss 0.3599 (0.3583)	grad_norm 257904.7188 (inf)	mem 14543MB
[2023-10-12 15:38:24 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2487 (0.2519)	loss 0.3648 (0.3587)	grad_norm 163928.5469 (inf)	mem 14543MB
[2023-10-12 15:40:30 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2456 (0.2517)	loss 0.3663 (0.3590)	grad_norm 155262.6250 (inf)	mem 14543MB
[2023-10-12 15:42:35 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2517 (0.2516)	loss 0.3553 (0.3592)	grad_norm 81886.1719 (inf)	mem 14543MB
[2023-10-12 15:44:40 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2506 (0.2516)	loss 0.3552 (0.3593)	grad_norm 118899.3672 (inf)	mem 14543MB
[2023-10-12 15:46:46 simmim_pretrain](main_simmim.py 218): INFO Train: [127/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2531 (0.2515)	loss 0.3488 (0.3593)	grad_norm 201421.7500 (inf)	mem 14543MB
[2023-10-12 15:47:59 simmim_pretrain](main_simmim.py 228): INFO EPOCH 127 training takes 0:28:28
[2023-10-12 15:48:00 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][0/6787]	eta 2:51:46 lr 0.000200	time 1.5186 (1.5186)	loss 0.3862 (0.3862)	grad_norm 217034.2500 (217034.2500)	mem 14543MB
[2023-10-12 15:50:06 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][500/6787]	eta 0:26:32 lr 0.000200	time 0.2527 (0.2533)	loss 0.3431 (0.3603)	grad_norm 282695.5938 (208315.7656)	mem 14543MB
[2023-10-12 15:52:11 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][1000/6787]	eta 0:24:16 lr 0.000200	time 0.2511 (0.2518)	loss 0.3599 (0.3599)	grad_norm 337960.5625 (212261.0469)	mem 14543MB
[2023-10-12 15:54:16 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][1500/6787]	eta 0:22:08 lr 0.000200	time 0.2469 (0.2513)	loss 0.3473 (0.3593)	grad_norm 215515.5625 (236224.3906)	mem 14543MB
[2023-10-12 15:56:21 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][2000/6787]	eta 0:20:01 lr 0.000200	time 0.2492 (0.2511)	loss 0.3423 (0.3587)	grad_norm 511594.0938 (278825.6562)	mem 14543MB
[2023-10-12 15:58:26 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2483 (0.2509)	loss 0.3569 (0.3582)	grad_norm 458018.4375 (315098.5312)	mem 14543MB
[2023-10-12 16:00:32 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2550 (0.2509)	loss 0.3695 (0.3584)	grad_norm 455031.3750 (331489.3750)	mem 14543MB
[2023-10-12 16:02:37 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][3500/6787]	eta 0:13:44 lr 0.000200	time 0.2518 (0.2509)	loss 0.3697 (0.3585)	grad_norm 248475.2500 (inf)	mem 14543MB
[2023-10-12 16:04:43 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2464 (0.2509)	loss 0.3881 (0.3586)	grad_norm 173020.7031 (inf)	mem 14543MB
[2023-10-12 16:06:48 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2457 (0.2509)	loss 0.3588 (0.3586)	grad_norm 155351.0312 (inf)	mem 14543MB
[2023-10-12 16:08:53 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2514 (0.2509)	loss 0.3717 (0.3586)	grad_norm 252390.2812 (inf)	mem 14543MB
[2023-10-12 16:10:59 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2518 (0.2509)	loss 0.3841 (0.3586)	grad_norm 223258.7344 (inf)	mem 14543MB
[2023-10-12 16:13:04 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2522 (0.2508)	loss 0.3480 (0.3586)	grad_norm 371494.4062 (inf)	mem 14543MB
[2023-10-12 16:15:10 simmim_pretrain](main_simmim.py 218): INFO Train: [128/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2464 (0.2508)	loss 0.3520 (0.3586)	grad_norm 354770.1562 (inf)	mem 14543MB
[2023-10-12 16:16:22 simmim_pretrain](main_simmim.py 228): INFO EPOCH 128 training takes 0:28:23
[2023-10-12 16:16:23 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][0/6787]	eta 2:44:01 lr 0.000200	time 1.4500 (1.4500)	loss 0.3577 (0.3577)	grad_norm 259416.8906 (259416.8906)	mem 14543MB
[2023-10-12 16:18:28 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][500/6787]	eta 0:26:26 lr 0.000200	time 0.2465 (0.2523)	loss 0.3518 (0.3601)	grad_norm 321515.8438 (inf)	mem 14543MB
[2023-10-12 16:20:34 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][1000/6787]	eta 0:24:16 lr 0.000200	time 0.2523 (0.2516)	loss 0.3727 (0.3594)	grad_norm 193473.9531 (inf)	mem 14543MB
[2023-10-12 16:22:39 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][1500/6787]	eta 0:22:08 lr 0.000200	time 0.2533 (0.2513)	loss 0.3690 (0.3595)	grad_norm 194347.1406 (inf)	mem 14543MB
[2023-10-12 16:24:45 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2460 (0.2512)	loss 0.3686 (0.3600)	grad_norm 123327.3047 (inf)	mem 14543MB
[2023-10-12 16:26:50 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2565 (0.2511)	loss 0.3478 (0.3602)	grad_norm 156901.4844 (inf)	mem 14543MB
[2023-10-12 16:28:55 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2499 (0.2511)	loss 0.3757 (0.3605)	grad_norm 135104.0938 (inf)	mem 14543MB
[2023-10-12 16:31:01 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2504 (0.2510)	loss 0.3595 (0.3606)	grad_norm 85180.9297 (inf)	mem 14543MB
[2023-10-12 16:33:06 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2515 (0.2511)	loss 0.3595 (0.3605)	grad_norm 101380.2188 (inf)	mem 14543MB
[2023-10-12 16:35:12 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2495 (0.2510)	loss 0.3749 (0.3605)	grad_norm 129272.8047 (inf)	mem 14543MB
[2023-10-12 16:37:17 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2528 (0.2510)	loss 0.3439 (0.3603)	grad_norm 196888.4375 (inf)	mem 14543MB
[2023-10-12 16:39:23 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2515 (0.2511)	loss 0.3673 (0.3601)	grad_norm 250946.1094 (inf)	mem 14543MB
[2023-10-12 16:41:29 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2530 (0.2511)	loss 0.3446 (0.3599)	grad_norm 252532.6875 (inf)	mem 14543MB
[2023-10-12 16:43:36 simmim_pretrain](main_simmim.py 218): INFO Train: [129/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2533 (0.2513)	loss 0.3712 (0.3597)	grad_norm 426896.1875 (inf)	mem 14543MB
[2023-10-12 16:44:50 simmim_pretrain](main_simmim.py 228): INFO EPOCH 129 training takes 0:28:27
[2023-10-12 16:44:51 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][0/6787]	eta 2:54:38 lr 0.000200	time 1.5439 (1.5439)	loss 0.3519 (0.3519)	grad_norm 471710.4375 (471710.4375)	mem 14543MB
[2023-10-12 16:46:58 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][500/6787]	eta 0:26:55 lr 0.000200	time 0.2552 (0.2569)	loss 0.3599 (0.3592)	grad_norm 276504.0000 (371220.8125)	mem 14543MB
[2023-10-12 16:49:06 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][1000/6787]	eta 0:24:40 lr 0.000200	time 0.2507 (0.2558)	loss 0.3549 (0.3580)	grad_norm 342059.5312 (inf)	mem 14543MB
[2023-10-12 16:51:13 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][1500/6787]	eta 0:22:30 lr 0.000200	time 0.2587 (0.2554)	loss 0.3576 (0.3577)	grad_norm 235381.9531 (inf)	mem 14543MB
[2023-10-12 16:53:20 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][2000/6787]	eta 0:20:20 lr 0.000200	time 0.2542 (0.2551)	loss 0.3481 (0.3577)	grad_norm 617979.8125 (inf)	mem 14543MB
[2023-10-12 16:55:27 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][2500/6787]	eta 0:18:12 lr 0.000200	time 0.2550 (0.2548)	loss 0.3503 (0.3577)	grad_norm 393041.7812 (inf)	mem 14543MB
[2023-10-12 16:57:34 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][3000/6787]	eta 0:16:04 lr 0.000200	time 0.2533 (0.2546)	loss 0.3402 (0.3577)	grad_norm 603406.9375 (inf)	mem 14543MB
[2023-10-12 16:59:40 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][3500/6787]	eta 0:13:56 lr 0.000200	time 0.2511 (0.2544)	loss 0.3503 (0.3578)	grad_norm 366752.0938 (inf)	mem 14543MB
[2023-10-12 17:01:47 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][4000/6787]	eta 0:11:48 lr 0.000200	time 0.2523 (0.2543)	loss 0.3662 (0.3578)	grad_norm 262770.4375 (inf)	mem 14543MB
[2023-10-12 17:03:53 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][4500/6787]	eta 0:09:41 lr 0.000200	time 0.2535 (0.2541)	loss 0.3482 (0.3580)	grad_norm 242703.5000 (inf)	mem 14543MB
[2023-10-12 17:06:00 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][5000/6787]	eta 0:07:33 lr 0.000200	time 0.2532 (0.2540)	loss 0.3486 (0.3582)	grad_norm 268152.5312 (inf)	mem 14543MB
[2023-10-12 17:08:06 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2540 (0.2539)	loss 0.3716 (0.3583)	grad_norm 327990.4062 (inf)	mem 14543MB
[2023-10-12 17:10:12 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2523 (0.2538)	loss 0.3543 (0.3583)	grad_norm 245587.0312 (inf)	mem 14543MB
[2023-10-12 17:12:19 simmim_pretrain](main_simmim.py 218): INFO Train: [130/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2504 (0.2537)	loss 0.3670 (0.3582)	grad_norm 291439.6562 (inf)	mem 14543MB
[2023-10-12 17:13:32 simmim_pretrain](main_simmim.py 228): INFO EPOCH 130 training takes 0:28:42
[2023-10-12 17:13:33 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][0/6787]	eta 2:31:28 lr 0.000200	time 1.3391 (1.3391)	loss 0.3429 (0.3429)	grad_norm 155737.2969 (155737.2969)	mem 14543MB
[2023-10-12 17:15:38 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2496 (0.2529)	loss 0.3679 (0.3612)	grad_norm 93049.5078 (148288.1094)	mem 14543MB
[2023-10-12 17:17:44 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2483 (0.2518)	loss 0.3485 (0.3614)	grad_norm 129578.6172 (141761.3281)	mem 14543MB
[2023-10-12 17:19:49 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][1500/6787]	eta 0:22:09 lr 0.000200	time 0.2515 (0.2514)	loss 0.3749 (0.3612)	grad_norm 136663.1406 (138612.8281)	mem 14543MB
[2023-10-12 17:21:54 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2501 (0.2513)	loss 0.3553 (0.3611)	grad_norm 133734.3750 (142076.5781)	mem 14543MB
[2023-10-12 17:24:00 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2496 (0.2512)	loss 0.3550 (0.3609)	grad_norm 408582.1875 (153667.4531)	mem 14543MB
[2023-10-12 17:26:05 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][3000/6787]	eta 0:15:51 lr 0.000200	time 0.2512 (0.2511)	loss 0.3580 (0.3606)	grad_norm 282452.0938 (162964.1406)	mem 14543MB
[2023-10-12 17:28:11 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2468 (0.2511)	loss 0.3567 (0.3603)	grad_norm 223185.2500 (171436.6875)	mem 14543MB
[2023-10-12 17:30:16 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2469 (0.2511)	loss 0.3557 (0.3600)	grad_norm 321513.8438 (181662.6406)	mem 14543MB
[2023-10-12 17:32:22 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2509 (0.2511)	loss 0.3737 (0.3598)	grad_norm 221285.6406 (inf)	mem 14543MB
[2023-10-12 17:34:28 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2491 (0.2512)	loss 0.3595 (0.3596)	grad_norm 258731.4062 (inf)	mem 14543MB
[2023-10-12 17:36:33 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2491 (0.2512)	loss 0.3390 (0.3594)	grad_norm 138180.3594 (inf)	mem 14543MB
[2023-10-12 17:38:39 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2550 (0.2511)	loss 0.3448 (0.3594)	grad_norm 338153.8750 (inf)	mem 14543MB
[2023-10-12 17:40:44 simmim_pretrain](main_simmim.py 218): INFO Train: [131/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2542 (0.2511)	loss 0.3889 (0.3594)	grad_norm 120454.3828 (inf)	mem 14543MB
[2023-10-12 17:41:56 simmim_pretrain](main_simmim.py 228): INFO EPOCH 131 training takes 0:28:24
[2023-10-12 17:41:58 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][0/6787]	eta 2:46:38 lr 0.000200	time 1.4732 (1.4732)	loss 0.3678 (0.3678)	grad_norm 200131.4062 (200131.4062)	mem 14543MB
[2023-10-12 17:44:03 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][500/6787]	eta 0:26:29 lr 0.000200	time 0.2553 (0.2528)	loss 0.3516 (0.3598)	grad_norm 206942.5312 (235991.3906)	mem 14543MB
[2023-10-12 17:46:09 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2513 (0.2519)	loss 0.3686 (0.3591)	grad_norm 165154.3750 (237167.0000)	mem 14543MB
[2023-10-12 17:48:14 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][1500/6787]	eta 0:22:09 lr 0.000200	time 0.2540 (0.2515)	loss 0.3346 (0.3600)	grad_norm 162795.5781 (inf)	mem 14543MB
[2023-10-12 17:50:19 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2529 (0.2512)	loss 0.3642 (0.3606)	grad_norm 124697.1172 (inf)	mem 14543MB
[2023-10-12 17:52:24 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2501 (0.2510)	loss 0.3689 (0.3612)	grad_norm 95991.1250 (inf)	mem 14543MB
[2023-10-12 17:54:30 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2466 (0.2510)	loss 0.3848 (0.3619)	grad_norm 61610.3945 (inf)	mem 14543MB
[2023-10-12 17:56:35 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][3500/6787]	eta 0:13:44 lr 0.000200	time 0.2473 (0.2509)	loss 0.3727 (0.3623)	grad_norm 62217.8867 (inf)	mem 14543MB
[2023-10-12 17:58:40 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2538 (0.2509)	loss 0.3864 (0.3624)	grad_norm 72399.7812 (inf)	mem 14543MB
[2023-10-12 18:00:45 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2534 (0.2508)	loss 0.3385 (0.3625)	grad_norm 87369.2734 (inf)	mem 14543MB
[2023-10-12 18:02:51 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2466 (0.2508)	loss 0.3484 (0.3623)	grad_norm 137244.1250 (inf)	mem 14543MB
[2023-10-12 18:04:56 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2459 (0.2508)	loss 0.3530 (0.3621)	grad_norm 165874.4688 (inf)	mem 14543MB
[2023-10-12 18:07:01 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2501 (0.2508)	loss 0.3632 (0.3619)	grad_norm 136591.6094 (inf)	mem 14543MB
[2023-10-12 18:09:06 simmim_pretrain](main_simmim.py 218): INFO Train: [132/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2504 (0.2507)	loss 0.3445 (0.3618)	grad_norm 135790.5781 (inf)	mem 14543MB
[2023-10-12 18:10:19 simmim_pretrain](main_simmim.py 228): INFO EPOCH 132 training takes 0:28:22
[2023-10-12 18:10:21 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][0/6787]	eta 3:29:28 lr 0.000200	time 1.8519 (1.8519)	loss 0.3727 (0.3727)	grad_norm 97838.2031 (97838.2031)	mem 14543MB
[2023-10-12 18:12:26 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][500/6787]	eta 0:26:31 lr 0.000200	time 0.2515 (0.2531)	loss 0.3704 (0.3590)	grad_norm 193506.2188 (157063.5312)	mem 14543MB
[2023-10-12 18:14:31 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][1000/6787]	eta 0:24:16 lr 0.000200	time 0.2538 (0.2517)	loss 0.3380 (0.3586)	grad_norm 227608.5625 (170667.0781)	mem 14543MB
[2023-10-12 18:16:36 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][1500/6787]	eta 0:22:08 lr 0.000200	time 0.2473 (0.2514)	loss 0.3699 (0.3582)	grad_norm 175783.0469 (182904.2656)	mem 14543MB
[2023-10-12 18:18:41 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][2000/6787]	eta 0:20:01 lr 0.000200	time 0.2491 (0.2511)	loss 0.3464 (0.3578)	grad_norm 581568.2500 (204627.3906)	mem 14543MB
[2023-10-12 18:20:47 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2501 (0.2510)	loss 0.3436 (0.3577)	grad_norm 329301.3438 (223439.9375)	mem 14543MB
[2023-10-12 18:22:52 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2526 (0.2509)	loss 0.3609 (0.3574)	grad_norm 442782.5312 (252066.7656)	mem 14543MB
[2023-10-12 18:24:57 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][3500/6787]	eta 0:13:44 lr 0.000200	time 0.2496 (0.2508)	loss 0.3751 (0.3572)	grad_norm 326120.0625 (inf)	mem 14543MB
[2023-10-12 18:27:02 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][4000/6787]	eta 0:11:38 lr 0.000200	time 0.2509 (0.2508)	loss 0.3789 (0.3573)	grad_norm 178101.1719 (inf)	mem 14543MB
[2023-10-12 18:29:08 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][4500/6787]	eta 0:09:33 lr 0.000200	time 0.2502 (0.2507)	loss 0.3726 (0.3576)	grad_norm 193723.7344 (inf)	mem 14543MB
[2023-10-12 18:31:13 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][5000/6787]	eta 0:07:27 lr 0.000200	time 0.2459 (0.2507)	loss 0.3557 (0.3580)	grad_norm 140253.6875 (inf)	mem 14543MB
[2023-10-12 18:33:18 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2536 (0.2506)	loss 0.3665 (0.3583)	grad_norm 127696.6719 (inf)	mem 14543MB
[2023-10-12 18:35:23 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2490 (0.2507)	loss 0.3338 (0.3585)	grad_norm 123458.5078 (inf)	mem 14543MB
[2023-10-12 18:37:29 simmim_pretrain](main_simmim.py 218): INFO Train: [133/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2465 (0.2507)	loss 0.3659 (0.3586)	grad_norm 133800.5625 (inf)	mem 14543MB
[2023-10-12 18:38:41 simmim_pretrain](main_simmim.py 228): INFO EPOCH 133 training takes 0:28:22
[2023-10-12 18:38:43 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][0/6787]	eta 2:45:43 lr 0.000200	time 1.4651 (1.4651)	loss 0.3602 (0.3602)	grad_norm 185661.7031 (185661.7031)	mem 14543MB
[2023-10-12 18:40:48 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][500/6787]	eta 0:26:31 lr 0.000200	time 0.2529 (0.2531)	loss 0.3573 (0.3572)	grad_norm 159416.6875 (171021.7812)	mem 14543MB
[2023-10-12 18:42:53 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][1000/6787]	eta 0:24:18 lr 0.000200	time 0.2546 (0.2520)	loss 0.3599 (0.3586)	grad_norm 202375.3906 (193314.6250)	mem 14543MB
[2023-10-12 18:44:59 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2523 (0.2517)	loss 0.3494 (0.3586)	grad_norm 161611.0781 (201038.0312)	mem 14543MB
[2023-10-12 18:47:05 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][2000/6787]	eta 0:20:05 lr 0.000200	time 0.2452 (0.2519)	loss 0.3617 (0.3584)	grad_norm 285122.7812 (221396.8750)	mem 14543MB
[2023-10-12 18:49:12 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][2500/6787]	eta 0:18:00 lr 0.000200	time 0.2537 (0.2521)	loss 0.3521 (0.3583)	grad_norm 375998.7500 (236736.6094)	mem 14543MB
[2023-10-12 18:51:18 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][3000/6787]	eta 0:15:55 lr 0.000200	time 0.2536 (0.2523)	loss 0.3517 (0.3580)	grad_norm 201996.0156 (inf)	mem 14543MB
[2023-10-12 18:53:26 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][3500/6787]	eta 0:13:50 lr 0.000200	time 0.2529 (0.2526)	loss 0.3649 (0.3581)	grad_norm 272885.8125 (inf)	mem 14543MB
[2023-10-12 18:55:32 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][4000/6787]	eta 0:11:44 lr 0.000200	time 0.2530 (0.2527)	loss 0.3591 (0.3582)	grad_norm 244011.6094 (inf)	mem 14543MB
[2023-10-12 18:57:39 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][4500/6787]	eta 0:09:38 lr 0.000200	time 0.2570 (0.2528)	loss 0.3658 (0.3583)	grad_norm 191045.4375 (inf)	mem 14543MB
[2023-10-12 18:59:46 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][5000/6787]	eta 0:07:31 lr 0.000200	time 0.2474 (0.2528)	loss 0.3627 (0.3583)	grad_norm 210572.5938 (inf)	mem 14543MB
[2023-10-12 19:01:52 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2566 (0.2529)	loss 0.3706 (0.3582)	grad_norm 584391.1250 (inf)	mem 14543MB
[2023-10-12 19:04:00 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2538 (0.2531)	loss 0.3448 (0.3581)	grad_norm 215602.3281 (inf)	mem 14543MB
[2023-10-12 19:06:08 simmim_pretrain](main_simmim.py 218): INFO Train: [134/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2540 (0.2533)	loss 0.3470 (0.3580)	grad_norm 324175.9375 (inf)	mem 14543MB
[2023-10-12 19:07:21 simmim_pretrain](main_simmim.py 228): INFO EPOCH 134 training takes 0:28:40
[2023-10-12 19:07:23 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][0/6787]	eta 2:47:38 lr 0.000200	time 1.4820 (1.4820)	loss 0.3740 (0.3740)	grad_norm 411637.9375 (411637.9375)	mem 14543MB
[2023-10-12 19:09:29 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][500/6787]	eta 0:26:42 lr 0.000200	time 0.2594 (0.2550)	loss 0.3374 (0.3573)	grad_norm 286568.0000 (inf)	mem 14543MB
[2023-10-12 19:11:35 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][1000/6787]	eta 0:24:28 lr 0.000200	time 0.2591 (0.2538)	loss 0.3576 (0.3568)	grad_norm 364674.8750 (inf)	mem 14543MB
[2023-10-12 19:13:42 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][1500/6787]	eta 0:22:19 lr 0.000200	time 0.2546 (0.2534)	loss 0.3367 (0.3570)	grad_norm 402828.5938 (inf)	mem 14543MB
[2023-10-12 19:15:48 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][2000/6787]	eta 0:20:12 lr 0.000200	time 0.2540 (0.2533)	loss 0.3637 (0.3569)	grad_norm 463561.6562 (inf)	mem 14543MB
[2023-10-12 19:17:55 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][2500/6787]	eta 0:18:05 lr 0.000200	time 0.2556 (0.2533)	loss 0.3554 (0.3567)	grad_norm 254329.4688 (inf)	mem 14543MB
[2023-10-12 19:20:01 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][3000/6787]	eta 0:15:59 lr 0.000200	time 0.2468 (0.2533)	loss 0.3444 (0.3566)	grad_norm 396845.4062 (inf)	mem 14543MB
[2023-10-12 19:22:09 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][3500/6787]	eta 0:13:53 lr 0.000200	time 0.2538 (0.2534)	loss 0.3718 (0.3567)	grad_norm 240162.9688 (inf)	mem 14543MB
[2023-10-12 19:24:18 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][4000/6787]	eta 0:11:47 lr 0.000200	time 0.2541 (0.2540)	loss 0.3508 (0.3568)	grad_norm 281023.1250 (inf)	mem 14543MB
[2023-10-12 19:26:26 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][4500/6787]	eta 0:09:41 lr 0.000200	time 0.2559 (0.2544)	loss 0.3683 (0.3569)	grad_norm 421727.2188 (inf)	mem 14543MB
[2023-10-12 19:28:35 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][5000/6787]	eta 0:07:35 lr 0.000200	time 0.2594 (0.2547)	loss 0.3510 (0.3569)	grad_norm 552607.7500 (inf)	mem 14543MB
[2023-10-12 19:30:43 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][5500/6787]	eta 0:05:27 lr 0.000200	time 0.2578 (0.2548)	loss 0.3710 (0.3569)	grad_norm 757826.7500 (inf)	mem 14543MB
[2023-10-12 19:32:51 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][6000/6787]	eta 0:03:20 lr 0.000200	time 0.2540 (0.2549)	loss 0.3531 (0.3569)	grad_norm 455450.0938 (inf)	mem 14543MB
[2023-10-12 19:34:59 simmim_pretrain](main_simmim.py 218): INFO Train: [135/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2551 (0.2550)	loss 0.3612 (0.3570)	grad_norm 351890.0625 (inf)	mem 14543MB
[2023-10-12 19:36:13 simmim_pretrain](main_simmim.py 228): INFO EPOCH 135 training takes 0:28:51
[2023-10-12 19:36:14 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][0/6787]	eta 2:48:19 lr 0.000200	time 1.4881 (1.4881)	loss 0.3467 (0.3467)	grad_norm 247090.6250 (247090.6250)	mem 14543MB
[2023-10-12 19:38:21 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][500/6787]	eta 0:26:46 lr 0.000200	time 0.2521 (0.2556)	loss 0.3630 (0.3592)	grad_norm 289176.0312 (246966.4375)	mem 14543MB
[2023-10-12 19:40:28 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][1000/6787]	eta 0:24:34 lr 0.000200	time 0.2555 (0.2547)	loss 0.3498 (0.3589)	grad_norm 276987.5000 (248842.0156)	mem 14543MB
[2023-10-12 19:42:35 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][1500/6787]	eta 0:22:25 lr 0.000200	time 0.2494 (0.2544)	loss 0.3560 (0.3588)	grad_norm 259091.4844 (246634.2969)	mem 14543MB
[2023-10-12 19:44:43 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][2000/6787]	eta 0:20:20 lr 0.000200	time 0.2600 (0.2550)	loss 0.3680 (0.3588)	grad_norm 312565.5625 (252054.2500)	mem 14543MB
[2023-10-12 19:46:53 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][2500/6787]	eta 0:18:16 lr 0.000200	time 0.2602 (0.2559)	loss 0.3583 (0.3582)	grad_norm 245105.7812 (282024.2188)	mem 14543MB
[2023-10-12 19:49:02 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][3000/6787]	eta 0:16:11 lr 0.000200	time 0.2604 (0.2564)	loss 0.3767 (0.3581)	grad_norm 230134.0000 (inf)	mem 14543MB
[2023-10-12 19:51:12 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][3500/6787]	eta 0:14:04 lr 0.000200	time 0.2601 (0.2569)	loss 0.3369 (0.3582)	grad_norm 246846.2500 (inf)	mem 14543MB
[2023-10-12 19:53:22 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][4000/6787]	eta 0:11:56 lr 0.000200	time 0.2597 (0.2572)	loss 0.3494 (0.3582)	grad_norm 186701.0312 (inf)	mem 14543MB
[2023-10-12 19:55:32 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][4500/6787]	eta 0:09:48 lr 0.000200	time 0.2611 (0.2574)	loss 0.3485 (0.3583)	grad_norm 285443.7812 (inf)	mem 14543MB
[2023-10-12 19:57:41 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][5000/6787]	eta 0:07:40 lr 0.000200	time 0.2606 (0.2576)	loss 0.3421 (0.3583)	grad_norm 302235.7500 (inf)	mem 14543MB
[2023-10-12 19:59:51 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][5500/6787]	eta 0:05:31 lr 0.000200	time 0.2600 (0.2578)	loss 0.3415 (0.3582)	grad_norm 318666.1562 (inf)	mem 14543MB
[2023-10-12 20:02:01 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2593 (0.2579)	loss 0.3480 (0.3582)	grad_norm 521203.0312 (inf)	mem 14543MB
[2023-10-12 20:04:10 simmim_pretrain](main_simmim.py 218): INFO Train: [136/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2576 (0.2580)	loss 0.3527 (0.3581)	grad_norm 325966.9375 (inf)	mem 14543MB
[2023-10-12 20:05:25 simmim_pretrain](main_simmim.py 228): INFO EPOCH 136 training takes 0:29:12
[2023-10-12 20:05:27 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][0/6787]	eta 2:44:03 lr 0.000200	time 1.4503 (1.4503)	loss 0.3651 (0.3651)	grad_norm 582980.5000 (582980.5000)	mem 14543MB
[2023-10-12 20:07:34 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][500/6787]	eta 0:26:56 lr 0.000200	time 0.2566 (0.2572)	loss 0.3694 (0.3567)	grad_norm 660918.7500 (451245.0625)	mem 14543MB
[2023-10-12 20:09:44 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][1000/6787]	eta 0:24:55 lr 0.000200	time 0.2541 (0.2585)	loss 0.3670 (0.3567)	grad_norm 429719.5625 (inf)	mem 14543MB
[2023-10-12 20:11:54 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][1500/6787]	eta 0:22:47 lr 0.000200	time 0.2586 (0.2587)	loss 0.3533 (0.3577)	grad_norm 226942.7812 (inf)	mem 14543MB
[2023-10-12 20:14:03 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][2000/6787]	eta 0:20:37 lr 0.000200	time 0.2582 (0.2586)	loss 0.3430 (0.3578)	grad_norm 114029.3672 (inf)	mem 14543MB
[2023-10-12 20:16:12 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][2500/6787]	eta 0:18:28 lr 0.000200	time 0.2582 (0.2585)	loss 0.3340 (0.3581)	grad_norm 342805.9062 (inf)	mem 14543MB
[2023-10-12 20:18:21 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][3000/6787]	eta 0:16:18 lr 0.000200	time 0.2587 (0.2585)	loss 0.3495 (0.3582)	grad_norm 198535.3906 (inf)	mem 14543MB
[2023-10-12 20:20:30 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][3500/6787]	eta 0:14:09 lr 0.000200	time 0.2578 (0.2584)	loss 0.3737 (0.3580)	grad_norm 348686.5312 (inf)	mem 14543MB
[2023-10-12 20:22:39 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][4000/6787]	eta 0:12:00 lr 0.000200	time 0.2588 (0.2584)	loss 0.3506 (0.3580)	grad_norm 167342.8281 (inf)	mem 14543MB
[2023-10-12 20:24:48 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][4500/6787]	eta 0:09:50 lr 0.000200	time 0.2593 (0.2584)	loss 0.3516 (0.3582)	grad_norm 280914.9375 (inf)	mem 14543MB
[2023-10-12 20:26:57 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][5000/6787]	eta 0:07:41 lr 0.000200	time 0.2575 (0.2583)	loss 0.3552 (0.3584)	grad_norm 261513.7500 (inf)	mem 14543MB
[2023-10-12 20:29:06 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][5500/6787]	eta 0:05:32 lr 0.000200	time 0.2569 (0.2582)	loss 0.3259 (0.3584)	grad_norm 236525.0312 (inf)	mem 14543MB
[2023-10-12 20:31:15 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][6000/6787]	eta 0:03:23 lr 0.000200	time 0.2579 (0.2582)	loss 0.3737 (0.3585)	grad_norm 262438.4062 (inf)	mem 14543MB
[2023-10-12 20:33:24 simmim_pretrain](main_simmim.py 218): INFO Train: [137/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2574 (0.2582)	loss 0.3743 (0.3583)	grad_norm 383274.7188 (inf)	mem 14543MB
[2023-10-12 20:34:38 simmim_pretrain](main_simmim.py 228): INFO EPOCH 137 training takes 0:29:13
[2023-10-12 20:34:40 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][0/6787]	eta 2:53:26 lr 0.000200	time 1.5333 (1.5333)	loss 0.3688 (0.3688)	grad_norm 423714.8438 (423714.8438)	mem 14543MB
[2023-10-12 20:36:46 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][500/6787]	eta 0:26:46 lr 0.000200	time 0.2546 (0.2555)	loss 0.3594 (0.3572)	grad_norm 356931.8125 (inf)	mem 14543MB
[2023-10-12 20:38:52 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][1000/6787]	eta 0:24:28 lr 0.000200	time 0.2536 (0.2537)	loss 0.3698 (0.3579)	grad_norm 201832.4062 (inf)	mem 14543MB
[2023-10-12 20:40:58 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][1500/6787]	eta 0:22:18 lr 0.000200	time 0.2507 (0.2531)	loss 0.3575 (0.3582)	grad_norm 335909.4375 (inf)	mem 14543MB
[2023-10-12 20:43:05 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][2000/6787]	eta 0:20:11 lr 0.000200	time 0.2508 (0.2530)	loss 0.3636 (0.3583)	grad_norm 392523.2812 (inf)	mem 14543MB
[2023-10-12 20:45:11 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][2500/6787]	eta 0:18:04 lr 0.000200	time 0.2519 (0.2530)	loss 0.3639 (0.3591)	grad_norm 117083.3594 (nan)	mem 14543MB
[2023-10-12 20:47:18 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][3000/6787]	eta 0:15:58 lr 0.000200	time 0.2488 (0.2531)	loss 0.3443 (0.3598)	grad_norm 98810.0312 (nan)	mem 14543MB
[2023-10-12 20:49:25 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][3500/6787]	eta 0:13:52 lr 0.000200	time 0.2534 (0.2532)	loss 0.3387 (0.3599)	grad_norm 131022.7344 (nan)	mem 14543MB
[2023-10-12 20:51:31 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][4000/6787]	eta 0:11:45 lr 0.000200	time 0.2502 (0.2532)	loss 0.3445 (0.3601)	grad_norm 184089.5625 (nan)	mem 14543MB
[2023-10-12 20:53:38 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][4500/6787]	eta 0:09:39 lr 0.000200	time 0.2529 (0.2532)	loss 0.3495 (0.3600)	grad_norm 177251.2500 (nan)	mem 14543MB
[2023-10-12 20:55:45 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][5000/6787]	eta 0:07:32 lr 0.000200	time 0.2519 (0.2532)	loss 0.3626 (0.3599)	grad_norm 149186.5156 (nan)	mem 14543MB
[2023-10-12 20:57:52 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2509 (0.2534)	loss 0.3609 (0.3597)	grad_norm 278803.7500 (nan)	mem 14543MB
[2023-10-12 21:00:02 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2610 (0.2539)	loss 0.3561 (0.3597)	grad_norm 409670.2812 (nan)	mem 14543MB
[2023-10-12 21:02:11 simmim_pretrain](main_simmim.py 218): INFO Train: [138/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2540 (0.2541)	loss 0.3453 (0.3595)	grad_norm 335395.8125 (nan)	mem 14543MB
[2023-10-12 21:03:24 simmim_pretrain](main_simmim.py 228): INFO EPOCH 138 training takes 0:28:45
[2023-10-12 21:03:26 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][0/6787]	eta 2:46:39 lr 0.000200	time 1.4733 (1.4733)	loss 0.3603 (0.3603)	grad_norm 736024.6250 (736024.6250)	mem 14543MB
[2023-10-12 21:05:32 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][500/6787]	eta 0:26:39 lr 0.000200	time 0.2537 (0.2544)	loss 0.3327 (0.3573)	grad_norm 310923.6250 (439042.5625)	mem 14543MB
[2023-10-12 21:07:38 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][1000/6787]	eta 0:24:25 lr 0.000200	time 0.2494 (0.2533)	loss 0.3654 (0.3576)	grad_norm 322528.1875 (412265.4375)	mem 14543MB
[2023-10-12 21:09:44 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][1500/6787]	eta 0:22:16 lr 0.000200	time 0.2509 (0.2528)	loss 0.3567 (0.3575)	grad_norm 560631.5000 (inf)	mem 14543MB
[2023-10-12 21:11:50 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][2000/6787]	eta 0:20:09 lr 0.000200	time 0.2499 (0.2527)	loss 0.3597 (0.3575)	grad_norm 237367.2812 (inf)	mem 14543MB
[2023-10-12 21:13:57 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][2500/6787]	eta 0:18:04 lr 0.000200	time 0.2570 (0.2529)	loss 0.3483 (0.3573)	grad_norm 364589.4688 (inf)	mem 14543MB
[2023-10-12 21:16:03 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][3000/6787]	eta 0:15:58 lr 0.000200	time 0.2557 (0.2530)	loss 0.3291 (0.3573)	grad_norm 521464.1562 (inf)	mem 14543MB
[2023-10-12 21:18:10 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][3500/6787]	eta 0:13:51 lr 0.000200	time 0.2513 (0.2530)	loss 0.3619 (0.3571)	grad_norm 638485.6875 (inf)	mem 14543MB
[2023-10-12 21:20:17 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][4000/6787]	eta 0:11:45 lr 0.000200	time 0.2657 (0.2531)	loss 0.3526 (0.3572)	grad_norm 305279.9688 (inf)	mem 14543MB
[2023-10-12 21:22:23 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][4500/6787]	eta 0:09:38 lr 0.000200	time 0.2503 (0.2531)	loss 0.3542 (0.3574)	grad_norm 303506.0625 (inf)	mem 14543MB
[2023-10-12 21:24:31 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][5000/6787]	eta 0:07:32 lr 0.000200	time 0.2553 (0.2532)	loss 0.3674 (0.3576)	grad_norm 318532.4688 (inf)	mem 14543MB
[2023-10-12 21:26:38 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2555 (0.2534)	loss 0.3693 (0.3577)	grad_norm 354473.2500 (inf)	mem 14543MB
[2023-10-12 21:28:45 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2523 (0.2535)	loss 0.3707 (0.3576)	grad_norm 181190.7031 (inf)	mem 14543MB
[2023-10-12 21:30:53 simmim_pretrain](main_simmim.py 218): INFO Train: [139/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2554 (0.2536)	loss 0.3820 (0.3577)	grad_norm 196072.5469 (inf)	mem 14543MB
[2023-10-12 21:32:06 simmim_pretrain](main_simmim.py 228): INFO EPOCH 139 training takes 0:28:41
[2023-10-12 21:32:07 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][0/6787]	eta 2:40:49 lr 0.000200	time 1.4217 (1.4217)	loss 0.3671 (0.3671)	grad_norm 157128.3750 (157128.3750)	mem 14543MB
[2023-10-12 21:34:13 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][500/6787]	eta 0:26:37 lr 0.000200	time 0.2471 (0.2542)	loss 0.3690 (0.3567)	grad_norm 192203.0625 (254308.3594)	mem 14543MB
[2023-10-12 21:36:19 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][1000/6787]	eta 0:24:25 lr 0.000200	time 0.2531 (0.2532)	loss 0.3539 (0.3576)	grad_norm 240057.7812 (254957.1875)	mem 14543MB
[2023-10-12 21:38:25 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][1500/6787]	eta 0:22:17 lr 0.000200	time 0.2517 (0.2530)	loss 0.3649 (0.3578)	grad_norm 353946.9062 (260324.5938)	mem 14543MB
[2023-10-12 21:40:32 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][2000/6787]	eta 0:20:11 lr 0.000200	time 0.2510 (0.2530)	loss 0.3665 (0.3576)	grad_norm 382478.8750 (287769.2500)	mem 14543MB
[2023-10-12 21:42:39 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][2500/6787]	eta 0:18:05 lr 0.000200	time 0.2489 (0.2532)	loss 0.3504 (0.3575)	grad_norm 515669.9375 (307327.9375)	mem 14543MB
[2023-10-12 21:44:48 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][3000/6787]	eta 0:16:02 lr 0.000200	time 0.2595 (0.2542)	loss 0.3828 (0.3574)	grad_norm 327587.2812 (327162.2812)	mem 14543MB
[2023-10-12 21:46:58 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][3500/6787]	eta 0:13:57 lr 0.000200	time 0.2578 (0.2549)	loss 0.3503 (0.3573)	grad_norm 603094.0000 (inf)	mem 14543MB
[2023-10-12 21:49:07 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][4000/6787]	eta 0:11:51 lr 0.000200	time 0.2594 (0.2554)	loss 0.3414 (0.3574)	grad_norm 283232.3750 (inf)	mem 14543MB
[2023-10-12 21:51:17 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][4500/6787]	eta 0:09:44 lr 0.000200	time 0.2598 (0.2558)	loss 0.3740 (0.3576)	grad_norm 196739.5625 (inf)	mem 14543MB
[2023-10-12 21:53:26 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][5000/6787]	eta 0:07:37 lr 0.000200	time 0.2593 (0.2561)	loss 0.3762 (0.3578)	grad_norm 139841.1562 (inf)	mem 14543MB
[2023-10-12 21:55:36 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][5500/6787]	eta 0:05:29 lr 0.000200	time 0.2584 (0.2564)	loss 0.3438 (0.3578)	grad_norm 201952.2031 (inf)	mem 14543MB
[2023-10-12 21:57:46 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2593 (0.2566)	loss 0.3781 (0.3579)	grad_norm 180120.3438 (inf)	mem 14543MB
[2023-10-12 21:59:55 simmim_pretrain](main_simmim.py 218): INFO Train: [140/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2543 (0.2568)	loss 0.3643 (0.3578)	grad_norm 331432.2188 (inf)	mem 14543MB
[2023-10-12 22:01:10 simmim_pretrain](main_simmim.py 228): INFO EPOCH 140 training takes 0:29:04
[2023-10-12 22:01:10 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_140.pth saving......
[2023-10-12 22:01:10 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_140.pth saved !!!
[2023-10-12 22:01:12 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][0/6787]	eta 2:29:52 lr 0.000200	time 1.3249 (1.3249)	loss 0.3513 (0.3513)	grad_norm 452105.2188 (452105.2188)	mem 14543MB
[2023-10-12 22:03:17 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][500/6787]	eta 0:26:34 lr 0.000200	time 0.2544 (0.2536)	loss 0.3574 (0.3564)	grad_norm 383170.1250 (436252.9375)	mem 14543MB
[2023-10-12 22:05:24 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][1000/6787]	eta 0:24:24 lr 0.000200	time 0.2506 (0.2530)	loss 0.3442 (0.3569)	grad_norm 657144.2500 (inf)	mem 14543MB
[2023-10-12 22:07:31 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][1500/6787]	eta 0:22:19 lr 0.000200	time 0.2561 (0.2534)	loss 0.3572 (0.3573)	grad_norm 566559.1875 (inf)	mem 14543MB
[2023-10-12 22:09:38 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][2000/6787]	eta 0:20:14 lr 0.000200	time 0.2530 (0.2536)	loss 0.3593 (0.3575)	grad_norm 276387.7188 (inf)	mem 14543MB
[2023-10-12 22:11:45 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][2500/6787]	eta 0:18:07 lr 0.000200	time 0.2483 (0.2536)	loss 0.5117 (0.3687)	grad_norm 11041.0029 (inf)	mem 14543MB
[2023-10-12 22:13:51 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][3000/6787]	eta 0:15:59 lr 0.000200	time 0.2501 (0.2535)	loss 0.4524 (0.3900)	grad_norm 46830.1914 (inf)	mem 14543MB
[2023-10-12 22:15:57 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][3500/6787]	eta 0:13:52 lr 0.000200	time 0.2474 (0.2533)	loss 0.3939 (0.3922)	grad_norm 19839.7910 (inf)	mem 14543MB
[2023-10-12 22:18:03 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][4000/6787]	eta 0:11:45 lr 0.000200	time 0.2490 (0.2532)	loss 0.3741 (0.3896)	grad_norm 43657.7344 (inf)	mem 14543MB
[2023-10-12 22:20:10 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][4500/6787]	eta 0:09:39 lr 0.000200	time 0.2528 (0.2532)	loss 0.3706 (0.3872)	grad_norm 31653.1074 (inf)	mem 14543MB
[2023-10-12 22:22:17 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][5000/6787]	eta 0:07:32 lr 0.000200	time 0.2465 (0.2533)	loss 0.3519 (0.3848)	grad_norm 17131.6387 (inf)	mem 14543MB
[2023-10-12 22:24:24 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2509 (0.2534)	loss 0.3499 (0.3827)	grad_norm 70889.2344 (inf)	mem 14543MB
[2023-10-12 22:26:31 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2538 (0.2534)	loss 0.3450 (0.3811)	grad_norm 66766.6719 (inf)	mem 14543MB
[2023-10-12 22:28:37 simmim_pretrain](main_simmim.py 218): INFO Train: [141/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2506 (0.2533)	loss 0.3536 (0.3795)	grad_norm 75082.8594 (inf)	mem 14543MB
[2023-10-12 22:29:50 simmim_pretrain](main_simmim.py 228): INFO EPOCH 141 training takes 0:28:39
[2023-10-12 22:29:51 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][0/6787]	eta 2:48:04 lr 0.000200	time 1.4858 (1.4858)	loss 0.3555 (0.3555)	grad_norm 75042.5000 (75042.5000)	mem 14543MB
[2023-10-12 22:31:57 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][500/6787]	eta 0:26:41 lr 0.000200	time 0.2517 (0.2547)	loss 0.3514 (0.3607)	grad_norm 86339.3516 (78284.5312)	mem 14543MB
[2023-10-12 22:34:04 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][1000/6787]	eta 0:24:29 lr 0.000200	time 0.2458 (0.2539)	loss 0.3757 (0.3603)	grad_norm 103156.4844 (83900.3047)	mem 14543MB
[2023-10-12 22:36:11 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][1500/6787]	eta 0:22:21 lr 0.000200	time 0.2519 (0.2538)	loss 0.3639 (0.3598)	grad_norm 130637.8750 (88242.4922)	mem 14543MB
[2023-10-12 22:38:18 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][2000/6787]	eta 0:20:15 lr 0.000200	time 0.2516 (0.2539)	loss 0.3417 (0.3596)	grad_norm 117280.4922 (99600.8750)	mem 14543MB
[2023-10-12 22:40:25 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][2500/6787]	eta 0:18:08 lr 0.000200	time 0.2543 (0.2539)	loss 0.3656 (0.3595)	grad_norm 88122.8984 (111333.5781)	mem 14543MB
[2023-10-12 22:42:32 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][3000/6787]	eta 0:16:01 lr 0.000200	time 0.2557 (0.2538)	loss 0.3608 (0.3592)	grad_norm 88883.7188 (119312.1406)	mem 14543MB
[2023-10-12 22:44:38 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][3500/6787]	eta 0:13:54 lr 0.000200	time 0.2463 (0.2538)	loss 0.3463 (0.3590)	grad_norm 202045.5469 (128418.7656)	mem 14543MB
[2023-10-12 22:46:45 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][4000/6787]	eta 0:11:47 lr 0.000200	time 0.2467 (0.2537)	loss 0.3541 (0.3588)	grad_norm 226299.7969 (inf)	mem 14543MB
[2023-10-12 22:48:52 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][4500/6787]	eta 0:09:40 lr 0.000200	time 0.2568 (0.2537)	loss 0.3487 (0.3588)	grad_norm 152624.7188 (inf)	mem 14543MB
[2023-10-12 22:50:59 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][5000/6787]	eta 0:07:33 lr 0.000200	time 0.2508 (0.2537)	loss 0.3639 (0.3586)	grad_norm 95081.8828 (inf)	mem 14543MB
[2023-10-12 22:53:05 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2568 (0.2536)	loss 0.3787 (0.3586)	grad_norm 107240.5078 (inf)	mem 14543MB
[2023-10-12 22:55:12 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2579 (0.2536)	loss 0.3574 (0.3586)	grad_norm 327172.4375 (inf)	mem 14543MB
[2023-10-12 22:57:18 simmim_pretrain](main_simmim.py 218): INFO Train: [142/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2532 (0.2535)	loss 0.3595 (0.3585)	grad_norm 257903.5781 (inf)	mem 14543MB
[2023-10-12 22:58:31 simmim_pretrain](main_simmim.py 228): INFO EPOCH 142 training takes 0:28:41
[2023-10-12 22:58:33 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][0/6787]	eta 2:40:52 lr 0.000200	time 1.4222 (1.4222)	loss 0.3443 (0.3443)	grad_norm 464211.7500 (464211.7500)	mem 14543MB
[2023-10-12 23:00:39 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][500/6787]	eta 0:26:46 lr 0.000200	time 0.2545 (0.2555)	loss 0.3399 (0.3560)	grad_norm 304563.1875 (465708.3438)	mem 14543MB
[2023-10-12 23:02:46 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][1000/6787]	eta 0:24:36 lr 0.000200	time 0.2539 (0.2551)	loss 0.3509 (0.3561)	grad_norm 548714.6875 (inf)	mem 14543MB
[2023-10-12 23:04:54 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][1500/6787]	eta 0:22:29 lr 0.000200	time 0.2546 (0.2552)	loss 0.3524 (0.3564)	grad_norm 382324.8438 (inf)	mem 14543MB
[2023-10-12 23:07:02 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][2000/6787]	eta 0:20:21 lr 0.000200	time 0.2548 (0.2552)	loss 0.3582 (0.3566)	grad_norm 320679.6562 (inf)	mem 14543MB
[2023-10-12 23:09:09 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][2500/6787]	eta 0:18:13 lr 0.000200	time 0.2533 (0.2550)	loss 0.3501 (0.3564)	grad_norm 537145.4375 (inf)	mem 14543MB
[2023-10-12 23:11:16 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][3000/6787]	eta 0:16:05 lr 0.000200	time 0.2534 (0.2550)	loss 0.3806 (0.3565)	grad_norm 490226.4375 (inf)	mem 14543MB
[2023-10-12 23:13:24 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][3500/6787]	eta 0:13:58 lr 0.000200	time 0.2564 (0.2550)	loss 0.3742 (0.3567)	grad_norm 154836.9844 (inf)	mem 14543MB
[2023-10-12 23:15:31 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][4000/6787]	eta 0:11:50 lr 0.000200	time 0.2526 (0.2550)	loss 0.3631 (0.3570)	grad_norm 210106.0469 (inf)	mem 14543MB
[2023-10-12 23:17:39 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][4500/6787]	eta 0:09:43 lr 0.000200	time 0.2539 (0.2550)	loss 0.3453 (0.3571)	grad_norm 184100.8281 (inf)	mem 14543MB
[2023-10-12 23:19:47 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][5000/6787]	eta 0:07:35 lr 0.000200	time 0.2538 (0.2550)	loss 0.3572 (0.3572)	grad_norm 161449.7344 (inf)	mem 14543MB
[2023-10-12 23:21:54 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][5500/6787]	eta 0:05:28 lr 0.000200	time 0.2527 (0.2551)	loss 0.3663 (0.3573)	grad_norm 146782.6094 (inf)	mem 14543MB
[2023-10-12 23:24:02 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][6000/6787]	eta 0:03:20 lr 0.000200	time 0.2594 (0.2551)	loss 0.3601 (0.3573)	grad_norm 251937.4844 (inf)	mem 14543MB
[2023-10-12 23:26:10 simmim_pretrain](main_simmim.py 218): INFO Train: [143/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2529 (0.2551)	loss 0.3617 (0.3572)	grad_norm 499877.8125 (inf)	mem 14543MB
[2023-10-12 23:27:24 simmim_pretrain](main_simmim.py 228): INFO EPOCH 143 training takes 0:28:52
[2023-10-12 23:27:25 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][0/6787]	eta 2:55:46 lr 0.000200	time 1.5539 (1.5539)	loss 0.3760 (0.3760)	grad_norm 382667.5312 (382667.5312)	mem 14543MB
[2023-10-12 23:29:32 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][500/6787]	eta 0:26:53 lr 0.000200	time 0.2544 (0.2566)	loss 0.3574 (0.3577)	grad_norm 399868.3438 (359994.4375)	mem 14543MB
[2023-10-12 23:31:39 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][1000/6787]	eta 0:24:38 lr 0.000200	time 0.2528 (0.2554)	loss 0.3389 (0.3571)	grad_norm 420865.2188 (inf)	mem 14543MB
[2023-10-12 23:33:46 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][1500/6787]	eta 0:22:26 lr 0.000200	time 0.2531 (0.2547)	loss 0.3485 (0.3570)	grad_norm 265816.0312 (inf)	mem 14543MB
[2023-10-12 23:35:52 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][2000/6787]	eta 0:20:15 lr 0.000200	time 0.2489 (0.2540)	loss 0.3503 (0.3573)	grad_norm 259058.4688 (inf)	mem 14543MB
[2023-10-12 23:37:58 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][2500/6787]	eta 0:18:07 lr 0.000200	time 0.2507 (0.2536)	loss 0.3535 (0.3578)	grad_norm 268508.8438 (inf)	mem 14543MB
[2023-10-12 23:40:04 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][3000/6787]	eta 0:15:59 lr 0.000200	time 0.2594 (0.2533)	loss 0.3469 (0.3579)	grad_norm 97643.1797 (inf)	mem 14543MB
[2023-10-12 23:42:10 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][3500/6787]	eta 0:13:52 lr 0.000200	time 0.2553 (0.2533)	loss 0.3552 (0.3580)	grad_norm 293765.2500 (inf)	mem 14543MB
[2023-10-12 23:44:18 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][4000/6787]	eta 0:11:46 lr 0.000200	time 0.2609 (0.2537)	loss 0.3665 (0.3579)	grad_norm 580131.0000 (inf)	mem 14543MB
[2023-10-12 23:46:29 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][4500/6787]	eta 0:09:41 lr 0.000200	time 0.2608 (0.2544)	loss 0.3280 (0.3577)	grad_norm 352433.3750 (inf)	mem 14543MB
[2023-10-12 23:48:39 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][5000/6787]	eta 0:07:35 lr 0.000200	time 0.2608 (0.2550)	loss 0.3488 (0.3577)	grad_norm 380837.4375 (inf)	mem 14543MB
[2023-10-12 23:50:49 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][5500/6787]	eta 0:05:28 lr 0.000200	time 0.2605 (0.2554)	loss 0.3520 (0.3576)	grad_norm 281264.0625 (inf)	mem 14543MB
[2023-10-12 23:52:59 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2610 (0.2558)	loss 0.3663 (0.3576)	grad_norm 465062.7812 (inf)	mem 14543MB
[2023-10-12 23:55:08 simmim_pretrain](main_simmim.py 218): INFO Train: [144/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2609 (0.2561)	loss 0.3539 (0.3575)	grad_norm 332526.3125 (inf)	mem 14543MB
[2023-10-12 23:56:24 simmim_pretrain](main_simmim.py 228): INFO EPOCH 144 training takes 0:29:00
[2023-10-12 23:56:25 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][0/6787]	eta 2:31:31 lr 0.000200	time 1.3395 (1.3395)	loss 0.3585 (0.3585)	grad_norm 509315.8750 (509315.8750)	mem 14543MB
[2023-10-12 23:58:32 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][500/6787]	eta 0:26:50 lr 0.000200	time 0.2547 (0.2562)	loss 0.3538 (0.3584)	grad_norm 287250.8125 (284358.6250)	mem 14543MB
[2023-10-13 00:00:39 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][1000/6787]	eta 0:24:36 lr 0.000200	time 0.2563 (0.2552)	loss 0.3738 (0.3582)	grad_norm 237128.4688 (263038.1250)	mem 14543MB
[2023-10-13 00:02:46 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][1500/6787]	eta 0:22:26 lr 0.000200	time 0.2501 (0.2547)	loss 0.3392 (0.3583)	grad_norm 278416.2812 (254640.7812)	mem 14543MB
[2023-10-13 00:04:52 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][2000/6787]	eta 0:20:16 lr 0.000200	time 0.2503 (0.2542)	loss 0.3660 (0.3582)	grad_norm 219032.8281 (250165.9375)	mem 14543MB
[2023-10-13 00:07:00 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][2500/6787]	eta 0:18:10 lr 0.000200	time 0.2539 (0.2543)	loss 0.3536 (0.3581)	grad_norm 386238.7500 (259889.0312)	mem 14543MB
[2023-10-13 00:09:08 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][3000/6787]	eta 0:16:04 lr 0.000200	time 0.2578 (0.2548)	loss 0.3443 (0.3580)	grad_norm 484961.1875 (272865.6875)	mem 14543MB
[2023-10-13 00:11:17 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][3500/6787]	eta 0:13:59 lr 0.000200	time 0.2583 (0.2553)	loss 0.3552 (0.3579)	grad_norm 369376.4062 (288776.8438)	mem 14543MB
[2023-10-13 00:13:26 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][4000/6787]	eta 0:11:51 lr 0.000200	time 0.2512 (0.2554)	loss 0.3522 (0.3577)	grad_norm 483793.6875 (305521.8750)	mem 14543MB
[2023-10-13 00:15:33 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][4500/6787]	eta 0:09:44 lr 0.000200	time 0.2519 (0.2554)	loss 0.3724 (0.3575)	grad_norm 238602.7344 (inf)	mem 14543MB
[2023-10-13 00:17:40 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][5000/6787]	eta 0:07:36 lr 0.000200	time 0.2550 (0.2552)	loss 0.3570 (0.3575)	grad_norm 505789.1250 (inf)	mem 14543MB
[2023-10-13 00:19:46 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][5500/6787]	eta 0:05:28 lr 0.000200	time 0.2560 (0.2550)	loss 0.3412 (0.3575)	grad_norm 592765.0625 (inf)	mem 14543MB
[2023-10-13 00:21:53 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][6000/6787]	eta 0:03:20 lr 0.000200	time 0.2507 (0.2549)	loss 0.3711 (0.3574)	grad_norm 445956.4062 (inf)	mem 14543MB
[2023-10-13 00:24:00 simmim_pretrain](main_simmim.py 218): INFO Train: [145/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2509 (0.2547)	loss 0.3392 (0.3573)	grad_norm 527869.8750 (inf)	mem 14543MB
[2023-10-13 00:25:13 simmim_pretrain](main_simmim.py 228): INFO EPOCH 145 training takes 0:28:49
[2023-10-13 00:25:14 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][0/6787]	eta 2:36:26 lr 0.000200	time 1.3830 (1.3830)	loss 0.3692 (0.3692)	grad_norm 434800.2188 (434800.2188)	mem 14543MB
[2023-10-13 00:27:21 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][500/6787]	eta 0:26:43 lr 0.000200	time 0.2590 (0.2551)	loss 0.3455 (0.3570)	grad_norm 322820.2812 (inf)	mem 14543MB
[2023-10-13 00:29:28 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][1000/6787]	eta 0:24:34 lr 0.000200	time 0.2535 (0.2548)	loss 0.3414 (0.3579)	grad_norm 262320.1250 (inf)	mem 14543MB
[2023-10-13 00:31:36 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][1500/6787]	eta 0:22:29 lr 0.000200	time 0.2562 (0.2553)	loss 0.3635 (0.3580)	grad_norm 217056.8594 (inf)	mem 14543MB
[2023-10-13 00:33:44 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][2000/6787]	eta 0:20:22 lr 0.000200	time 0.2578 (0.2555)	loss 0.3396 (0.3592)	grad_norm 239126.0156 (inf)	mem 14543MB
[2023-10-13 00:35:52 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][2500/6787]	eta 0:18:15 lr 0.000200	time 0.2590 (0.2556)	loss 0.3515 (0.3598)	grad_norm 152799.5469 (inf)	mem 14543MB
[2023-10-13 00:38:00 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][3000/6787]	eta 0:16:07 lr 0.000200	time 0.2518 (0.2556)	loss 0.3935 (0.3599)	grad_norm 199040.6406 (inf)	mem 14543MB
[2023-10-13 00:40:08 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][3500/6787]	eta 0:13:59 lr 0.000200	time 0.2534 (0.2555)	loss 0.3694 (0.3600)	grad_norm 83091.8125 (inf)	mem 14543MB
[2023-10-13 00:42:15 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][4000/6787]	eta 0:11:51 lr 0.000200	time 0.2572 (0.2553)	loss 0.3343 (0.3599)	grad_norm 226849.3594 (inf)	mem 14543MB
[2023-10-13 00:44:22 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][4500/6787]	eta 0:09:43 lr 0.000200	time 0.2524 (0.2552)	loss 0.3787 (0.3598)	grad_norm 216481.7031 (inf)	mem 14543MB
[2023-10-13 00:46:31 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][5000/6787]	eta 0:07:36 lr 0.000200	time 0.2609 (0.2555)	loss 0.3484 (0.3597)	grad_norm 331799.2812 (inf)	mem 14543MB
[2023-10-13 00:48:41 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][5500/6787]	eta 0:05:29 lr 0.000200	time 0.2606 (0.2559)	loss 0.3624 (0.3596)	grad_norm 204233.0156 (inf)	mem 14543MB
[2023-10-13 00:50:51 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2600 (0.2562)	loss 0.3379 (0.3595)	grad_norm 330938.0312 (inf)	mem 14543MB
[2023-10-13 00:53:01 simmim_pretrain](main_simmim.py 218): INFO Train: [146/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2600 (0.2565)	loss 0.3557 (0.3593)	grad_norm 264080.6875 (inf)	mem 14543MB
[2023-10-13 00:54:16 simmim_pretrain](main_simmim.py 228): INFO EPOCH 146 training takes 0:29:02
[2023-10-13 00:54:17 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][0/6787]	eta 2:47:20 lr 0.000200	time 1.4794 (1.4794)	loss 0.3573 (0.3573)	grad_norm 211475.4219 (211475.4219)	mem 14543MB
[2023-10-13 00:56:23 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][500/6787]	eta 0:26:42 lr 0.000200	time 0.2493 (0.2550)	loss 0.3644 (0.3586)	grad_norm 169592.3281 (241175.1250)	mem 14543MB
[2023-10-13 00:58:31 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][1000/6787]	eta 0:24:39 lr 0.000200	time 0.2589 (0.2556)	loss 0.3665 (0.3588)	grad_norm 347051.6250 (238049.0312)	mem 14543MB
[2023-10-13 01:00:40 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][1500/6787]	eta 0:22:35 lr 0.000200	time 0.2580 (0.2564)	loss 0.3511 (0.3585)	grad_norm 104975.1953 (239609.1875)	mem 14543MB
[2023-10-13 01:02:49 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][2000/6787]	eta 0:20:29 lr 0.000200	time 0.2590 (0.2569)	loss 0.3505 (0.3582)	grad_norm 294382.8438 (253863.4062)	mem 14543MB
[2023-10-13 01:04:57 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][2500/6787]	eta 0:18:20 lr 0.000200	time 0.2559 (0.2566)	loss 0.3512 (0.3579)	grad_norm 201535.5469 (288262.2812)	mem 14543MB
[2023-10-13 01:07:06 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][3000/6787]	eta 0:16:11 lr 0.000200	time 0.2601 (0.2566)	loss 0.3461 (0.3578)	grad_norm 273209.3750 (303969.1875)	mem 14543MB
[2023-10-13 01:09:14 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][3500/6787]	eta 0:14:03 lr 0.000200	time 0.2607 (0.2567)	loss 0.3483 (0.3577)	grad_norm 423470.6875 (324463.2188)	mem 14543MB
[2023-10-13 01:11:23 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][4000/6787]	eta 0:11:55 lr 0.000200	time 0.2514 (0.2568)	loss 0.3388 (0.3575)	grad_norm 347963.3750 (inf)	mem 14543MB
[2023-10-13 01:13:31 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][4500/6787]	eta 0:09:47 lr 0.000200	time 0.2540 (0.2568)	loss 0.3642 (0.3575)	grad_norm 427354.7812 (inf)	mem 14543MB
[2023-10-13 01:15:40 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][5000/6787]	eta 0:07:38 lr 0.000200	time 0.2533 (0.2568)	loss 0.3419 (0.3575)	grad_norm 284245.1875 (inf)	mem 14543MB
[2023-10-13 01:17:48 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][5500/6787]	eta 0:05:30 lr 0.000200	time 0.2591 (0.2569)	loss 0.3724 (0.3575)	grad_norm 244469.0625 (inf)	mem 14543MB
[2023-10-13 01:19:57 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2493 (0.2569)	loss 0.3375 (0.3577)	grad_norm 268601.1250 (inf)	mem 14543MB
[2023-10-13 01:22:06 simmim_pretrain](main_simmim.py 218): INFO Train: [147/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.3587 (0.2570)	loss 0.3700 (0.3577)	grad_norm 122887.5938 (inf)	mem 14543MB
[2023-10-13 01:23:20 simmim_pretrain](main_simmim.py 228): INFO EPOCH 147 training takes 0:29:04
[2023-10-13 01:23:22 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][0/6787]	eta 2:46:19 lr 0.000200	time 1.4704 (1.4704)	loss 0.3338 (0.3338)	grad_norm 357979.3438 (357979.3438)	mem 14543MB
[2023-10-13 01:25:31 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][500/6787]	eta 0:27:19 lr 0.000200	time 0.2596 (0.2608)	loss 0.3456 (0.3572)	grad_norm 272372.8438 (292792.9688)	mem 14543MB
[2023-10-13 01:27:40 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][1000/6787]	eta 0:24:58 lr 0.000200	time 0.2570 (0.2589)	loss 0.3517 (0.3571)	grad_norm 393587.7188 (340455.0625)	mem 14543MB
[2023-10-13 01:29:48 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][1500/6787]	eta 0:22:44 lr 0.000200	time 0.2497 (0.2581)	loss 0.3650 (0.3570)	grad_norm 427314.7812 (355725.2188)	mem 14543MB
[2023-10-13 01:31:56 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][2000/6787]	eta 0:20:33 lr 0.000200	time 0.2544 (0.2576)	loss 0.3522 (0.3575)	grad_norm 302286.1250 (inf)	mem 14543MB
[2023-10-13 01:34:04 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][2500/6787]	eta 0:18:23 lr 0.000200	time 0.2574 (0.2575)	loss 0.3650 (0.3576)	grad_norm 244324.5469 (inf)	mem 14543MB
[2023-10-13 01:36:13 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][3000/6787]	eta 0:16:15 lr 0.000200	time 0.2611 (0.2575)	loss 0.3645 (0.3578)	grad_norm 247005.0469 (inf)	mem 14543MB
[2023-10-13 01:38:22 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][3500/6787]	eta 0:14:06 lr 0.000200	time 0.2580 (0.2574)	loss 0.3812 (0.3579)	grad_norm 253302.4375 (inf)	mem 14543MB
[2023-10-13 01:40:30 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][4000/6787]	eta 0:11:57 lr 0.000200	time 0.2500 (0.2574)	loss 0.3407 (0.3579)	grad_norm 297803.8438 (inf)	mem 14543MB
[2023-10-13 01:42:39 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][4500/6787]	eta 0:09:48 lr 0.000200	time 0.2545 (0.2574)	loss 0.3601 (0.3578)	grad_norm 430838.8750 (inf)	mem 14543MB
[2023-10-13 01:44:48 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][5000/6787]	eta 0:07:39 lr 0.000200	time 0.2530 (0.2574)	loss 0.3491 (0.3577)	grad_norm 333429.0312 (inf)	mem 14543MB
[2023-10-13 01:46:56 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][5500/6787]	eta 0:05:31 lr 0.000200	time 0.2458 (0.2573)	loss 0.3570 (0.3576)	grad_norm 301454.5625 (inf)	mem 14543MB
[2023-10-13 01:49:04 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2539 (0.2573)	loss 0.3670 (0.3576)	grad_norm 555655.0000 (inf)	mem 14543MB
[2023-10-13 01:51:13 simmim_pretrain](main_simmim.py 218): INFO Train: [148/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2547 (0.2573)	loss 0.3523 (0.3577)	grad_norm 292190.5312 (inf)	mem 14543MB
[2023-10-13 01:52:27 simmim_pretrain](main_simmim.py 228): INFO EPOCH 148 training takes 0:29:06
[2023-10-13 01:52:28 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][0/6787]	eta 2:40:08 lr 0.000200	time 1.4157 (1.4157)	loss 0.3588 (0.3588)	grad_norm 403019.2812 (403019.2812)	mem 14543MB
[2023-10-13 01:54:37 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][500/6787]	eta 0:27:05 lr 0.000200	time 0.2530 (0.2586)	loss 0.3609 (0.3600)	grad_norm 267265.0938 (271737.1562)	mem 14543MB
[2023-10-13 01:56:45 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][1000/6787]	eta 0:24:52 lr 0.000200	time 0.2602 (0.2578)	loss 0.3482 (0.3591)	grad_norm 298225.5938 (267084.9688)	mem 14543MB
[2023-10-13 01:58:54 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][1500/6787]	eta 0:22:42 lr 0.000200	time 0.2572 (0.2577)	loss 0.3622 (0.3593)	grad_norm 224466.4375 (264735.8750)	mem 14543MB
[2023-10-13 02:01:03 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][2000/6787]	eta 0:20:33 lr 0.000200	time 0.2571 (0.2577)	loss 0.3543 (0.3589)	grad_norm 395137.3750 (278995.8750)	mem 14543MB
[2023-10-13 02:03:11 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][2500/6787]	eta 0:18:24 lr 0.000200	time 0.2559 (0.2576)	loss 0.3610 (0.3583)	grad_norm 357110.0000 (301106.0000)	mem 14543MB
[2023-10-13 02:05:20 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][3000/6787]	eta 0:16:15 lr 0.000200	time 0.2608 (0.2575)	loss 0.3617 (0.3583)	grad_norm 395157.3750 (inf)	mem 14543MB
[2023-10-13 02:07:28 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][3500/6787]	eta 0:14:06 lr 0.000200	time 0.2594 (0.2574)	loss 0.3586 (0.3583)	grad_norm 382023.6875 (inf)	mem 14543MB
[2023-10-13 02:09:37 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][4000/6787]	eta 0:11:57 lr 0.000200	time 0.2587 (0.2573)	loss 0.3418 (0.3584)	grad_norm 241769.4062 (inf)	mem 14543MB
[2023-10-13 02:11:45 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][4500/6787]	eta 0:09:48 lr 0.000200	time 0.2569 (0.2573)	loss 0.3659 (0.3585)	grad_norm 384938.4688 (inf)	mem 14543MB
[2023-10-13 02:13:54 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][5000/6787]	eta 0:07:39 lr 0.000200	time 0.2503 (0.2573)	loss 0.3620 (0.3584)	grad_norm 189740.0469 (inf)	mem 14543MB
[2023-10-13 02:16:03 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][5500/6787]	eta 0:05:31 lr 0.000200	time 0.2563 (0.2573)	loss 0.3393 (0.3583)	grad_norm 446399.0312 (inf)	mem 14543MB
[2023-10-13 02:18:11 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2507 (0.2573)	loss 0.3549 (0.3582)	grad_norm 570175.2500 (inf)	mem 14543MB
[2023-10-13 02:20:20 simmim_pretrain](main_simmim.py 218): INFO Train: [149/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2587 (0.2574)	loss 0.3556 (0.3580)	grad_norm 495990.3125 (inf)	mem 14543MB
[2023-10-13 02:21:35 simmim_pretrain](main_simmim.py 228): INFO EPOCH 149 training takes 0:29:07
[2023-10-13 02:21:36 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][0/6787]	eta 2:42:07 lr 0.000200	time 1.4332 (1.4332)	loss 0.3699 (0.3699)	grad_norm 353860.7500 (353860.7500)	mem 14543MB
[2023-10-13 02:23:45 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][500/6787]	eta 0:27:14 lr 0.000200	time 0.2555 (0.2599)	loss 0.3398 (0.3568)	grad_norm 455074.1562 (inf)	mem 14543MB
[2023-10-13 02:25:53 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][1000/6787]	eta 0:24:56 lr 0.000200	time 0.2596 (0.2585)	loss 0.3575 (0.3577)	grad_norm 196789.5312 (inf)	mem 14543MB
[2023-10-13 02:28:02 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][1500/6787]	eta 0:22:43 lr 0.000200	time 0.2540 (0.2579)	loss 0.3870 (0.3583)	grad_norm 336320.4688 (inf)	mem 14543MB
[2023-10-13 02:30:10 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][2000/6787]	eta 0:20:33 lr 0.000200	time 0.2529 (0.2576)	loss 0.3658 (0.3583)	grad_norm 150733.2344 (inf)	mem 14543MB
[2023-10-13 02:32:19 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][2500/6787]	eta 0:18:24 lr 0.000200	time 0.2597 (0.2576)	loss 0.3405 (0.3584)	grad_norm 273879.8125 (inf)	mem 14543MB
[2023-10-13 02:34:28 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][3000/6787]	eta 0:16:15 lr 0.000200	time 0.2562 (0.2576)	loss 0.3691 (0.3583)	grad_norm 507146.6562 (inf)	mem 14543MB
[2023-10-13 02:36:37 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][3500/6787]	eta 0:14:06 lr 0.000200	time 0.2575 (0.2576)	loss 0.3571 (0.3583)	grad_norm 379908.3750 (inf)	mem 14543MB
[2023-10-13 02:38:45 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][4000/6787]	eta 0:11:57 lr 0.000200	time 0.2546 (0.2575)	loss 0.3515 (0.3582)	grad_norm 299977.9688 (inf)	mem 14543MB
[2023-10-13 02:40:54 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][4500/6787]	eta 0:09:49 lr 0.000200	time 0.2569 (0.2576)	loss 0.3840 (0.3583)	grad_norm 225012.5156 (inf)	mem 14543MB
[2023-10-13 02:43:03 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][5000/6787]	eta 0:07:40 lr 0.000200	time 0.2543 (0.2575)	loss 0.3767 (0.3583)	grad_norm 239171.5312 (inf)	mem 14543MB
[2023-10-13 02:45:11 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][5500/6787]	eta 0:05:31 lr 0.000200	time 0.2592 (0.2575)	loss 0.5483 (0.3655)	grad_norm 1782.6455 (inf)	mem 14543MB
[2023-10-13 02:47:20 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2516 (0.2575)	loss 0.5035 (0.3772)	grad_norm 20636.1270 (inf)	mem 14543MB
[2023-10-13 02:49:28 simmim_pretrain](main_simmim.py 218): INFO Train: [150/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2605 (0.2574)	loss 0.4623 (0.3849)	grad_norm 25645.9219 (inf)	mem 14543MB
[2023-10-13 02:50:42 simmim_pretrain](main_simmim.py 228): INFO EPOCH 150 training takes 0:29:07
[2023-10-13 02:50:44 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][0/6787]	eta 2:38:48 lr 0.000200	time 1.4040 (1.4040)	loss 0.4102 (0.4102)	grad_norm 13462.2559 (13462.2559)	mem 14543MB
[2023-10-13 02:52:53 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][500/6787]	eta 0:27:15 lr 0.000200	time 0.2570 (0.2601)	loss 0.3867 (0.4030)	grad_norm 17193.7891 (15487.4199)	mem 14543MB
[2023-10-13 02:55:01 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][1000/6787]	eta 0:24:55 lr 0.000200	time 0.2575 (0.2584)	loss 0.3982 (0.3895)	grad_norm 20401.3320 (18724.9551)	mem 14543MB
[2023-10-13 02:57:09 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][1500/6787]	eta 0:22:43 lr 0.000200	time 0.2523 (0.2578)	loss 0.3558 (0.3831)	grad_norm 21270.8145 (20845.8789)	mem 14543MB
[2023-10-13 02:59:17 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][2000/6787]	eta 0:20:32 lr 0.000200	time 0.2557 (0.2574)	loss 0.3790 (0.3791)	grad_norm 23940.1211 (21782.5605)	mem 14543MB
[2023-10-13 03:01:26 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][2500/6787]	eta 0:18:23 lr 0.000200	time 0.2536 (0.2574)	loss 0.3604 (0.3767)	grad_norm 81420.7109 (22379.1445)	mem 14543MB
[2023-10-13 03:03:34 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][3000/6787]	eta 0:16:14 lr 0.000200	time 0.2546 (0.2573)	loss 0.3600 (0.3747)	grad_norm 77059.1797 (24392.2520)	mem 14543MB
[2023-10-13 03:05:43 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][3500/6787]	eta 0:14:05 lr 0.000200	time 0.2585 (0.2573)	loss 0.3695 (0.3729)	grad_norm 44571.5820 (27122.8027)	mem 14543MB
[2023-10-13 03:07:52 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][4000/6787]	eta 0:11:57 lr 0.000200	time 0.2573 (0.2574)	loss 0.3584 (0.3716)	grad_norm 38739.6602 (28973.2324)	mem 14543MB
[2023-10-13 03:10:00 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][4500/6787]	eta 0:09:48 lr 0.000200	time 0.2578 (0.2573)	loss 0.3468 (0.3705)	grad_norm 62294.9141 (30826.6465)	mem 14543MB
[2023-10-13 03:12:09 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][5000/6787]	eta 0:07:39 lr 0.000200	time 0.2581 (0.2573)	loss 0.3878 (0.3695)	grad_norm 57446.9414 (34103.2031)	mem 14543MB
[2023-10-13 03:14:17 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][5500/6787]	eta 0:05:31 lr 0.000200	time 0.2605 (0.2572)	loss 0.3756 (0.3688)	grad_norm 106045.9844 (37038.3789)	mem 14543MB
[2023-10-13 03:16:25 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2614 (0.2571)	loss 0.3640 (0.3680)	grad_norm 109342.7734 (40335.4336)	mem 14543MB
[2023-10-13 03:18:35 simmim_pretrain](main_simmim.py 218): INFO Train: [151/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2597 (0.2573)	loss 0.3543 (0.3674)	grad_norm 205913.9531 (43840.9336)	mem 14543MB
[2023-10-13 03:19:50 simmim_pretrain](main_simmim.py 228): INFO EPOCH 151 training takes 0:29:07
[2023-10-13 03:19:52 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][0/6787]	eta 2:46:33 lr 0.000200	time 1.4724 (1.4724)	loss 0.3513 (0.3513)	grad_norm 111140.8203 (111140.8203)	mem 14543MB
[2023-10-13 03:21:58 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][500/6787]	eta 0:26:38 lr 0.000200	time 0.2522 (0.2542)	loss 0.3485 (0.3579)	grad_norm 129025.0234 (118477.9375)	mem 14543MB
[2023-10-13 03:24:04 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][1000/6787]	eta 0:24:26 lr 0.000200	time 0.2592 (0.2534)	loss 0.3452 (0.3585)	grad_norm 194501.3438 (126527.5391)	mem 14543MB
[2023-10-13 03:26:10 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][1500/6787]	eta 0:22:17 lr 0.000200	time 0.2587 (0.2529)	loss 0.3579 (0.3590)	grad_norm 118416.9219 (135834.5625)	mem 14543MB
[2023-10-13 03:28:16 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][2000/6787]	eta 0:20:10 lr 0.000200	time 0.2530 (0.2528)	loss 0.3569 (0.3588)	grad_norm 369486.2500 (149380.3906)	mem 14543MB
[2023-10-13 03:30:23 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][2500/6787]	eta 0:18:03 lr 0.000200	time 0.2524 (0.2528)	loss 0.3456 (0.3586)	grad_norm 197205.8125 (164560.0000)	mem 14543MB
[2023-10-13 03:32:30 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][3000/6787]	eta 0:15:58 lr 0.000200	time 0.2481 (0.2531)	loss 0.3715 (0.3584)	grad_norm 286720.9688 (201639.7812)	mem 14543MB
[2023-10-13 03:34:37 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][3500/6787]	eta 0:13:52 lr 0.000200	time 0.2549 (0.2533)	loss 0.3885 (0.3583)	grad_norm 218390.5781 (inf)	mem 14543MB
[2023-10-13 03:36:45 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][4000/6787]	eta 0:11:46 lr 0.000200	time 0.2547 (0.2536)	loss 0.3567 (0.3584)	grad_norm 144553.0000 (inf)	mem 14543MB
[2023-10-13 03:38:53 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][4500/6787]	eta 0:09:40 lr 0.000200	time 0.2543 (0.2538)	loss 0.3598 (0.3584)	grad_norm 217747.8594 (inf)	mem 14543MB
[2023-10-13 03:41:01 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][5000/6787]	eta 0:07:34 lr 0.000200	time 0.2557 (0.2541)	loss 0.3733 (0.3582)	grad_norm 178488.0469 (inf)	mem 14543MB
[2023-10-13 03:43:09 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][5500/6787]	eta 0:05:27 lr 0.000200	time 0.2609 (0.2543)	loss 0.3376 (0.3584)	grad_norm 152598.9375 (inf)	mem 14543MB
[2023-10-13 03:45:18 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][6000/6787]	eta 0:03:20 lr 0.000200	time 0.2548 (0.2547)	loss 0.3764 (0.3586)	grad_norm 88212.9766 (inf)	mem 14543MB
[2023-10-13 03:47:27 simmim_pretrain](main_simmim.py 218): INFO Train: [152/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2516 (0.2548)	loss 0.3510 (0.3587)	grad_norm 114580.9141 (inf)	mem 14543MB
[2023-10-13 03:48:40 simmim_pretrain](main_simmim.py 228): INFO EPOCH 152 training takes 0:28:50
[2023-10-13 03:48:42 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][0/6787]	eta 2:53:06 lr 0.000200	time 1.5303 (1.5303)	loss 0.3431 (0.3431)	grad_norm 88908.8828 (88908.8828)	mem 14543MB
[2023-10-13 03:50:50 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][500/6787]	eta 0:26:59 lr 0.000200	time 0.2538 (0.2575)	loss 0.3524 (0.3590)	grad_norm 71872.1328 (104846.9062)	mem 14543MB
[2023-10-13 03:52:58 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][1000/6787]	eta 0:24:51 lr 0.000200	time 0.2616 (0.2577)	loss 0.3828 (0.3587)	grad_norm 171802.3281 (116874.8906)	mem 14543MB
[2023-10-13 03:55:09 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][1500/6787]	eta 0:22:46 lr 0.000200	time 0.2613 (0.2585)	loss 0.3540 (0.3584)	grad_norm 376390.4062 (128587.7812)	mem 14543MB
[2023-10-13 03:57:19 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][2000/6787]	eta 0:20:40 lr 0.000200	time 0.2547 (0.2590)	loss 0.3691 (0.3585)	grad_norm 193374.7656 (147317.0312)	mem 14543MB
[2023-10-13 03:59:27 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][2500/6787]	eta 0:18:28 lr 0.000200	time 0.2567 (0.2586)	loss 0.3634 (0.3583)	grad_norm 145557.3906 (154220.4531)	mem 14543MB
[2023-10-13 04:01:35 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][3000/6787]	eta 0:16:17 lr 0.000200	time 0.2565 (0.2582)	loss 0.3662 (0.3579)	grad_norm 259877.6094 (176576.6875)	mem 14543MB
[2023-10-13 04:03:45 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][3500/6787]	eta 0:14:08 lr 0.000200	time 0.2606 (0.2582)	loss 0.3922 (0.3578)	grad_norm 456254.2500 (187944.7031)	mem 14543MB
[2023-10-13 04:05:53 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][4000/6787]	eta 0:11:59 lr 0.000200	time 0.2536 (0.2581)	loss 0.3480 (0.3576)	grad_norm 393385.7500 (200468.7344)	mem 14543MB
[2023-10-13 04:08:01 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][4500/6787]	eta 0:09:49 lr 0.000200	time 0.2591 (0.2577)	loss 0.3633 (0.3575)	grad_norm 300445.6875 (218728.2188)	mem 14543MB
[2023-10-13 04:10:09 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][5000/6787]	eta 0:07:40 lr 0.000200	time 0.2532 (0.2576)	loss 0.3641 (0.3574)	grad_norm 391887.3750 (243255.8750)	mem 14543MB
[2023-10-13 04:12:17 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][5500/6787]	eta 0:05:31 lr 0.000200	time 0.2528 (0.2574)	loss 0.3732 (0.3573)	grad_norm 394974.6250 (inf)	mem 14543MB
[2023-10-13 04:14:24 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2462 (0.2572)	loss 0.3477 (0.3572)	grad_norm 362436.6562 (inf)	mem 14543MB
[2023-10-13 04:16:31 simmim_pretrain](main_simmim.py 218): INFO Train: [153/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2526 (0.2570)	loss 0.3289 (0.3572)	grad_norm 457967.6875 (inf)	mem 14543MB
[2023-10-13 04:17:45 simmim_pretrain](main_simmim.py 228): INFO EPOCH 153 training takes 0:29:04
[2023-10-13 04:17:47 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][0/6787]	eta 2:49:52 lr 0.000200	time 1.5018 (1.5018)	loss 0.3556 (0.3556)	grad_norm 351122.5000 (351122.5000)	mem 14543MB
[2023-10-13 04:19:53 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][500/6787]	eta 0:26:46 lr 0.000200	time 0.2496 (0.2556)	loss 0.3384 (0.3568)	grad_norm 426157.5312 (365153.0938)	mem 14543MB
[2023-10-13 04:22:00 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][1000/6787]	eta 0:24:32 lr 0.000200	time 0.2513 (0.2545)	loss 0.3527 (0.3566)	grad_norm 462092.5312 (inf)	mem 14543MB
[2023-10-13 04:24:07 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][1500/6787]	eta 0:22:24 lr 0.000200	time 0.2565 (0.2543)	loss 0.3599 (0.3566)	grad_norm 362926.0625 (inf)	mem 14543MB
[2023-10-13 04:26:13 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][2000/6787]	eta 0:20:15 lr 0.000200	time 0.2546 (0.2540)	loss 0.3437 (0.3565)	grad_norm 385189.7500 (inf)	mem 14543MB
[2023-10-13 04:28:20 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][2500/6787]	eta 0:18:08 lr 0.000200	time 0.2525 (0.2539)	loss 0.3511 (0.3565)	grad_norm 380030.4375 (inf)	mem 14543MB
[2023-10-13 04:30:27 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][3000/6787]	eta 0:16:01 lr 0.000200	time 0.2529 (0.2538)	loss 0.3349 (0.3565)	grad_norm 497230.6562 (inf)	mem 14543MB
[2023-10-13 04:32:34 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][3500/6787]	eta 0:13:54 lr 0.000200	time 0.2541 (0.2538)	loss 0.3668 (0.3564)	grad_norm 478590.4688 (inf)	mem 14543MB
[2023-10-13 04:34:40 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][4000/6787]	eta 0:11:47 lr 0.000200	time 0.2537 (0.2537)	loss 0.3513 (0.3563)	grad_norm 353974.0000 (inf)	mem 14543MB
[2023-10-13 04:36:47 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][4500/6787]	eta 0:09:40 lr 0.000200	time 0.2524 (0.2538)	loss 0.3305 (0.3562)	grad_norm 280012.6250 (inf)	mem 14543MB
[2023-10-13 04:38:54 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][5000/6787]	eta 0:07:33 lr 0.000200	time 0.2522 (0.2538)	loss 0.3422 (0.3562)	grad_norm 510298.7812 (inf)	mem 14543MB
[2023-10-13 04:41:01 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2537 (0.2538)	loss 0.3462 (0.3562)	grad_norm 221191.6406 (inf)	mem 14543MB
[2023-10-13 04:43:07 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2525 (0.2536)	loss 0.3580 (0.3563)	grad_norm 277066.1562 (inf)	mem 14543MB
[2023-10-13 04:45:13 simmim_pretrain](main_simmim.py 218): INFO Train: [154/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2513 (0.2535)	loss 0.3458 (0.3563)	grad_norm 185827.8125 (inf)	mem 14543MB
[2023-10-13 04:46:26 simmim_pretrain](main_simmim.py 228): INFO EPOCH 154 training takes 0:28:40
[2023-10-13 04:46:27 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][0/6787]	eta 2:58:16 lr 0.000200	time 1.5760 (1.5760)	loss 0.3474 (0.3474)	grad_norm 361899.0000 (361899.0000)	mem 14543MB
[2023-10-13 04:48:33 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][500/6787]	eta 0:26:33 lr 0.000200	time 0.2528 (0.2535)	loss 0.3478 (0.3581)	grad_norm 240292.4531 (inf)	mem 14543MB
[2023-10-13 04:50:38 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][1000/6787]	eta 0:24:19 lr 0.000200	time 0.2524 (0.2522)	loss 0.3553 (0.3577)	grad_norm 197346.3281 (inf)	mem 14543MB
[2023-10-13 04:52:44 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][1500/6787]	eta 0:22:13 lr 0.000200	time 0.2583 (0.2522)	loss 0.3633 (0.3579)	grad_norm 257376.0469 (inf)	mem 14543MB
[2023-10-13 04:54:51 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][2000/6787]	eta 0:20:09 lr 0.000200	time 0.2579 (0.2526)	loss 0.3523 (0.3580)	grad_norm 124071.3906 (inf)	mem 14543MB
[2023-10-13 04:56:59 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][2500/6787]	eta 0:18:05 lr 0.000200	time 0.2612 (0.2532)	loss 0.3725 (0.3578)	grad_norm 335331.0938 (inf)	mem 14543MB
[2023-10-13 04:59:08 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][3000/6787]	eta 0:16:01 lr 0.000200	time 0.2609 (0.2539)	loss 0.3728 (0.3579)	grad_norm 255552.9844 (inf)	mem 14543MB
[2023-10-13 05:01:16 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][3500/6787]	eta 0:13:56 lr 0.000200	time 0.2471 (0.2544)	loss 0.3641 (0.3577)	grad_norm 201499.5625 (inf)	mem 14543MB
[2023-10-13 05:03:25 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][4000/6787]	eta 0:11:49 lr 0.000200	time 0.2567 (0.2547)	loss 0.3288 (0.3577)	grad_norm 186453.6406 (inf)	mem 14543MB
[2023-10-13 05:05:33 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][4500/6787]	eta 0:09:42 lr 0.000200	time 0.2533 (0.2549)	loss 0.3303 (0.3576)	grad_norm 213723.7969 (inf)	mem 14543MB
[2023-10-13 05:07:42 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][5000/6787]	eta 0:07:36 lr 0.000200	time 0.2602 (0.2553)	loss 0.3532 (0.3577)	grad_norm 192604.1875 (inf)	mem 14543MB
[2023-10-13 05:09:52 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][5500/6787]	eta 0:05:29 lr 0.000200	time 0.2603 (0.2557)	loss 0.3498 (0.3576)	grad_norm 272069.6562 (inf)	mem 14543MB
[2023-10-13 05:12:01 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2572 (0.2558)	loss 0.3418 (0.3576)	grad_norm 310849.5000 (inf)	mem 14543MB
[2023-10-13 05:14:10 simmim_pretrain](main_simmim.py 218): INFO Train: [155/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2596 (0.2560)	loss 0.3525 (0.3577)	grad_norm 389106.2188 (inf)	mem 14543MB
[2023-10-13 05:15:24 simmim_pretrain](main_simmim.py 228): INFO EPOCH 155 training takes 0:28:58
[2023-10-13 05:15:25 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][0/6787]	eta 2:44:36 lr 0.000200	time 1.4553 (1.4553)	loss 0.3663 (0.3663)	grad_norm 371849.5000 (371849.5000)	mem 14543MB
[2023-10-13 05:17:34 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][500/6787]	eta 0:27:13 lr 0.000200	time 0.2593 (0.2598)	loss 0.3414 (0.3566)	grad_norm 493985.0938 (377549.1875)	mem 14543MB
[2023-10-13 05:19:44 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][1000/6787]	eta 0:25:05 lr 0.000200	time 0.2611 (0.2601)	loss 0.3656 (0.3564)	grad_norm 274734.3750 (inf)	mem 14543MB
[2023-10-13 05:21:54 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][1500/6787]	eta 0:22:55 lr 0.000200	time 0.2573 (0.2602)	loss 0.3597 (0.3565)	grad_norm 360929.5938 (inf)	mem 14543MB
[2023-10-13 05:24:04 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][2000/6787]	eta 0:20:45 lr 0.000200	time 0.2590 (0.2602)	loss 0.3390 (0.3563)	grad_norm 528151.4375 (inf)	mem 14543MB
[2023-10-13 05:26:15 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][2500/6787]	eta 0:18:35 lr 0.000200	time 0.2596 (0.2603)	loss 0.3266 (0.3563)	grad_norm 295734.4688 (inf)	mem 14543MB
[2023-10-13 05:28:25 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][3000/6787]	eta 0:16:25 lr 0.000200	time 0.2611 (0.2604)	loss 0.3476 (0.3562)	grad_norm 489478.5625 (inf)	mem 14543MB
[2023-10-13 05:30:36 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][3500/6787]	eta 0:14:15 lr 0.000200	time 0.2611 (0.2604)	loss 0.3662 (0.3563)	grad_norm 518558.8750 (inf)	mem 14543MB
[2023-10-13 05:32:46 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][4000/6787]	eta 0:12:05 lr 0.000200	time 0.2607 (0.2604)	loss 0.3533 (0.3565)	grad_norm 171952.5000 (inf)	mem 14543MB
[2023-10-13 05:34:56 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][4500/6787]	eta 0:09:55 lr 0.000200	time 0.2608 (0.2605)	loss 0.3420 (0.3567)	grad_norm 240473.8281 (inf)	mem 14543MB
[2023-10-13 05:37:07 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][5000/6787]	eta 0:07:45 lr 0.000200	time 0.2606 (0.2605)	loss 0.3475 (0.3570)	grad_norm 279045.9375 (inf)	mem 14543MB
[2023-10-13 05:39:17 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][5500/6787]	eta 0:05:35 lr 0.000200	time 0.2611 (0.2605)	loss 0.3566 (0.3572)	grad_norm 171222.9531 (inf)	mem 14543MB
[2023-10-13 05:41:27 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][6000/6787]	eta 0:03:25 lr 0.000200	time 0.2607 (0.2605)	loss 0.3543 (0.3571)	grad_norm 490550.9062 (inf)	mem 14543MB
[2023-10-13 05:43:38 simmim_pretrain](main_simmim.py 218): INFO Train: [156/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2611 (0.2605)	loss 0.3655 (0.3571)	grad_norm 328912.0625 (inf)	mem 14543MB
[2023-10-13 05:44:53 simmim_pretrain](main_simmim.py 228): INFO EPOCH 156 training takes 0:29:29
[2023-10-13 05:44:54 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][0/6787]	eta 2:42:18 lr 0.000200	time 1.4348 (1.4348)	loss 0.3433 (0.3433)	grad_norm 537741.4375 (537741.4375)	mem 14543MB
[2023-10-13 05:47:02 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][500/6787]	eta 0:26:59 lr 0.000200	time 0.2589 (0.2576)	loss 0.3615 (0.3575)	grad_norm 281209.5312 (inf)	mem 14543MB
[2023-10-13 05:49:10 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][1000/6787]	eta 0:24:47 lr 0.000200	time 0.2545 (0.2571)	loss 0.3620 (0.3593)	grad_norm 114405.8750 (inf)	mem 14543MB
[2023-10-13 05:51:20 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][1500/6787]	eta 0:22:44 lr 0.000200	time 0.2612 (0.2580)	loss 0.3707 (0.3593)	grad_norm 122775.2891 (inf)	mem 14543MB
[2023-10-13 05:53:30 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][2000/6787]	eta 0:20:37 lr 0.000200	time 0.2613 (0.2586)	loss 0.3496 (0.3594)	grad_norm 175143.0469 (inf)	mem 14543MB
[2023-10-13 05:55:40 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][2500/6787]	eta 0:18:30 lr 0.000200	time 0.2610 (0.2589)	loss 0.3827 (0.3598)	grad_norm 243360.6562 (inf)	mem 14543MB
[2023-10-13 05:57:50 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][3000/6787]	eta 0:16:21 lr 0.000200	time 0.2608 (0.2591)	loss 0.3679 (0.3598)	grad_norm 299998.3750 (inf)	mem 14543MB
[2023-10-13 06:00:00 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][3500/6787]	eta 0:14:12 lr 0.000200	time 0.2605 (0.2592)	loss 0.3591 (0.3596)	grad_norm 209698.4531 (inf)	mem 14543MB
[2023-10-13 06:02:10 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][4000/6787]	eta 0:12:02 lr 0.000200	time 0.2605 (0.2593)	loss 0.3815 (0.3595)	grad_norm 160190.5156 (inf)	mem 14543MB
[2023-10-13 06:04:20 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][4500/6787]	eta 0:09:53 lr 0.000200	time 0.2566 (0.2593)	loss 0.3420 (0.3594)	grad_norm 474693.3438 (inf)	mem 14543MB
[2023-10-13 06:06:30 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][5000/6787]	eta 0:07:43 lr 0.000200	time 0.2596 (0.2593)	loss 0.3503 (0.3592)	grad_norm 365059.6250 (inf)	mem 14543MB
[2023-10-13 06:08:38 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][5500/6787]	eta 0:05:33 lr 0.000200	time 0.2577 (0.2591)	loss 0.3428 (0.3589)	grad_norm 563106.5000 (inf)	mem 14543MB
[2023-10-13 06:10:46 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][6000/6787]	eta 0:03:23 lr 0.000200	time 0.2567 (0.2589)	loss 0.3734 (0.3587)	grad_norm 256868.7812 (inf)	mem 14543MB
[2023-10-13 06:12:54 simmim_pretrain](main_simmim.py 218): INFO Train: [157/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2545 (0.2586)	loss 0.3443 (0.3586)	grad_norm 296856.0938 (inf)	mem 14543MB
[2023-10-13 06:14:08 simmim_pretrain](main_simmim.py 228): INFO EPOCH 157 training takes 0:29:14
[2023-10-13 06:14:09 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][0/6787]	eta 2:45:09 lr 0.000200	time 1.4601 (1.4601)	loss 0.3510 (0.3510)	grad_norm 258717.1719 (258717.1719)	mem 14543MB
[2023-10-13 06:16:14 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][500/6787]	eta 0:26:22 lr 0.000200	time 0.2462 (0.2517)	loss 0.3545 (0.3582)	grad_norm 230107.0312 (233489.0312)	mem 14543MB
[2023-10-13 06:18:19 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][1000/6787]	eta 0:24:10 lr 0.000200	time 0.2463 (0.2507)	loss 0.3629 (0.3583)	grad_norm 276626.1250 (231824.6406)	mem 14543MB
[2023-10-13 06:20:24 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][1500/6787]	eta 0:22:04 lr 0.000200	time 0.2483 (0.2505)	loss 0.3516 (0.3582)	grad_norm 495431.4688 (238631.6094)	mem 14543MB
[2023-10-13 06:22:29 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][2000/6787]	eta 0:19:57 lr 0.000200	time 0.2530 (0.2503)	loss 0.3694 (0.3580)	grad_norm 418535.8125 (263063.8125)	mem 14543MB
[2023-10-13 06:24:33 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][2500/6787]	eta 0:17:52 lr 0.000200	time 0.2491 (0.2502)	loss 0.3729 (0.3578)	grad_norm 301516.2812 (inf)	mem 14543MB
[2023-10-13 06:26:38 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][3000/6787]	eta 0:15:47 lr 0.000200	time 0.2482 (0.2501)	loss 0.3497 (0.3578)	grad_norm 221309.6719 (inf)	mem 14543MB
[2023-10-13 06:28:43 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][3500/6787]	eta 0:13:41 lr 0.000200	time 0.2473 (0.2500)	loss 0.3421 (0.3578)	grad_norm 144594.2500 (inf)	mem 14543MB
[2023-10-13 06:30:48 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2587 (0.2499)	loss 0.3508 (0.3579)	grad_norm 203066.7812 (inf)	mem 14543MB
[2023-10-13 06:32:52 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][4500/6787]	eta 0:09:31 lr 0.000200	time 0.2479 (0.2499)	loss 0.3603 (0.3580)	grad_norm 316892.8750 (inf)	mem 14543MB
[2023-10-13 06:34:58 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][5000/6787]	eta 0:07:26 lr 0.000200	time 0.2515 (0.2500)	loss 0.3322 (0.3578)	grad_norm 346415.8750 (inf)	mem 14543MB
[2023-10-13 06:37:04 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2562 (0.2502)	loss 0.3629 (0.3578)	grad_norm 288676.2812 (inf)	mem 14543MB
[2023-10-13 06:39:10 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2476 (0.2504)	loss 0.3564 (0.3578)	grad_norm 501229.6562 (inf)	mem 14543MB
[2023-10-13 06:41:14 simmim_pretrain](main_simmim.py 218): INFO Train: [158/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2494 (0.2502)	loss 0.3415 (0.3576)	grad_norm 917671.5000 (inf)	mem 14543MB
[2023-10-13 06:42:25 simmim_pretrain](main_simmim.py 228): INFO EPOCH 158 training takes 0:28:17
[2023-10-13 06:42:27 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][0/6787]	eta 2:37:10 lr 0.000200	time 1.3895 (1.3895)	loss 0.3457 (0.3457)	grad_norm 353975.7188 (353975.7188)	mem 14543MB
[2023-10-13 06:44:30 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][500/6787]	eta 0:25:59 lr 0.000200	time 0.2452 (0.2480)	loss 0.3496 (0.3549)	grad_norm 606030.5625 (inf)	mem 14543MB
[2023-10-13 06:46:32 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][1000/6787]	eta 0:23:47 lr 0.000200	time 0.2444 (0.2466)	loss 0.3409 (0.3557)	grad_norm 476927.6250 (inf)	mem 14543MB
[2023-10-13 06:48:34 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][1500/6787]	eta 0:21:39 lr 0.000200	time 0.2444 (0.2458)	loss 0.3594 (0.3563)	grad_norm 431038.6250 (inf)	mem 14543MB
[2023-10-13 06:50:36 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][2000/6787]	eta 0:19:34 lr 0.000200	time 0.2436 (0.2453)	loss 0.3656 (0.3560)	grad_norm 372077.4062 (inf)	mem 14543MB
[2023-10-13 06:52:38 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][2500/6787]	eta 0:17:30 lr 0.000200	time 0.2433 (0.2450)	loss 0.3620 (0.3561)	grad_norm 426754.4062 (inf)	mem 14543MB
[2023-10-13 06:54:40 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][3000/6787]	eta 0:15:27 lr 0.000200	time 0.2439 (0.2448)	loss 0.3565 (0.3563)	grad_norm 265930.3438 (inf)	mem 14543MB
[2023-10-13 06:56:42 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][3500/6787]	eta 0:13:24 lr 0.000200	time 0.2435 (0.2447)	loss 0.3607 (0.3571)	grad_norm 153865.7969 (inf)	mem 14543MB
[2023-10-13 06:58:44 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][4000/6787]	eta 0:11:21 lr 0.000200	time 0.2438 (0.2445)	loss 0.3483 (0.3578)	grad_norm 129962.8906 (inf)	mem 14543MB
[2023-10-13 07:00:46 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][4500/6787]	eta 0:09:19 lr 0.000200	time 0.2437 (0.2444)	loss 0.3758 (0.3581)	grad_norm 124392.2969 (inf)	mem 14543MB
[2023-10-13 07:02:48 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][5000/6787]	eta 0:07:16 lr 0.000200	time 0.2437 (0.2444)	loss 0.3437 (0.3584)	grad_norm 189971.3438 (inf)	mem 14543MB
[2023-10-13 07:04:49 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][5500/6787]	eta 0:05:14 lr 0.000200	time 0.2437 (0.2443)	loss 0.3691 (0.3585)	grad_norm 146737.9531 (inf)	mem 14543MB
[2023-10-13 07:06:51 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][6000/6787]	eta 0:03:12 lr 0.000200	time 0.2437 (0.2443)	loss 0.3781 (0.3585)	grad_norm 172779.5312 (inf)	mem 14543MB
[2023-10-13 07:08:53 simmim_pretrain](main_simmim.py 218): INFO Train: [159/200][6500/6787]	eta 0:01:10 lr 0.000200	time 0.2436 (0.2442)	loss 0.3606 (0.3585)	grad_norm 181695.5312 (inf)	mem 14543MB
[2023-10-13 07:10:04 simmim_pretrain](main_simmim.py 228): INFO EPOCH 159 training takes 0:27:38
[2023-10-13 07:10:05 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][0/6787]	eta 2:19:12 lr 0.000200	time 1.2306 (1.2306)	loss 0.3481 (0.3481)	grad_norm 102236.2812 (102236.2812)	mem 14543MB
[2023-10-13 07:12:07 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][500/6787]	eta 0:25:45 lr 0.000200	time 0.2439 (0.2458)	loss 0.3740 (0.3583)	grad_norm 174118.9844 (227118.1719)	mem 14543MB
[2023-10-13 07:14:09 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][1000/6787]	eta 0:23:36 lr 0.000200	time 0.2440 (0.2448)	loss 0.3265 (0.3574)	grad_norm 275769.4688 (253380.7500)	mem 14543MB
[2023-10-13 07:16:11 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][1500/6787]	eta 0:21:33 lr 0.000200	time 0.2441 (0.2446)	loss 0.3455 (0.3571)	grad_norm 333898.8125 (283318.9375)	mem 14543MB
[2023-10-13 07:18:13 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][2000/6787]	eta 0:19:30 lr 0.000200	time 0.2441 (0.2445)	loss 0.3657 (0.3569)	grad_norm 216874.9844 (inf)	mem 14543MB
[2023-10-13 07:20:15 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][2500/6787]	eta 0:17:27 lr 0.000200	time 0.2441 (0.2444)	loss 0.3663 (0.3571)	grad_norm 266075.2188 (inf)	mem 14543MB
[2023-10-13 07:22:17 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][3000/6787]	eta 0:15:25 lr 0.000200	time 0.2437 (0.2444)	loss 0.3544 (0.3571)	grad_norm 323675.9062 (inf)	mem 14543MB
[2023-10-13 07:24:19 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][3500/6787]	eta 0:13:23 lr 0.000200	time 0.2443 (0.2444)	loss 0.3519 (0.3573)	grad_norm 205161.0938 (inf)	mem 14543MB
[2023-10-13 07:26:21 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][4000/6787]	eta 0:11:20 lr 0.000200	time 0.2437 (0.2443)	loss 0.3420 (0.3573)	grad_norm 301832.3750 (inf)	mem 14543MB
[2023-10-13 07:28:23 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][4500/6787]	eta 0:09:18 lr 0.000200	time 0.2436 (0.2443)	loss 0.3832 (0.3572)	grad_norm 166255.3906 (inf)	mem 14543MB
[2023-10-13 07:30:25 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][5000/6787]	eta 0:07:16 lr 0.000200	time 0.2437 (0.2442)	loss 0.3417 (0.3572)	grad_norm 303188.2188 (inf)	mem 14543MB
[2023-10-13 07:32:27 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][5500/6787]	eta 0:05:14 lr 0.000200	time 0.2436 (0.2442)	loss 0.3745 (0.3571)	grad_norm 880668.4375 (inf)	mem 14543MB
[2023-10-13 07:34:29 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][6000/6787]	eta 0:03:12 lr 0.000200	time 0.2436 (0.2441)	loss 0.3636 (0.3570)	grad_norm 612333.3750 (inf)	mem 14543MB
[2023-10-13 07:36:31 simmim_pretrain](main_simmim.py 218): INFO Train: [160/200][6500/6787]	eta 0:01:10 lr 0.000200	time 0.2433 (0.2441)	loss 0.3579 (0.3569)	grad_norm 339250.9688 (inf)	mem 14543MB
[2023-10-13 07:37:41 simmim_pretrain](main_simmim.py 228): INFO EPOCH 160 training takes 0:27:37
[2023-10-13 07:37:41 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_160.pth saving......
[2023-10-13 07:37:42 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_160.pth saved !!!
[2023-10-13 07:37:43 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][0/6787]	eta 2:36:56 lr 0.000200	time 1.3875 (1.3875)	loss 0.3617 (0.3617)	grad_norm 220175.4844 (220175.4844)	mem 14543MB
[2023-10-13 07:39:45 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][500/6787]	eta 0:25:46 lr 0.000200	time 0.2440 (0.2460)	loss 0.3413 (0.3574)	grad_norm 341399.0938 (259755.2344)	mem 14543MB
[2023-10-13 07:41:47 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][1000/6787]	eta 0:23:36 lr 0.000200	time 0.2438 (0.2449)	loss 0.3743 (0.3578)	grad_norm 247712.6250 (251756.7656)	mem 14543MB
[2023-10-13 07:43:49 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][1500/6787]	eta 0:21:33 lr 0.000200	time 0.2445 (0.2446)	loss 0.3647 (0.3580)	grad_norm 280618.3750 (250955.6250)	mem 14543MB
[2023-10-13 07:45:51 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][2000/6787]	eta 0:19:30 lr 0.000200	time 0.2439 (0.2444)	loss 0.3601 (0.3578)	grad_norm 215340.0938 (262470.1250)	mem 14543MB
[2023-10-13 07:47:53 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][2500/6787]	eta 0:17:27 lr 0.000200	time 0.2444 (0.2444)	loss 0.3719 (0.3577)	grad_norm 214835.4219 (279945.9062)	mem 14543MB
[2023-10-13 07:49:56 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][3000/6787]	eta 0:15:25 lr 0.000200	time 0.2454 (0.2445)	loss 0.3598 (0.3575)	grad_norm 385935.8438 (304813.8750)	mem 14543MB
[2023-10-13 07:51:58 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][3500/6787]	eta 0:13:24 lr 0.000200	time 0.2454 (0.2447)	loss 0.3507 (0.3574)	grad_norm 460918.9062 (330253.8438)	mem 14543MB
[2023-10-13 07:54:01 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][4000/6787]	eta 0:11:22 lr 0.000200	time 0.2471 (0.2448)	loss 0.3458 (0.3572)	grad_norm 278269.8125 (inf)	mem 14543MB
[2023-10-13 07:56:04 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][4500/6787]	eta 0:09:20 lr 0.000200	time 0.2453 (0.2449)	loss 0.3476 (0.3570)	grad_norm 557877.1250 (inf)	mem 14543MB
[2023-10-13 07:58:07 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][5000/6787]	eta 0:07:17 lr 0.000200	time 0.2454 (0.2450)	loss 0.3498 (0.3571)	grad_norm 487547.6562 (inf)	mem 14543MB
[2023-10-13 08:00:10 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][5500/6787]	eta 0:05:15 lr 0.000200	time 0.2463 (0.2451)	loss 0.3349 (0.3571)	grad_norm 355191.7812 (inf)	mem 14543MB
[2023-10-13 08:02:12 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][6000/6787]	eta 0:03:12 lr 0.000200	time 0.2481 (0.2450)	loss 0.3665 (0.3572)	grad_norm 214859.5469 (inf)	mem 14543MB
[2023-10-13 08:04:15 simmim_pretrain](main_simmim.py 218): INFO Train: [161/200][6500/6787]	eta 0:01:10 lr 0.000200	time 0.2453 (0.2450)	loss 0.3542 (0.3575)	grad_norm 327978.1875 (inf)	mem 14543MB
[2023-10-13 08:05:25 simmim_pretrain](main_simmim.py 228): INFO EPOCH 161 training takes 0:27:43
[2023-10-13 08:05:27 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][0/6787]	eta 2:28:05 lr 0.000200	time 1.3092 (1.3092)	loss 0.3798 (0.3798)	grad_norm 212816.1875 (212816.1875)	mem 14543MB
[2023-10-13 08:07:29 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][500/6787]	eta 0:25:53 lr 0.000200	time 0.2490 (0.2470)	loss 0.3524 (0.3594)	grad_norm 208015.3438 (255356.5000)	mem 14543MB
[2023-10-13 08:09:32 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][1000/6787]	eta 0:23:46 lr 0.000200	time 0.2445 (0.2464)	loss 0.3522 (0.3579)	grad_norm 313810.5000 (293862.6875)	mem 14543MB
[2023-10-13 08:11:35 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][1500/6787]	eta 0:21:41 lr 0.000200	time 0.2488 (0.2462)	loss 0.3710 (0.3575)	grad_norm 428011.2188 (323607.4062)	mem 14543MB
[2023-10-13 08:13:38 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][2000/6787]	eta 0:19:38 lr 0.000200	time 0.2456 (0.2461)	loss 0.3625 (0.3572)	grad_norm 470220.7812 (359089.8438)	mem 14543MB
[2023-10-13 08:15:41 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][2500/6787]	eta 0:17:35 lr 0.000200	time 0.2440 (0.2461)	loss 0.3270 (0.3570)	grad_norm 681758.8750 (inf)	mem 14543MB
[2023-10-13 08:17:44 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][3000/6787]	eta 0:15:31 lr 0.000200	time 0.2443 (0.2461)	loss 0.3553 (0.3568)	grad_norm 506910.2812 (inf)	mem 14543MB
[2023-10-13 08:19:47 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][3500/6787]	eta 0:13:28 lr 0.000200	time 0.2445 (0.2460)	loss 0.3528 (0.3570)	grad_norm 448595.9688 (inf)	mem 14543MB
[2023-10-13 08:21:50 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][4000/6787]	eta 0:11:25 lr 0.000200	time 0.2438 (0.2460)	loss 0.3693 (0.3578)	grad_norm 127302.8203 (inf)	mem 14543MB
[2023-10-13 08:23:52 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][4500/6787]	eta 0:09:22 lr 0.000200	time 0.2490 (0.2460)	loss 0.3700 (0.3582)	grad_norm 140054.6406 (inf)	mem 14543MB
[2023-10-13 08:25:55 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][5000/6787]	eta 0:07:19 lr 0.000200	time 0.2444 (0.2459)	loss 0.3632 (0.3584)	grad_norm 168065.4844 (inf)	mem 14543MB
[2023-10-13 08:27:58 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][5500/6787]	eta 0:05:16 lr 0.000200	time 0.2444 (0.2459)	loss 0.3488 (0.3586)	grad_norm 139496.7188 (inf)	mem 14543MB
[2023-10-13 08:30:01 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][6000/6787]	eta 0:03:13 lr 0.000200	time 0.2442 (0.2459)	loss 0.3654 (0.3587)	grad_norm 191229.7031 (inf)	mem 14543MB
[2023-10-13 08:32:04 simmim_pretrain](main_simmim.py 218): INFO Train: [162/200][6500/6787]	eta 0:01:10 lr 0.000200	time 0.2439 (0.2459)	loss 0.3501 (0.3587)	grad_norm 155272.0156 (inf)	mem 14543MB
[2023-10-13 08:33:15 simmim_pretrain](main_simmim.py 228): INFO EPOCH 162 training takes 0:27:49
[2023-10-13 08:33:16 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][0/6787]	eta 2:42:09 lr 0.000200	time 1.4336 (1.4336)	loss 0.3827 (0.3827)	grad_norm 158166.1562 (158166.1562)	mem 14543MB
[2023-10-13 08:35:19 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][500/6787]	eta 0:25:59 lr 0.000200	time 0.2452 (0.2481)	loss 0.3446 (0.3583)	grad_norm 155169.2969 (226022.0625)	mem 14543MB
[2023-10-13 08:37:22 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][1000/6787]	eta 0:23:48 lr 0.000200	time 0.2446 (0.2469)	loss 0.3435 (0.3578)	grad_norm 180997.2500 (259132.4688)	mem 14543MB
[2023-10-13 08:39:25 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][1500/6787]	eta 0:21:43 lr 0.000200	time 0.2448 (0.2465)	loss 0.3648 (0.3572)	grad_norm 387402.8750 (284876.9062)	mem 14543MB
[2023-10-13 08:41:28 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][2000/6787]	eta 0:19:39 lr 0.000200	time 0.2443 (0.2463)	loss 0.3480 (0.3572)	grad_norm 430725.9375 (307281.5625)	mem 14543MB
[2023-10-13 08:43:31 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][2500/6787]	eta 0:17:35 lr 0.000200	time 0.2443 (0.2462)	loss 0.3461 (0.3572)	grad_norm 549763.7500 (336486.4688)	mem 14543MB
[2023-10-13 08:45:34 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][3000/6787]	eta 0:15:32 lr 0.000200	time 0.2446 (0.2462)	loss 0.3377 (0.3571)	grad_norm 535634.6250 (inf)	mem 14543MB
[2023-10-13 08:47:37 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][3500/6787]	eta 0:13:28 lr 0.000200	time 0.2485 (0.2461)	loss 0.3735 (0.3571)	grad_norm 832909.3750 (inf)	mem 14543MB
[2023-10-13 08:49:39 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][4000/6787]	eta 0:11:25 lr 0.000200	time 0.2481 (0.2461)	loss 0.3497 (0.3570)	grad_norm 372282.9688 (inf)	mem 14543MB
[2023-10-13 08:51:42 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][4500/6787]	eta 0:09:22 lr 0.000200	time 0.2451 (0.2460)	loss 0.3623 (0.3573)	grad_norm 228408.2500 (inf)	mem 14543MB
[2023-10-13 08:53:45 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][5000/6787]	eta 0:07:19 lr 0.000200	time 0.2451 (0.2460)	loss 0.3526 (0.3574)	grad_norm 281228.7500 (inf)	mem 14543MB
[2023-10-13 08:55:48 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][5500/6787]	eta 0:05:16 lr 0.000200	time 0.2440 (0.2460)	loss 0.3682 (0.3575)	grad_norm 316905.0938 (inf)	mem 14543MB
[2023-10-13 08:57:51 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][6000/6787]	eta 0:03:13 lr 0.000200	time 0.2441 (0.2460)	loss 0.3656 (0.3576)	grad_norm 446959.0000 (inf)	mem 14543MB
[2023-10-13 08:59:54 simmim_pretrain](main_simmim.py 218): INFO Train: [163/200][6500/6787]	eta 0:01:10 lr 0.000200	time 0.2480 (0.2460)	loss 0.3422 (0.3575)	grad_norm 179075.6406 (inf)	mem 14543MB
[2023-10-13 09:01:05 simmim_pretrain](main_simmim.py 228): INFO EPOCH 163 training takes 0:27:50
[2023-10-13 09:01:06 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][0/6787]	eta 2:24:26 lr 0.000200	time 1.2769 (1.2769)	loss 0.3618 (0.3618)	grad_norm 168501.8438 (168501.8438)	mem 14543MB
[2023-10-13 09:03:09 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][500/6787]	eta 0:25:58 lr 0.000200	time 0.2443 (0.2478)	loss 0.3615 (0.3605)	grad_norm 85595.3984 (150176.7031)	mem 14543MB
[2023-10-13 09:05:12 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][1000/6787]	eta 0:23:48 lr 0.000200	time 0.2439 (0.2468)	loss 0.3568 (0.3603)	grad_norm 138852.4062 (146163.7188)	mem 14543MB
[2023-10-13 09:07:15 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][1500/6787]	eta 0:21:42 lr 0.000200	time 0.2446 (0.2464)	loss 0.3348 (0.3608)	grad_norm 223223.5469 (140518.1719)	mem 14543MB
[2023-10-13 09:09:18 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][2000/6787]	eta 0:19:39 lr 0.000200	time 0.2453 (0.2463)	loss 0.3638 (0.3606)	grad_norm 137159.5000 (142774.9375)	mem 14543MB
[2023-10-13 09:11:21 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][2500/6787]	eta 0:17:35 lr 0.000200	time 0.2453 (0.2462)	loss 0.3763 (0.3601)	grad_norm 219539.3906 (153732.7031)	mem 14543MB
[2023-10-13 09:13:24 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][3000/6787]	eta 0:15:32 lr 0.000200	time 0.2444 (0.2462)	loss 0.3500 (0.3596)	grad_norm 191823.7188 (162009.1094)	mem 14543MB
[2023-10-13 09:15:27 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][3500/6787]	eta 0:13:28 lr 0.000200	time 0.2457 (0.2461)	loss 0.3486 (0.3593)	grad_norm 303283.9375 (169603.4375)	mem 14543MB
[2023-10-13 09:17:30 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][4000/6787]	eta 0:11:25 lr 0.000200	time 0.2446 (0.2461)	loss 0.3649 (0.3591)	grad_norm 538078.5625 (182905.6562)	mem 14543MB
[2023-10-13 09:19:32 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][4500/6787]	eta 0:09:22 lr 0.000200	time 0.2481 (0.2460)	loss 0.3488 (0.3588)	grad_norm 158370.2344 (204587.8906)	mem 14543MB
[2023-10-13 09:21:35 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][5000/6787]	eta 0:07:19 lr 0.000200	time 0.2451 (0.2460)	loss 0.3587 (0.3586)	grad_norm 334846.9375 (220143.5938)	mem 14543MB
[2023-10-13 09:23:38 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][5500/6787]	eta 0:05:16 lr 0.000200	time 0.2449 (0.2460)	loss 0.3696 (0.3584)	grad_norm 135668.7188 (inf)	mem 14543MB
[2023-10-13 09:25:41 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][6000/6787]	eta 0:03:13 lr 0.000200	time 0.2451 (0.2460)	loss 0.3462 (0.3584)	grad_norm 250772.6406 (inf)	mem 14543MB
[2023-10-13 09:27:44 simmim_pretrain](main_simmim.py 218): INFO Train: [164/200][6500/6787]	eta 0:01:10 lr 0.000200	time 0.2454 (0.2460)	loss 0.3515 (0.3584)	grad_norm 218418.6875 (inf)	mem 14543MB
[2023-10-13 09:28:55 simmim_pretrain](main_simmim.py 228): INFO EPOCH 164 training takes 0:27:50
[2023-10-13 09:28:56 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][0/6787]	eta 2:23:51 lr 0.000200	time 1.2717 (1.2717)	loss 0.3586 (0.3586)	grad_norm 270000.0938 (270000.0938)	mem 14543MB
[2023-10-13 09:30:59 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][500/6787]	eta 0:25:57 lr 0.000200	time 0.2457 (0.2478)	loss 0.3777 (0.3568)	grad_norm 357105.6562 (259645.5938)	mem 14543MB
[2023-10-13 09:33:02 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][1000/6787]	eta 0:23:48 lr 0.000200	time 0.2455 (0.2468)	loss 0.3699 (0.3569)	grad_norm 258978.7344 (320131.6562)	mem 14543MB
[2023-10-13 09:35:05 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][1500/6787]	eta 0:21:42 lr 0.000200	time 0.2454 (0.2464)	loss 0.3689 (0.3567)	grad_norm 365289.1875 (342477.8125)	mem 14543MB
[2023-10-13 09:37:08 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][2000/6787]	eta 0:19:38 lr 0.000200	time 0.2452 (0.2463)	loss 0.3476 (0.3570)	grad_norm 371304.2500 (inf)	mem 14543MB
[2023-10-13 09:39:11 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][2500/6787]	eta 0:17:35 lr 0.000200	time 0.2460 (0.2462)	loss 0.3434 (0.3572)	grad_norm 179247.8281 (inf)	mem 14543MB
[2023-10-13 09:41:14 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][3000/6787]	eta 0:15:31 lr 0.000200	time 0.2452 (0.2461)	loss 0.3721 (0.3573)	grad_norm 224285.6562 (inf)	mem 14543MB
[2023-10-13 09:43:17 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][3500/6787]	eta 0:13:28 lr 0.000200	time 0.2452 (0.2460)	loss 0.3483 (0.3575)	grad_norm 289217.6562 (inf)	mem 14543MB
[2023-10-13 09:45:20 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][4000/6787]	eta 0:11:25 lr 0.000200	time 0.2459 (0.2460)	loss 0.3396 (0.3575)	grad_norm 422155.1562 (inf)	mem 14543MB
[2023-10-13 09:47:24 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][4500/6787]	eta 0:09:23 lr 0.000200	time 0.2495 (0.2463)	loss 0.3639 (0.3574)	grad_norm 325241.3750 (inf)	mem 14543MB
[2023-10-13 09:49:30 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][5000/6787]	eta 0:07:21 lr 0.000200	time 0.2516 (0.2469)	loss 0.3333 (0.3572)	grad_norm 321164.3750 (inf)	mem 14543MB
[2023-10-13 09:51:37 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][5500/6787]	eta 0:05:18 lr 0.000200	time 0.2465 (0.2475)	loss 0.3337 (0.3572)	grad_norm 280656.5938 (inf)	mem 14543MB
[2023-10-13 09:53:43 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][6000/6787]	eta 0:03:15 lr 0.000200	time 0.2550 (0.2480)	loss 0.3470 (0.3573)	grad_norm 328595.9375 (inf)	mem 14543MB
[2023-10-13 09:55:53 simmim_pretrain](main_simmim.py 218): INFO Train: [165/200][6500/6787]	eta 0:01:11 lr 0.000200	time 0.2611 (0.2489)	loss 0.3561 (0.3575)	grad_norm 171798.4375 (inf)	mem 14543MB
[2023-10-13 09:57:08 simmim_pretrain](main_simmim.py 228): INFO EPOCH 165 training takes 0:28:13
[2023-10-13 09:57:10 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][0/6787]	eta 2:28:02 lr 0.000200	time 1.3088 (1.3088)	loss 0.3554 (0.3554)	grad_norm 133739.7344 (133739.7344)	mem 14543MB
[2023-10-13 09:59:14 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][500/6787]	eta 0:26:13 lr 0.000200	time 0.2464 (0.2503)	loss 0.3597 (0.3599)	grad_norm 176402.4844 (139173.7656)	mem 14543MB
[2023-10-13 10:01:18 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][1000/6787]	eta 0:24:01 lr 0.000200	time 0.2460 (0.2490)	loss 0.3671 (0.3600)	grad_norm 199878.1406 (134413.2500)	mem 14543MB
[2023-10-13 10:03:21 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][1500/6787]	eta 0:21:53 lr 0.000200	time 0.2458 (0.2484)	loss 0.3691 (0.3601)	grad_norm 141788.3750 (133173.8125)	mem 14543MB
[2023-10-13 10:05:25 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][2000/6787]	eta 0:19:47 lr 0.000200	time 0.2466 (0.2481)	loss 0.3370 (0.3597)	grad_norm 186883.1562 (144039.6250)	mem 14543MB
[2023-10-13 10:07:29 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][2500/6787]	eta 0:17:44 lr 0.000200	time 0.2453 (0.2483)	loss 0.3509 (0.3595)	grad_norm 131602.8906 (154643.1094)	mem 14543MB
[2023-10-13 10:09:34 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][3000/6787]	eta 0:15:41 lr 0.000200	time 0.2504 (0.2485)	loss 0.3678 (0.3593)	grad_norm 295628.7500 (164803.7656)	mem 14543MB
[2023-10-13 10:11:40 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][3500/6787]	eta 0:13:38 lr 0.000200	time 0.2484 (0.2491)	loss 0.3935 (0.3592)	grad_norm 166350.6875 (173726.8750)	mem 14543MB
[2023-10-13 10:13:48 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][4000/6787]	eta 0:11:36 lr 0.000200	time 0.2489 (0.2498)	loss 0.3443 (0.3589)	grad_norm 337484.4375 (205526.6562)	mem 14543MB
[2023-10-13 10:15:55 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][4500/6787]	eta 0:09:32 lr 0.000200	time 0.2575 (0.2504)	loss 0.3418 (0.3587)	grad_norm 360448.0000 (219656.7344)	mem 14543MB
[2023-10-13 10:18:04 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2604 (0.2511)	loss 0.3646 (0.3583)	grad_norm 472809.2812 (233837.3125)	mem 14543MB
[2023-10-13 10:20:12 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2513 (0.2516)	loss 0.3422 (0.3582)	grad_norm 334329.8750 (250818.3594)	mem 14543MB
[2023-10-13 10:22:20 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2576 (0.2519)	loss 0.3632 (0.3580)	grad_norm 202576.9531 (inf)	mem 14543MB
[2023-10-13 10:24:28 simmim_pretrain](main_simmim.py 218): INFO Train: [166/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2601 (0.2522)	loss 0.3587 (0.3579)	grad_norm 242910.6562 (inf)	mem 14543MB
[2023-10-13 10:25:43 simmim_pretrain](main_simmim.py 228): INFO EPOCH 166 training takes 0:28:34
[2023-10-13 10:25:44 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][0/6787]	eta 2:30:36 lr 0.000200	time 1.3314 (1.3314)	loss 0.3587 (0.3587)	grad_norm 221753.3906 (221753.3906)	mem 14543MB
[2023-10-13 10:27:51 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][500/6787]	eta 0:26:45 lr 0.000200	time 0.2515 (0.2554)	loss 0.3706 (0.3585)	grad_norm 220825.6875 (270814.2500)	mem 14543MB
[2023-10-13 10:29:57 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][1000/6787]	eta 0:24:30 lr 0.000200	time 0.2466 (0.2540)	loss 0.3554 (0.3589)	grad_norm 313616.3438 (260036.7500)	mem 14543MB
[2023-10-13 10:32:03 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][1500/6787]	eta 0:22:19 lr 0.000200	time 0.2469 (0.2534)	loss 0.3893 (0.3585)	grad_norm 417989.4062 (255936.3438)	mem 14543MB
[2023-10-13 10:34:09 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][2000/6787]	eta 0:20:10 lr 0.000200	time 0.2518 (0.2528)	loss 0.3556 (0.3585)	grad_norm 197368.0156 (273454.9375)	mem 14543MB
[2023-10-13 10:36:14 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][2500/6787]	eta 0:18:02 lr 0.000200	time 0.2521 (0.2524)	loss 0.3795 (0.3580)	grad_norm 474783.0000 (298285.5312)	mem 14543MB
[2023-10-13 10:38:19 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][3000/6787]	eta 0:15:54 lr 0.000200	time 0.2466 (0.2520)	loss 0.3419 (0.3576)	grad_norm 341850.7188 (329990.2500)	mem 14543MB
[2023-10-13 10:40:24 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2449 (0.2517)	loss 0.3692 (0.3574)	grad_norm 318762.3438 (inf)	mem 14543MB
[2023-10-13 10:42:29 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2479 (0.2514)	loss 0.3701 (0.3575)	grad_norm 402413.1875 (inf)	mem 14543MB
[2023-10-13 10:44:34 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2461 (0.2512)	loss 0.3485 (0.3577)	grad_norm 216998.4688 (inf)	mem 14543MB
[2023-10-13 10:46:39 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2535 (0.2511)	loss 0.3470 (0.3578)	grad_norm 156082.0312 (inf)	mem 14543MB
[2023-10-13 10:48:44 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2458 (0.2510)	loss 0.3458 (0.3579)	grad_norm 79119.3750 (inf)	mem 14543MB
[2023-10-13 10:50:49 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2574 (0.2510)	loss 0.3592 (0.3582)	grad_norm 79177.7578 (inf)	mem 14543MB
[2023-10-13 10:52:55 simmim_pretrain](main_simmim.py 218): INFO Train: [167/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2499 (0.2510)	loss 0.3667 (0.3585)	grad_norm 122780.8281 (inf)	mem 14543MB
[2023-10-13 10:54:07 simmim_pretrain](main_simmim.py 228): INFO EPOCH 167 training takes 0:28:24
[2023-10-13 10:54:09 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][0/6787]	eta 3:00:22 lr 0.000200	time 1.5945 (1.5945)	loss 0.3890 (0.3890)	grad_norm 61192.7109 (61192.7109)	mem 14543MB
[2023-10-13 10:56:14 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][500/6787]	eta 0:26:35 lr 0.000200	time 0.2534 (0.2537)	loss 0.3589 (0.3604)	grad_norm 159491.5156 (131847.3438)	mem 14543MB
[2023-10-13 10:58:20 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][1000/6787]	eta 0:24:21 lr 0.000200	time 0.2546 (0.2526)	loss 0.3582 (0.3597)	grad_norm 208774.1562 (154517.2344)	mem 14543MB
[2023-10-13 11:00:26 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][1500/6787]	eta 0:22:14 lr 0.000200	time 0.2477 (0.2524)	loss 0.3559 (0.3592)	grad_norm 233936.6875 (168350.3438)	mem 14543MB
[2023-10-13 11:02:32 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][2000/6787]	eta 0:20:07 lr 0.000200	time 0.2464 (0.2523)	loss 0.3591 (0.3587)	grad_norm 137638.8750 (178147.2031)	mem 14543MB
[2023-10-13 11:04:38 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][2500/6787]	eta 0:18:01 lr 0.000200	time 0.2505 (0.2523)	loss 0.3473 (0.3586)	grad_norm 185826.8594 (185974.0781)	mem 14543MB
[2023-10-13 11:06:44 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][3000/6787]	eta 0:15:55 lr 0.000200	time 0.2523 (0.2523)	loss 0.3572 (0.3583)	grad_norm 357885.2188 (210770.6250)	mem 14543MB
[2023-10-13 11:08:51 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][3500/6787]	eta 0:13:49 lr 0.000200	time 0.2558 (0.2523)	loss 0.3564 (0.3580)	grad_norm 466469.1562 (232267.9844)	mem 14543MB
[2023-10-13 11:10:57 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][4000/6787]	eta 0:11:43 lr 0.000200	time 0.2459 (0.2523)	loss 0.3366 (0.3579)	grad_norm 369993.4062 (257380.0469)	mem 14543MB
[2023-10-13 11:13:03 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2585 (0.2523)	loss 0.3393 (0.3578)	grad_norm 335482.3125 (274836.0938)	mem 14543MB
[2023-10-13 11:15:08 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2506 (0.2522)	loss 0.3469 (0.3576)	grad_norm 1160416.5000 (301340.6562)	mem 14543MB
[2023-10-13 11:17:14 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2462 (0.2521)	loss 0.3541 (0.3575)	grad_norm 357477.4375 (inf)	mem 14543MB
[2023-10-13 11:19:20 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2526 (0.2520)	loss 0.3571 (0.3576)	grad_norm 140712.5938 (inf)	mem 14543MB
[2023-10-13 11:21:25 simmim_pretrain](main_simmim.py 218): INFO Train: [168/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2472 (0.2520)	loss 0.3422 (0.3576)	grad_norm 302327.0000 (inf)	mem 14543MB
[2023-10-13 11:22:38 simmim_pretrain](main_simmim.py 228): INFO EPOCH 168 training takes 0:28:30
[2023-10-13 11:22:39 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][0/6787]	eta 3:01:30 lr 0.000200	time 1.6046 (1.6046)	loss 0.3356 (0.3356)	grad_norm 222485.7188 (222485.7188)	mem 14543MB
[2023-10-13 11:24:44 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2511 (0.2530)	loss 0.3594 (0.3578)	grad_norm 366837.8750 (259586.3281)	mem 14543MB
[2023-10-13 11:26:50 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][1000/6787]	eta 0:24:16 lr 0.000200	time 0.2533 (0.2517)	loss 0.3321 (0.3574)	grad_norm 290214.8125 (299226.5000)	mem 14543MB
[2023-10-13 11:28:55 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][1500/6787]	eta 0:22:08 lr 0.000200	time 0.2488 (0.2513)	loss 0.3635 (0.3570)	grad_norm 475944.4375 (330011.9062)	mem 14543MB
[2023-10-13 11:31:00 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2598 (0.2513)	loss 0.3659 (0.3568)	grad_norm 316713.4375 (inf)	mem 14543MB
[2023-10-13 11:33:06 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][2500/6787]	eta 0:17:57 lr 0.000200	time 0.2455 (0.2513)	loss 0.3620 (0.3569)	grad_norm 311703.8125 (inf)	mem 14543MB
[2023-10-13 11:35:12 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][3000/6787]	eta 0:15:51 lr 0.000200	time 0.2528 (0.2513)	loss 0.3282 (0.3571)	grad_norm 450430.1875 (inf)	mem 14543MB
[2023-10-13 11:37:18 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2470 (0.2515)	loss 0.5572 (0.3589)	grad_norm 40141.7773 (inf)	mem 14543MB
[2023-10-13 11:39:24 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2529 (0.2516)	loss 0.3605 (0.3681)	grad_norm 55909.1328 (inf)	mem 14543MB
[2023-10-13 11:41:30 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2539 (0.2517)	loss 0.3421 (0.3682)	grad_norm 44270.9531 (inf)	mem 14543MB
[2023-10-13 11:43:37 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2483 (0.2518)	loss 0.3629 (0.3681)	grad_norm 21967.7871 (inf)	mem 14543MB
[2023-10-13 11:45:43 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2584 (0.2518)	loss 0.3656 (0.3678)	grad_norm 22016.1504 (inf)	mem 14543MB
[2023-10-13 11:47:49 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2529 (0.2518)	loss 0.3860 (0.3674)	grad_norm 51017.5742 (inf)	mem 14543MB
[2023-10-13 11:49:55 simmim_pretrain](main_simmim.py 218): INFO Train: [169/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2467 (0.2519)	loss 0.3502 (0.3669)	grad_norm 58240.2656 (inf)	mem 14543MB
[2023-10-13 11:51:08 simmim_pretrain](main_simmim.py 228): INFO EPOCH 169 training takes 0:28:30
[2023-10-13 11:51:09 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][0/6787]	eta 2:43:37 lr 0.000200	time 1.4465 (1.4465)	loss 0.3507 (0.3507)	grad_norm 58643.3359 (58643.3359)	mem 14543MB
[2023-10-13 11:53:15 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][500/6787]	eta 0:26:32 lr 0.000200	time 0.2513 (0.2534)	loss 0.3657 (0.3615)	grad_norm 40290.1523 (48998.8633)	mem 14543MB
[2023-10-13 11:55:20 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][1000/6787]	eta 0:24:21 lr 0.000200	time 0.2517 (0.2525)	loss 0.3525 (0.3611)	grad_norm 37085.3789 (53129.5859)	mem 14543MB
[2023-10-13 11:57:26 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][1500/6787]	eta 0:22:12 lr 0.000200	time 0.2540 (0.2521)	loss 0.3643 (0.3606)	grad_norm 91229.5312 (59043.3438)	mem 14543MB
[2023-10-13 11:59:32 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][2000/6787]	eta 0:20:05 lr 0.000200	time 0.2469 (0.2518)	loss 0.3761 (0.3599)	grad_norm 76814.6484 (64850.3672)	mem 14543MB
[2023-10-13 12:01:37 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2479 (0.2517)	loss 0.3625 (0.3595)	grad_norm 99347.4531 (69596.9688)	mem 14543MB
[2023-10-13 12:03:43 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2465 (0.2516)	loss 0.3423 (0.3594)	grad_norm 95042.6016 (75063.4531)	mem 14543MB
[2023-10-13 12:05:48 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2584 (0.2515)	loss 0.3459 (0.3592)	grad_norm 92178.9688 (82647.7812)	mem 14543MB
[2023-10-13 12:07:54 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2481 (0.2515)	loss 0.3740 (0.3589)	grad_norm 154235.5000 (90068.5781)	mem 14543MB
[2023-10-13 12:09:59 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2464 (0.2514)	loss 0.3386 (0.3587)	grad_norm 237254.6875 (98517.3438)	mem 14543MB
[2023-10-13 12:12:05 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2562 (0.2514)	loss 0.3495 (0.3586)	grad_norm 195652.6719 (109687.5781)	mem 14543MB
[2023-10-13 12:14:10 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2530 (0.2513)	loss 0.3794 (0.3585)	grad_norm 410068.5625 (125423.1797)	mem 14543MB
[2023-10-13 12:16:16 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2496 (0.2513)	loss 0.3532 (0.3583)	grad_norm 216391.1562 (139856.7969)	mem 14543MB
[2023-10-13 12:18:21 simmim_pretrain](main_simmim.py 218): INFO Train: [170/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2527 (0.2513)	loss 0.3402 (0.3582)	grad_norm 397446.0312 (153151.2812)	mem 14543MB
[2023-10-13 12:19:34 simmim_pretrain](main_simmim.py 228): INFO EPOCH 170 training takes 0:28:26
[2023-10-13 12:19:36 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][0/6787]	eta 3:01:10 lr 0.000200	time 1.6017 (1.6017)	loss 0.3693 (0.3693)	grad_norm 466116.8125 (466116.8125)	mem 14543MB
[2023-10-13 12:21:41 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][500/6787]	eta 0:26:35 lr 0.000200	time 0.2495 (0.2538)	loss 0.3490 (0.3578)	grad_norm 424978.3438 (338295.4375)	mem 14543MB
[2023-10-13 12:23:47 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][1000/6787]	eta 0:24:23 lr 0.000200	time 0.2521 (0.2529)	loss 0.3701 (0.3570)	grad_norm 395261.7500 (345965.4688)	mem 14543MB
[2023-10-13 12:25:53 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][1500/6787]	eta 0:22:16 lr 0.000200	time 0.2589 (0.2528)	loss 0.3567 (0.3568)	grad_norm 325881.0625 (348855.5312)	mem 14543MB
[2023-10-13 12:28:00 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][2000/6787]	eta 0:20:09 lr 0.000200	time 0.2546 (0.2527)	loss 0.3614 (0.3564)	grad_norm 841634.9375 (355705.6250)	mem 14543MB
[2023-10-13 12:30:06 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][2500/6787]	eta 0:18:03 lr 0.000200	time 0.2454 (0.2527)	loss 0.3485 (0.3564)	grad_norm 521801.4688 (inf)	mem 14543MB
[2023-10-13 12:32:12 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][3000/6787]	eta 0:15:57 lr 0.000200	time 0.2525 (0.2527)	loss 0.3565 (0.3563)	grad_norm 465554.5312 (inf)	mem 14543MB
[2023-10-13 12:34:19 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][3500/6787]	eta 0:13:50 lr 0.000200	time 0.2515 (0.2527)	loss 0.3585 (0.3562)	grad_norm 464424.2500 (inf)	mem 14543MB
[2023-10-13 12:36:25 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][4000/6787]	eta 0:11:44 lr 0.000200	time 0.2529 (0.2527)	loss 0.3468 (0.3561)	grad_norm 475429.9375 (inf)	mem 14543MB
[2023-10-13 12:38:31 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][4500/6787]	eta 0:09:37 lr 0.000200	time 0.2504 (0.2526)	loss 0.3617 (0.3559)	grad_norm 464281.5000 (inf)	mem 14543MB
[2023-10-13 12:40:37 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][5000/6787]	eta 0:07:31 lr 0.000200	time 0.2538 (0.2525)	loss 0.3614 (0.3559)	grad_norm 432284.7188 (inf)	mem 14543MB
[2023-10-13 12:42:43 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2522 (0.2524)	loss 0.3652 (0.3560)	grad_norm 281701.3750 (inf)	mem 14543MB
[2023-10-13 12:44:48 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2528 (0.2524)	loss 0.3715 (0.3560)	grad_norm 299196.1875 (inf)	mem 14543MB
[2023-10-13 12:46:54 simmim_pretrain](main_simmim.py 218): INFO Train: [171/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2502 (0.2523)	loss 0.3581 (0.3561)	grad_norm 112424.3359 (inf)	mem 14543MB
[2023-10-13 12:48:07 simmim_pretrain](main_simmim.py 228): INFO EPOCH 171 training takes 0:28:32
[2023-10-13 12:48:08 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][0/6787]	eta 2:52:41 lr 0.000200	time 1.5267 (1.5267)	loss 0.3633 (0.3633)	grad_norm 134335.3125 (134335.3125)	mem 14543MB
[2023-10-13 12:50:14 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][500/6787]	eta 0:26:33 lr 0.000200	time 0.2511 (0.2535)	loss 0.3573 (0.3568)	grad_norm 281342.1875 (214038.3125)	mem 14543MB
[2023-10-13 12:52:19 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][1000/6787]	eta 0:24:19 lr 0.000200	time 0.2500 (0.2522)	loss 0.3687 (0.3572)	grad_norm 235114.5469 (215037.8594)	mem 14543MB
[2023-10-13 12:54:25 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][1500/6787]	eta 0:22:11 lr 0.000200	time 0.2508 (0.2518)	loss 0.3305 (0.3567)	grad_norm 389761.3750 (235739.2344)	mem 14543MB
[2023-10-13 12:56:31 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][2000/6787]	eta 0:20:05 lr 0.000200	time 0.2482 (0.2517)	loss 0.3575 (0.3567)	grad_norm 364430.0938 (257126.1562)	mem 14543MB
[2023-10-13 12:58:36 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2537 (0.2516)	loss 0.3557 (0.3564)	grad_norm 432418.4688 (273453.0000)	mem 14543MB
[2023-10-13 13:00:42 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2486 (0.2516)	loss 0.3446 (0.3564)	grad_norm 220069.6250 (inf)	mem 14543MB
[2023-10-13 13:02:47 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2512 (0.2515)	loss 0.3554 (0.3566)	grad_norm 158950.5938 (inf)	mem 14543MB
[2023-10-13 13:04:53 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2517 (0.2514)	loss 0.3448 (0.3567)	grad_norm 299793.8750 (inf)	mem 14543MB
[2023-10-13 13:06:58 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2491 (0.2513)	loss 0.3577 (0.3567)	grad_norm 121309.2734 (inf)	mem 14543MB
[2023-10-13 13:09:04 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2521 (0.2513)	loss 0.3635 (0.3568)	grad_norm 146870.6094 (inf)	mem 14543MB
[2023-10-13 13:11:09 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2502 (0.2513)	loss 0.3662 (0.3567)	grad_norm 697606.4375 (inf)	mem 14543MB
[2023-10-13 13:13:15 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2504 (0.2514)	loss 0.3408 (0.3567)	grad_norm 417194.5312 (inf)	mem 14543MB
[2023-10-13 13:15:21 simmim_pretrain](main_simmim.py 218): INFO Train: [172/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2482 (0.2514)	loss 0.3290 (0.3566)	grad_norm 464593.3750 (inf)	mem 14543MB
[2023-10-13 13:16:34 simmim_pretrain](main_simmim.py 228): INFO EPOCH 172 training takes 0:28:27
[2023-10-13 13:16:36 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][0/6787]	eta 2:48:38 lr 0.000200	time 1.4908 (1.4908)	loss 0.3410 (0.3410)	grad_norm 364327.1562 (364327.1562)	mem 14543MB
[2023-10-13 13:18:42 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][500/6787]	eta 0:26:41 lr 0.000200	time 0.2516 (0.2548)	loss 0.3250 (0.3559)	grad_norm 374274.0000 (395520.8750)	mem 14543MB
[2023-10-13 13:20:48 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][1000/6787]	eta 0:24:27 lr 0.000200	time 0.2467 (0.2535)	loss 0.3637 (0.3552)	grad_norm 561121.0000 (405394.1250)	mem 14543MB
[2023-10-13 13:22:54 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][1500/6787]	eta 0:22:18 lr 0.000200	time 0.2533 (0.2532)	loss 0.3391 (0.3555)	grad_norm 238660.5156 (inf)	mem 14543MB
[2023-10-13 13:25:01 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][2000/6787]	eta 0:20:11 lr 0.000200	time 0.2556 (0.2530)	loss 0.3636 (0.3561)	grad_norm 214211.0000 (inf)	mem 14543MB
[2023-10-13 13:27:07 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][2500/6787]	eta 0:18:03 lr 0.000200	time 0.2502 (0.2528)	loss 0.3906 (0.3565)	grad_norm 212856.2812 (inf)	mem 14543MB
[2023-10-13 13:29:13 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][3000/6787]	eta 0:15:56 lr 0.000200	time 0.2525 (0.2526)	loss 0.3737 (0.3568)	grad_norm 177084.5469 (inf)	mem 14543MB
[2023-10-13 13:31:18 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][3500/6787]	eta 0:13:49 lr 0.000200	time 0.2496 (0.2525)	loss 0.3302 (0.3570)	grad_norm 161417.3750 (inf)	mem 14543MB
[2023-10-13 13:33:24 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][4000/6787]	eta 0:11:43 lr 0.000200	time 0.2530 (0.2523)	loss 0.3739 (0.3569)	grad_norm 320008.7812 (inf)	mem 14543MB
[2023-10-13 13:35:29 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2526 (0.2521)	loss 0.3397 (0.3569)	grad_norm 146682.1406 (inf)	mem 14543MB
[2023-10-13 13:37:35 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2498 (0.2520)	loss 0.3433 (0.3570)	grad_norm 162987.9375 (inf)	mem 14543MB
[2023-10-13 13:39:40 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2542 (0.2518)	loss 0.3443 (0.3571)	grad_norm 94976.4062 (inf)	mem 14543MB
[2023-10-13 13:41:45 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2488 (0.2517)	loss 0.3680 (0.3575)	grad_norm 142997.5312 (inf)	mem 14543MB
[2023-10-13 13:43:50 simmim_pretrain](main_simmim.py 218): INFO Train: [173/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2546 (0.2516)	loss 0.3529 (0.3576)	grad_norm 106500.7188 (inf)	mem 14543MB
[2023-10-13 13:45:02 simmim_pretrain](main_simmim.py 228): INFO EPOCH 173 training takes 0:28:28
[2023-10-13 13:45:04 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][0/6787]	eta 2:57:04 lr 0.000200	time 1.5654 (1.5654)	loss 0.3643 (0.3643)	grad_norm 161605.8125 (161605.8125)	mem 14543MB
[2023-10-13 13:47:09 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][500/6787]	eta 0:26:28 lr 0.000200	time 0.2467 (0.2526)	loss 0.3632 (0.3582)	grad_norm 119358.9453 (142749.9062)	mem 14543MB
[2023-10-13 13:49:15 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][1000/6787]	eta 0:24:18 lr 0.000200	time 0.2469 (0.2521)	loss 0.3434 (0.3576)	grad_norm 205515.5938 (157318.2500)	mem 14543MB
[2023-10-13 13:51:21 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][1500/6787]	eta 0:22:11 lr 0.000200	time 0.2489 (0.2519)	loss 0.3750 (0.3576)	grad_norm 245292.9219 (164527.9219)	mem 14543MB
[2023-10-13 13:53:27 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][2000/6787]	eta 0:20:06 lr 0.000200	time 0.2465 (0.2520)	loss 0.3635 (0.3576)	grad_norm 197961.8438 (inf)	mem 14543MB
[2023-10-13 13:55:33 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][2500/6787]	eta 0:18:00 lr 0.000200	time 0.2535 (0.2520)	loss 0.3595 (0.3579)	grad_norm 101259.0312 (inf)	mem 14543MB
[2023-10-13 13:57:39 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][3000/6787]	eta 0:15:54 lr 0.000200	time 0.2562 (0.2521)	loss 0.3660 (0.3583)	grad_norm 155792.5781 (inf)	mem 14543MB
[2023-10-13 13:59:45 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][3500/6787]	eta 0:13:48 lr 0.000200	time 0.2456 (0.2522)	loss 0.3399 (0.3586)	grad_norm 113733.9609 (inf)	mem 14543MB
[2023-10-13 14:01:52 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][4000/6787]	eta 0:11:43 lr 0.000200	time 0.2578 (0.2523)	loss 0.3350 (0.3588)	grad_norm 154773.9375 (inf)	mem 14543MB
[2023-10-13 14:03:58 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][4500/6787]	eta 0:09:37 lr 0.000200	time 0.2562 (0.2523)	loss 0.3624 (0.3587)	grad_norm 98354.1719 (inf)	mem 14543MB
[2023-10-13 14:06:04 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2562 (0.2523)	loss 0.3550 (0.3585)	grad_norm 200539.7812 (inf)	mem 14543MB
[2023-10-13 14:08:11 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2539 (0.2524)	loss 0.3701 (0.3584)	grad_norm 204500.5938 (inf)	mem 14543MB
[2023-10-13 14:10:17 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2513 (0.2524)	loss 0.3585 (0.3584)	grad_norm 298652.7188 (inf)	mem 14543MB
[2023-10-13 14:12:24 simmim_pretrain](main_simmim.py 218): INFO Train: [174/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2520 (0.2525)	loss 0.3551 (0.3582)	grad_norm 346487.5938 (inf)	mem 14543MB
[2023-10-13 14:13:37 simmim_pretrain](main_simmim.py 228): INFO EPOCH 174 training takes 0:28:34
[2023-10-13 14:13:38 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][0/6787]	eta 2:40:12 lr 0.000200	time 1.4163 (1.4163)	loss 0.3526 (0.3526)	grad_norm 171432.5312 (171432.5312)	mem 14543MB
[2023-10-13 14:15:44 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][500/6787]	eta 0:26:35 lr 0.000200	time 0.2517 (0.2538)	loss 0.3681 (0.3567)	grad_norm 340015.5625 (322708.9688)	mem 14543MB
[2023-10-13 14:17:50 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][1000/6787]	eta 0:24:23 lr 0.000200	time 0.2521 (0.2528)	loss 0.3775 (0.3565)	grad_norm 337308.0000 (373191.3750)	mem 14543MB
[2023-10-13 14:19:56 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][1500/6787]	eta 0:22:15 lr 0.000200	time 0.2481 (0.2525)	loss 0.3501 (0.3564)	grad_norm 315614.5000 (inf)	mem 14543MB
[2023-10-13 14:22:01 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][2000/6787]	eta 0:20:07 lr 0.000200	time 0.2457 (0.2522)	loss 0.3634 (0.3563)	grad_norm 495129.0938 (inf)	mem 14543MB
[2023-10-13 14:24:07 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][2500/6787]	eta 0:18:00 lr 0.000200	time 0.2499 (0.2520)	loss 0.3562 (0.3561)	grad_norm 300935.6875 (inf)	mem 14543MB
[2023-10-13 14:26:12 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][3000/6787]	eta 0:15:53 lr 0.000200	time 0.2490 (0.2518)	loss 0.3837 (0.3562)	grad_norm 295160.4688 (inf)	mem 14543MB
[2023-10-13 14:28:18 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2464 (0.2517)	loss 0.3642 (0.3560)	grad_norm 323705.7500 (inf)	mem 14543MB
[2023-10-13 14:30:23 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2519 (0.2515)	loss 0.3519 (0.3559)	grad_norm 426892.1875 (inf)	mem 14543MB
[2023-10-13 14:32:28 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2547 (0.2515)	loss 0.3643 (0.3559)	grad_norm 493198.4688 (inf)	mem 14543MB
[2023-10-13 14:34:33 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2453 (0.2513)	loss 0.3492 (0.3560)	grad_norm inf (inf)	mem 14543MB
[2023-10-13 14:36:39 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2559 (0.2512)	loss 0.3482 (0.3561)	grad_norm 364682.7812 (inf)	mem 14543MB
[2023-10-13 14:38:44 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2500 (0.2512)	loss 0.3774 (0.3563)	grad_norm 121211.3516 (inf)	mem 14543MB
[2023-10-13 14:40:49 simmim_pretrain](main_simmim.py 218): INFO Train: [175/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2459 (0.2511)	loss 0.3731 (0.3564)	grad_norm 352697.5938 (inf)	mem 14543MB
[2023-10-13 14:42:02 simmim_pretrain](main_simmim.py 228): INFO EPOCH 175 training takes 0:28:24
[2023-10-13 14:42:03 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][0/6787]	eta 2:32:37 lr 0.000200	time 1.3492 (1.3492)	loss 0.3504 (0.3504)	grad_norm 304569.6875 (304569.6875)	mem 14543MB
[2023-10-13 14:44:08 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][500/6787]	eta 0:26:32 lr 0.000200	time 0.2528 (0.2533)	loss 0.3783 (0.3570)	grad_norm 360711.3438 (262258.7812)	mem 14543MB
[2023-10-13 14:46:14 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][1000/6787]	eta 0:24:21 lr 0.000200	time 0.2512 (0.2525)	loss 0.3344 (0.3567)	grad_norm 382950.3438 (284186.5312)	mem 14543MB
[2023-10-13 14:48:20 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][1500/6787]	eta 0:22:14 lr 0.000200	time 0.2498 (0.2524)	loss 0.3922 (0.3564)	grad_norm 420884.3125 (313460.2500)	mem 14543MB
[2023-10-13 14:50:27 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][2000/6787]	eta 0:20:08 lr 0.000200	time 0.2500 (0.2524)	loss 0.3466 (0.3562)	grad_norm 569204.1250 (332326.0625)	mem 14543MB
[2023-10-13 14:52:33 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][2500/6787]	eta 0:18:02 lr 0.000200	time 0.2526 (0.2525)	loss 0.3668 (0.3560)	grad_norm 227858.9219 (inf)	mem 14543MB
[2023-10-13 14:54:39 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][3000/6787]	eta 0:15:56 lr 0.000200	time 0.2592 (0.2526)	loss 0.3587 (0.3562)	grad_norm 192857.4531 (inf)	mem 14543MB
[2023-10-13 14:56:46 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][3500/6787]	eta 0:13:50 lr 0.000200	time 0.2503 (0.2526)	loss 0.3633 (0.3564)	grad_norm 145429.2656 (inf)	mem 14543MB
[2023-10-13 14:58:52 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][4000/6787]	eta 0:11:43 lr 0.000200	time 0.2474 (0.2525)	loss 0.3313 (0.3570)	grad_norm 165360.3281 (inf)	mem 14543MB
[2023-10-13 15:00:58 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][4500/6787]	eta 0:09:37 lr 0.000200	time 0.2533 (0.2525)	loss 0.3604 (0.3574)	grad_norm 115199.1484 (inf)	mem 14543MB
[2023-10-13 15:03:04 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2517 (0.2524)	loss 0.3681 (0.3576)	grad_norm 133063.5156 (inf)	mem 14543MB
[2023-10-13 15:05:09 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2527 (0.2522)	loss 0.3429 (0.3579)	grad_norm 154319.3750 (inf)	mem 14543MB
[2023-10-13 15:07:14 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2466 (0.2521)	loss 0.3500 (0.3578)	grad_norm 129154.7734 (inf)	mem 14543MB
[2023-10-13 15:09:20 simmim_pretrain](main_simmim.py 218): INFO Train: [176/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2475 (0.2520)	loss 0.3682 (0.3578)	grad_norm 121991.1094 (inf)	mem 14543MB
[2023-10-13 15:10:32 simmim_pretrain](main_simmim.py 228): INFO EPOCH 176 training takes 0:28:30
[2023-10-13 15:10:34 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][0/6787]	eta 3:05:32 lr 0.000200	time 1.6402 (1.6402)	loss 0.3702 (0.3702)	grad_norm 82397.2344 (82397.2344)	mem 14543MB
[2023-10-13 15:12:39 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2522 (0.2530)	loss 0.3670 (0.3589)	grad_norm 90639.8359 (131379.0312)	mem 14543MB
[2023-10-13 15:14:44 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][1000/6787]	eta 0:24:15 lr 0.000200	time 0.2533 (0.2515)	loss 0.3399 (0.3588)	grad_norm 138804.9375 (128666.5234)	mem 14543MB
[2023-10-13 15:16:49 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][1500/6787]	eta 0:22:07 lr 0.000200	time 0.2507 (0.2511)	loss 0.3772 (0.3593)	grad_norm 126654.2969 (125652.7578)	mem 14543MB
[2023-10-13 15:18:54 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][2000/6787]	eta 0:20:01 lr 0.000200	time 0.2518 (0.2509)	loss 0.3604 (0.3591)	grad_norm 160520.8906 (125847.0234)	mem 14543MB
[2023-10-13 15:21:00 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][2500/6787]	eta 0:17:55 lr 0.000200	time 0.2491 (0.2509)	loss 0.3669 (0.3587)	grad_norm 126495.6406 (132592.0469)	mem 14543MB
[2023-10-13 15:23:05 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][3000/6787]	eta 0:15:50 lr 0.000200	time 0.2454 (0.2509)	loss 0.3558 (0.3586)	grad_norm 228613.7656 (140080.8125)	mem 14543MB
[2023-10-13 15:25:11 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2538 (0.2510)	loss 0.3351 (0.3584)	grad_norm 133409.6562 (148887.7500)	mem 14543MB
[2023-10-13 15:27:17 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2525 (0.2511)	loss 0.3366 (0.3582)	grad_norm 288540.2188 (157983.7500)	mem 14543MB
[2023-10-13 15:29:23 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2487 (0.2512)	loss 0.3534 (0.3580)	grad_norm 291285.2812 (171557.6875)	mem 14543MB
[2023-10-13 15:31:29 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2533 (0.2513)	loss 0.3296 (0.3577)	grad_norm 228369.9531 (187558.5938)	mem 14543MB
[2023-10-13 15:33:35 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2543 (0.2514)	loss 0.3602 (0.3576)	grad_norm 651642.6875 (202574.6719)	mem 14543MB
[2023-10-13 15:35:42 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2459 (0.2515)	loss 0.3505 (0.3576)	grad_norm 212421.2031 (nan)	mem 14543MB
[2023-10-13 15:37:48 simmim_pretrain](main_simmim.py 218): INFO Train: [177/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2575 (0.2517)	loss 0.3672 (0.3576)	grad_norm 225284.5156 (nan)	mem 14543MB
[2023-10-13 15:39:01 simmim_pretrain](main_simmim.py 228): INFO EPOCH 177 training takes 0:28:29
[2023-10-13 15:39:03 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][0/6787]	eta 2:43:36 lr 0.000200	time 1.4463 (1.4463)	loss 0.3479 (0.3479)	grad_norm 279496.1875 (279496.1875)	mem 14543MB
[2023-10-13 15:41:09 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][500/6787]	eta 0:26:39 lr 0.000200	time 0.2540 (0.2545)	loss 0.3604 (0.3572)	grad_norm 155986.1250 (inf)	mem 14543MB
[2023-10-13 15:43:15 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][1000/6787]	eta 0:24:27 lr 0.000200	time 0.2511 (0.2536)	loss 0.3650 (0.3588)	grad_norm 152570.0625 (inf)	mem 14543MB
[2023-10-13 15:45:21 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][1500/6787]	eta 0:22:18 lr 0.000200	time 0.2516 (0.2532)	loss 0.3484 (0.3591)	grad_norm 122526.7188 (inf)	mem 14543MB
[2023-10-13 15:47:28 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][2000/6787]	eta 0:20:10 lr 0.000200	time 0.2534 (0.2530)	loss 0.3494 (0.3595)	grad_norm 193233.1562 (inf)	mem 14543MB
[2023-10-13 15:49:34 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][2500/6787]	eta 0:18:03 lr 0.000200	time 0.2505 (0.2528)	loss 0.3541 (0.3594)	grad_norm 93997.1406 (inf)	mem 14543MB
[2023-10-13 15:51:39 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][3000/6787]	eta 0:15:56 lr 0.000200	time 0.2591 (0.2525)	loss 0.3529 (0.3591)	grad_norm 165179.5156 (inf)	mem 14543MB
[2023-10-13 15:53:45 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][3500/6787]	eta 0:13:49 lr 0.000200	time 0.2499 (0.2523)	loss 0.3481 (0.3588)	grad_norm 151640.6250 (inf)	mem 14543MB
[2023-10-13 15:55:50 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2534 (0.2522)	loss 0.3503 (0.3587)	grad_norm 175264.9531 (inf)	mem 14543MB
[2023-10-13 15:57:55 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2506 (0.2520)	loss 0.3480 (0.3584)	grad_norm 144900.8438 (inf)	mem 14543MB
[2023-10-13 16:00:01 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2589 (0.2518)	loss 0.3573 (0.3582)	grad_norm 357703.0938 (inf)	mem 14543MB
[2023-10-13 16:02:06 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2502 (0.2516)	loss 0.3635 (0.3581)	grad_norm 372290.4375 (inf)	mem 14543MB
[2023-10-13 16:04:11 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2516 (0.2515)	loss 0.3635 (0.3580)	grad_norm 212023.1250 (inf)	mem 14543MB
[2023-10-13 16:06:16 simmim_pretrain](main_simmim.py 218): INFO Train: [178/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2512 (0.2514)	loss 0.3423 (0.3578)	grad_norm 201310.3125 (inf)	mem 14543MB
[2023-10-13 16:07:28 simmim_pretrain](main_simmim.py 228): INFO EPOCH 178 training takes 0:28:26
[2023-10-13 16:07:30 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][0/6787]	eta 2:58:19 lr 0.000200	time 1.5764 (1.5764)	loss 0.3674 (0.3674)	grad_norm 436660.1250 (436660.1250)	mem 14543MB
[2023-10-13 16:09:35 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][500/6787]	eta 0:26:30 lr 0.000200	time 0.2597 (0.2529)	loss 0.3590 (0.3567)	grad_norm 201875.3750 (inf)	mem 14543MB
[2023-10-13 16:11:41 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][1000/6787]	eta 0:24:20 lr 0.000200	time 0.2556 (0.2524)	loss 0.3547 (0.3589)	grad_norm 98453.1562 (inf)	mem 14543MB
[2023-10-13 16:13:47 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][1500/6787]	eta 0:22:15 lr 0.000200	time 0.2508 (0.2526)	loss 0.3435 (0.3592)	grad_norm 137136.0781 (inf)	mem 14543MB
[2023-10-13 16:15:54 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][2000/6787]	eta 0:20:10 lr 0.000200	time 0.2553 (0.2528)	loss 0.3464 (0.3596)	grad_norm 145842.3281 (inf)	mem 14543MB
[2023-10-13 16:18:01 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][2500/6787]	eta 0:18:04 lr 0.000200	time 0.2555 (0.2531)	loss 0.3649 (0.3596)	grad_norm 113860.8125 (inf)	mem 14543MB
[2023-10-13 16:20:09 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][3000/6787]	eta 0:16:00 lr 0.000200	time 0.2594 (0.2537)	loss 0.3439 (0.3594)	grad_norm 167252.1250 (inf)	mem 14543MB
[2023-10-13 16:22:19 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][3500/6787]	eta 0:13:56 lr 0.000200	time 0.2593 (0.2544)	loss 0.3714 (0.3590)	grad_norm 203946.1875 (inf)	mem 14543MB
[2023-10-13 16:24:29 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][4000/6787]	eta 0:11:50 lr 0.000200	time 0.2592 (0.2550)	loss 0.3609 (0.3589)	grad_norm 105017.1562 (inf)	mem 14543MB
[2023-10-13 16:26:37 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][4500/6787]	eta 0:09:43 lr 0.000200	time 0.2579 (0.2552)	loss 0.3569 (0.3589)	grad_norm 96443.5859 (inf)	mem 14543MB
[2023-10-13 16:28:46 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][5000/6787]	eta 0:07:36 lr 0.000200	time 0.2592 (0.2554)	loss 0.3526 (0.3590)	grad_norm 116598.6172 (inf)	mem 14543MB
[2023-10-13 16:30:53 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][5500/6787]	eta 0:05:28 lr 0.000200	time 0.2513 (0.2554)	loss 0.3581 (0.3591)	grad_norm 159960.1094 (inf)	mem 14543MB
[2023-10-13 16:33:01 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][6000/6787]	eta 0:03:20 lr 0.000200	time 0.2563 (0.2554)	loss 0.3503 (0.3591)	grad_norm 243081.6250 (inf)	mem 14543MB
[2023-10-13 16:35:08 simmim_pretrain](main_simmim.py 218): INFO Train: [179/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2539 (0.2554)	loss 0.3621 (0.3589)	grad_norm 121159.7344 (inf)	mem 14543MB
[2023-10-13 16:36:22 simmim_pretrain](main_simmim.py 228): INFO EPOCH 179 training takes 0:28:53
[2023-10-13 16:36:24 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][0/6787]	eta 2:44:49 lr 0.000200	time 1.4571 (1.4571)	loss 0.3565 (0.3565)	grad_norm 215607.2500 (215607.2500)	mem 14543MB
[2023-10-13 16:38:30 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][500/6787]	eta 0:26:39 lr 0.000200	time 0.2466 (0.2544)	loss 0.3521 (0.3571)	grad_norm 224558.2656 (191749.0156)	mem 14543MB
[2023-10-13 16:40:35 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][1000/6787]	eta 0:24:23 lr 0.000200	time 0.2535 (0.2530)	loss 0.3722 (0.3574)	grad_norm 174706.5625 (195154.1250)	mem 14543MB
[2023-10-13 16:42:41 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][1500/6787]	eta 0:22:15 lr 0.000200	time 0.2489 (0.2525)	loss 0.3626 (0.3570)	grad_norm 398399.4688 (225161.1875)	mem 14543MB
[2023-10-13 16:44:47 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][2000/6787]	eta 0:20:07 lr 0.000200	time 0.2456 (0.2523)	loss 0.3714 (0.3567)	grad_norm 243426.7344 (inf)	mem 14543MB
[2023-10-13 16:46:53 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][2500/6787]	eta 0:18:00 lr 0.000200	time 0.2519 (0.2522)	loss 0.3839 (0.3569)	grad_norm 110051.3906 (nan)	mem 14543MB
[2023-10-13 16:48:58 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][3000/6787]	eta 0:15:54 lr 0.000200	time 0.2516 (0.2520)	loss 0.3560 (0.3574)	grad_norm 127171.4297 (nan)	mem 14543MB
[2023-10-13 16:51:04 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][3500/6787]	eta 0:13:48 lr 0.000200	time 0.2512 (0.2520)	loss 0.3501 (0.3576)	grad_norm 132613.2344 (nan)	mem 14543MB
[2023-10-13 16:53:10 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2511 (0.2519)	loss 0.3740 (0.3582)	grad_norm 72408.9844 (nan)	mem 14543MB
[2023-10-13 16:55:15 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2537 (0.2518)	loss 0.3361 (0.3585)	grad_norm 71960.0703 (nan)	mem 14543MB
[2023-10-13 16:57:21 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2489 (0.2517)	loss 0.3537 (0.3589)	grad_norm 60139.3828 (nan)	mem 14543MB
[2023-10-13 16:59:27 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][5500/6787]	eta 0:05:23 lr 0.000200	time 0.2598 (0.2517)	loss 0.3631 (0.3592)	grad_norm 79601.4609 (nan)	mem 14543MB
[2023-10-13 17:01:33 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2582 (0.2518)	loss 0.3625 (0.3593)	grad_norm 68794.8203 (nan)	mem 14543MB
[2023-10-13 17:03:39 simmim_pretrain](main_simmim.py 218): INFO Train: [180/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2493 (0.2518)	loss 0.3575 (0.3594)	grad_norm 85724.7969 (nan)	mem 14543MB
[2023-10-13 17:04:52 simmim_pretrain](main_simmim.py 228): INFO EPOCH 180 training takes 0:28:29
[2023-10-13 17:04:52 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_180.pth saving......
[2023-10-13 17:04:53 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_180.pth saved !!!
[2023-10-13 17:04:54 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][0/6787]	eta 2:26:40 lr 0.000200	time 1.2967 (1.2967)	loss 0.3552 (0.3552)	grad_norm 85865.9219 (85865.9219)	mem 14543MB
[2023-10-13 17:07:00 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][500/6787]	eta 0:26:39 lr 0.000200	time 0.2579 (0.2544)	loss 0.3643 (0.3587)	grad_norm 38902.9453 (92803.9766)	mem 14543MB
[2023-10-13 17:09:06 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][1000/6787]	eta 0:24:28 lr 0.000200	time 0.2483 (0.2537)	loss 0.3367 (0.3582)	grad_norm 112823.5703 (94805.3281)	mem 14543MB
[2023-10-13 17:11:13 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][1500/6787]	eta 0:22:19 lr 0.000200	time 0.2459 (0.2534)	loss 0.3346 (0.3579)	grad_norm 69781.5000 (104531.6172)	mem 14543MB
[2023-10-13 17:13:20 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][2000/6787]	eta 0:20:13 lr 0.000200	time 0.2480 (0.2535)	loss 0.3413 (0.3576)	grad_norm 124624.3047 (114849.0859)	mem 14543MB
[2023-10-13 17:15:26 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][2500/6787]	eta 0:18:06 lr 0.000200	time 0.2531 (0.2534)	loss 0.3699 (0.3575)	grad_norm 99668.1641 (124477.9922)	mem 14543MB
[2023-10-13 17:17:33 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][3000/6787]	eta 0:15:59 lr 0.000200	time 0.2536 (0.2533)	loss 0.3473 (0.3574)	grad_norm 172290.0312 (132671.6562)	mem 14543MB
[2023-10-13 17:19:39 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][3500/6787]	eta 0:13:52 lr 0.000200	time 0.2490 (0.2532)	loss 0.3615 (0.3573)	grad_norm 206155.5312 (147419.6562)	mem 14543MB
[2023-10-13 17:21:45 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][4000/6787]	eta 0:11:45 lr 0.000200	time 0.2503 (0.2531)	loss 0.3517 (0.3570)	grad_norm 181384.9688 (162562.0469)	mem 14543MB
[2023-10-13 17:23:51 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][4500/6787]	eta 0:09:38 lr 0.000200	time 0.2487 (0.2530)	loss 0.3595 (0.3569)	grad_norm 255865.3594 (185355.2969)	mem 14543MB
[2023-10-13 17:25:58 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][5000/6787]	eta 0:07:32 lr 0.000200	time 0.2494 (0.2530)	loss 0.3735 (0.3568)	grad_norm 183144.1250 (199658.5625)	mem 14543MB
[2023-10-13 17:28:04 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2489 (0.2529)	loss 0.3832 (0.3566)	grad_norm 154694.3125 (inf)	mem 14543MB
[2023-10-13 17:30:10 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2522 (0.2528)	loss 0.3663 (0.3566)	grad_norm 250510.2344 (inf)	mem 14543MB
[2023-10-13 17:32:16 simmim_pretrain](main_simmim.py 218): INFO Train: [181/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2483 (0.2528)	loss 0.3569 (0.3566)	grad_norm 243042.2656 (inf)	mem 14543MB
[2023-10-13 17:33:29 simmim_pretrain](main_simmim.py 228): INFO EPOCH 181 training takes 0:28:36
[2023-10-13 17:33:30 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][0/6787]	eta 2:48:47 lr 0.000200	time 1.4922 (1.4922)	loss 0.3684 (0.3684)	grad_norm 253017.4688 (253017.4688)	mem 14543MB
[2023-10-13 17:35:35 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][500/6787]	eta 0:26:29 lr 0.000200	time 0.2519 (0.2528)	loss 0.3504 (0.3578)	grad_norm 100166.4844 (inf)	mem 14543MB
[2023-10-13 17:37:41 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2590 (0.2518)	loss 0.3641 (0.3583)	grad_norm 118435.4609 (inf)	mem 14543MB
[2023-10-13 17:39:46 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2507 (0.2516)	loss 0.3551 (0.3585)	grad_norm 69517.2969 (inf)	mem 14543MB
[2023-10-13 17:41:52 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][2000/6787]	eta 0:20:04 lr 0.000200	time 0.2483 (0.2516)	loss 0.3468 (0.3585)	grad_norm 118994.6797 (inf)	mem 14543MB
[2023-10-13 17:43:58 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][2500/6787]	eta 0:17:59 lr 0.000200	time 0.2577 (0.2517)	loss 0.3287 (0.3585)	grad_norm 81066.2109 (inf)	mem 14543MB
[2023-10-13 17:46:04 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][3000/6787]	eta 0:15:53 lr 0.000200	time 0.2530 (0.2518)	loss 0.3565 (0.3583)	grad_norm 201463.7031 (inf)	mem 14543MB
[2023-10-13 17:48:11 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][3500/6787]	eta 0:13:48 lr 0.000200	time 0.2602 (0.2519)	loss 0.3482 (0.3581)	grad_norm 181093.2031 (inf)	mem 14543MB
[2023-10-13 17:50:17 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2586 (0.2521)	loss 0.3625 (0.3579)	grad_norm 151281.2969 (inf)	mem 14543MB
[2023-10-13 17:52:24 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][4500/6787]	eta 0:09:37 lr 0.000200	time 0.2606 (0.2523)	loss 0.3597 (0.3577)	grad_norm 141815.9062 (inf)	mem 14543MB
[2023-10-13 17:54:34 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][5000/6787]	eta 0:07:32 lr 0.000200	time 0.2610 (0.2531)	loss 0.3373 (0.3579)	grad_norm 139475.9688 (inf)	mem 14543MB
[2023-10-13 17:56:44 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2606 (0.2538)	loss 0.3451 (0.3580)	grad_norm 129226.3750 (inf)	mem 14543MB
[2023-10-13 17:58:55 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][6000/6787]	eta 0:03:20 lr 0.000200	time 0.2608 (0.2543)	loss 0.3433 (0.3582)	grad_norm 115159.5625 (inf)	mem 14543MB
[2023-10-13 18:01:05 simmim_pretrain](main_simmim.py 218): INFO Train: [182/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2609 (0.2548)	loss 0.3533 (0.3582)	grad_norm 80655.1641 (inf)	mem 14543MB
[2023-10-13 18:02:20 simmim_pretrain](main_simmim.py 228): INFO EPOCH 182 training takes 0:28:51
[2023-10-13 18:02:21 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][0/6787]	eta 2:45:14 lr 0.000200	time 1.4609 (1.4609)	loss 0.3515 (0.3515)	grad_norm 76554.4844 (76554.4844)	mem 14543MB
[2023-10-13 18:04:27 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][500/6787]	eta 0:26:39 lr 0.000200	time 0.2476 (0.2544)	loss 0.3591 (0.3564)	grad_norm 127096.1562 (170891.0000)	mem 14543MB
[2023-10-13 18:06:33 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][1000/6787]	eta 0:24:26 lr 0.000200	time 0.2491 (0.2533)	loss 0.3560 (0.3564)	grad_norm 77557.0859 (165109.9219)	mem 14543MB
[2023-10-13 18:08:39 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][1500/6787]	eta 0:22:17 lr 0.000200	time 0.2463 (0.2529)	loss 0.3723 (0.3568)	grad_norm 413376.1875 (171186.3438)	mem 14543MB
[2023-10-13 18:10:45 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][2000/6787]	eta 0:20:09 lr 0.000200	time 0.2519 (0.2527)	loss 0.3581 (0.3566)	grad_norm 137128.2500 (190310.2969)	mem 14543MB
[2023-10-13 18:12:52 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][2500/6787]	eta 0:18:02 lr 0.000200	time 0.2532 (0.2526)	loss 0.3703 (0.3567)	grad_norm 317263.0625 (210609.0156)	mem 14543MB
[2023-10-13 18:14:58 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][3000/6787]	eta 0:15:56 lr 0.000200	time 0.2541 (0.2526)	loss 0.3459 (0.3565)	grad_norm 251966.2344 (227942.5625)	mem 14543MB
[2023-10-13 18:17:04 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][3500/6787]	eta 0:13:50 lr 0.000200	time 0.2498 (0.2526)	loss 0.3682 (0.3564)	grad_norm 275606.4375 (240739.4219)	mem 14543MB
[2023-10-13 18:19:11 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][4000/6787]	eta 0:11:44 lr 0.000200	time 0.2523 (0.2526)	loss 0.3632 (0.3564)	grad_norm 270686.3750 (inf)	mem 14543MB
[2023-10-13 18:21:17 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][4500/6787]	eta 0:09:37 lr 0.000200	time 0.2482 (0.2526)	loss 0.3367 (0.3565)	grad_norm 188962.1719 (inf)	mem 14543MB
[2023-10-13 18:23:24 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][5000/6787]	eta 0:07:31 lr 0.000200	time 0.2581 (0.2527)	loss 0.3610 (0.3566)	grad_norm 311665.9062 (inf)	mem 14543MB
[2023-10-13 18:25:32 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2598 (0.2531)	loss 0.3751 (0.3566)	grad_norm 206069.2656 (inf)	mem 14543MB
[2023-10-13 18:27:42 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2599 (0.2537)	loss 0.3391 (0.3564)	grad_norm 147205.3906 (inf)	mem 14543MB
[2023-10-13 18:29:52 simmim_pretrain](main_simmim.py 218): INFO Train: [183/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2534 (0.2541)	loss 0.3746 (0.3564)	grad_norm 219439.5156 (inf)	mem 14543MB
[2023-10-13 18:31:06 simmim_pretrain](main_simmim.py 228): INFO EPOCH 183 training takes 0:28:45
[2023-10-13 18:31:07 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][0/6787]	eta 2:57:50 lr 0.000200	time 1.5722 (1.5722)	loss 0.3643 (0.3643)	grad_norm 376927.5312 (376927.5312)	mem 14543MB
[2023-10-13 18:33:15 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][500/6787]	eta 0:26:57 lr 0.000200	time 0.2524 (0.2572)	loss 0.3228 (0.3554)	grad_norm 454106.4375 (338742.6875)	mem 14543MB
[2023-10-13 18:35:22 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][1000/6787]	eta 0:24:41 lr 0.000200	time 0.2519 (0.2560)	loss 0.3319 (0.3552)	grad_norm 493399.6562 (inf)	mem 14543MB
[2023-10-13 18:37:29 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][1500/6787]	eta 0:22:29 lr 0.000200	time 0.2501 (0.2552)	loss 0.3598 (0.3552)	grad_norm 493181.5312 (inf)	mem 14543MB
[2023-10-13 18:39:35 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][2000/6787]	eta 0:20:18 lr 0.000200	time 0.2550 (0.2546)	loss 0.3548 (0.3553)	grad_norm 278771.2500 (inf)	mem 14543MB
[2023-10-13 18:41:41 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][2500/6787]	eta 0:18:09 lr 0.000200	time 0.2502 (0.2542)	loss 0.3281 (0.3553)	grad_norm 474966.7500 (inf)	mem 14543MB
[2023-10-13 18:43:48 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][3000/6787]	eta 0:16:01 lr 0.000200	time 0.2477 (0.2539)	loss 0.3494 (0.3552)	grad_norm 312082.7500 (inf)	mem 14543MB
[2023-10-13 18:45:53 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][3500/6787]	eta 0:13:53 lr 0.000200	time 0.2534 (0.2536)	loss 0.3691 (0.3552)	grad_norm 336733.9062 (inf)	mem 14543MB
[2023-10-13 18:47:59 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][4000/6787]	eta 0:11:45 lr 0.000200	time 0.2592 (0.2533)	loss 0.3524 (0.3551)	grad_norm 587151.1875 (inf)	mem 14543MB
[2023-10-13 18:50:05 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][4500/6787]	eta 0:09:38 lr 0.000200	time 0.2464 (0.2531)	loss 0.3453 (0.3551)	grad_norm 263619.8125 (inf)	mem 14543MB
[2023-10-13 18:52:10 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][5000/6787]	eta 0:07:31 lr 0.000200	time 0.2460 (0.2529)	loss 0.3554 (0.3552)	grad_norm 292374.7188 (inf)	mem 14543MB
[2023-10-13 18:54:16 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2479 (0.2527)	loss 0.3508 (0.3554)	grad_norm 144429.1719 (inf)	mem 14543MB
[2023-10-13 18:56:21 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2488 (0.2526)	loss 0.3663 (0.3555)	grad_norm 207911.6562 (inf)	mem 14543MB
[2023-10-13 18:58:27 simmim_pretrain](main_simmim.py 218): INFO Train: [184/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2539 (0.2524)	loss 0.3455 (0.3557)	grad_norm 156165.5156 (inf)	mem 14543MB
[2023-10-13 18:59:39 simmim_pretrain](main_simmim.py 228): INFO EPOCH 184 training takes 0:28:33
[2023-10-13 18:59:41 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][0/6787]	eta 2:50:30 lr 0.000200	time 1.5074 (1.5074)	loss 0.3373 (0.3373)	grad_norm 234501.8906 (234501.8906)	mem 14543MB
[2023-10-13 19:01:47 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][500/6787]	eta 0:26:35 lr 0.000200	time 0.2505 (0.2538)	loss 0.3905 (0.3568)	grad_norm 157650.0312 (inf)	mem 14543MB
[2023-10-13 19:03:52 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][1000/6787]	eta 0:24:22 lr 0.000200	time 0.2461 (0.2528)	loss 0.3562 (0.3572)	grad_norm 246554.1094 (inf)	mem 14543MB
[2023-10-13 19:05:59 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][1500/6787]	eta 0:22:15 lr 0.000200	time 0.2580 (0.2526)	loss 0.3528 (0.3569)	grad_norm 215366.1875 (inf)	mem 14543MB
[2023-10-13 19:08:05 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][2000/6787]	eta 0:20:09 lr 0.000200	time 0.2562 (0.2528)	loss 0.3562 (0.3570)	grad_norm 181876.3438 (inf)	mem 14543MB
[2023-10-13 19:10:12 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][2500/6787]	eta 0:18:03 lr 0.000200	time 0.2589 (0.2528)	loss 0.3453 (0.3568)	grad_norm 196953.1094 (inf)	mem 14543MB
[2023-10-13 19:12:18 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][3000/6787]	eta 0:15:57 lr 0.000200	time 0.2526 (0.2529)	loss 0.3461 (0.3567)	grad_norm 443918.4375 (inf)	mem 14543MB
[2023-10-13 19:14:25 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][3500/6787]	eta 0:13:51 lr 0.000200	time 0.2593 (0.2530)	loss 0.3527 (0.3565)	grad_norm 255741.5625 (inf)	mem 14543MB
[2023-10-13 19:16:32 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][4000/6787]	eta 0:11:45 lr 0.000200	time 0.2513 (0.2531)	loss 0.3608 (0.3563)	grad_norm 692436.2500 (inf)	mem 14543MB
[2023-10-13 19:18:39 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][4500/6787]	eta 0:09:38 lr 0.000200	time 0.2871 (0.2531)	loss 0.3488 (0.3561)	grad_norm 239431.0156 (inf)	mem 14543MB
[2023-10-13 19:20:45 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][5000/6787]	eta 0:07:32 lr 0.000200	time 0.2526 (0.2531)	loss 0.3497 (0.3562)	grad_norm 250409.8594 (inf)	mem 14543MB
[2023-10-13 19:22:52 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][5500/6787]	eta 0:05:25 lr 0.000200	time 0.2541 (0.2531)	loss 0.3545 (0.3563)	grad_norm 134846.6094 (inf)	mem 14543MB
[2023-10-13 19:24:58 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][6000/6787]	eta 0:03:19 lr 0.000200	time 0.2459 (0.2531)	loss 0.3626 (0.3566)	grad_norm 151372.5625 (inf)	mem 14543MB
[2023-10-13 19:27:04 simmim_pretrain](main_simmim.py 218): INFO Train: [185/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2570 (0.2530)	loss 0.3617 (0.3568)	grad_norm 142897.0625 (inf)	mem 14543MB
[2023-10-13 19:28:17 simmim_pretrain](main_simmim.py 228): INFO EPOCH 185 training takes 0:28:37
[2023-10-13 19:28:19 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][0/6787]	eta 2:55:48 lr 0.000200	time 1.5542 (1.5542)	loss 0.3465 (0.3465)	grad_norm 69697.7031 (69697.7031)	mem 14543MB
[2023-10-13 19:30:24 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][500/6787]	eta 0:26:35 lr 0.000200	time 0.2526 (0.2538)	loss 0.3424 (0.3585)	grad_norm 106456.5469 (116079.1406)	mem 14543MB
[2023-10-13 19:32:30 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][1000/6787]	eta 0:24:23 lr 0.000200	time 0.2537 (0.2528)	loss 0.3512 (0.3580)	grad_norm 148266.9375 (125810.9453)	mem 14543MB
[2023-10-13 19:34:36 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][1500/6787]	eta 0:22:13 lr 0.000200	time 0.2460 (0.2522)	loss 0.3681 (0.3579)	grad_norm 110984.7188 (138786.0625)	mem 14543MB
[2023-10-13 19:36:41 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][2000/6787]	eta 0:20:05 lr 0.000200	time 0.2497 (0.2519)	loss 0.3559 (0.3577)	grad_norm 202212.3438 (150280.7344)	mem 14543MB
[2023-10-13 19:38:47 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][2500/6787]	eta 0:17:59 lr 0.000200	time 0.2515 (0.2517)	loss 0.3477 (0.3575)	grad_norm 192295.7031 (163308.4375)	mem 14543MB
[2023-10-13 19:40:52 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2458 (0.2516)	loss 0.3780 (0.3572)	grad_norm 329073.6562 (180958.5625)	mem 14543MB
[2023-10-13 19:42:58 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2498 (0.2516)	loss 0.3551 (0.3570)	grad_norm 162216.1719 (199337.0156)	mem 14543MB
[2023-10-13 19:45:04 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2529 (0.2516)	loss 0.3431 (0.3571)	grad_norm 204631.0938 (inf)	mem 14543MB
[2023-10-13 19:47:10 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2521 (0.2517)	loss 0.3492 (0.3577)	grad_norm 167290.2344 (inf)	mem 14543MB
[2023-10-13 19:49:16 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2511 (0.2518)	loss 0.3563 (0.3581)	grad_norm 64944.2695 (inf)	mem 14543MB
[2023-10-13 19:51:23 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2513 (0.2519)	loss 0.3580 (0.3585)	grad_norm 44634.4023 (inf)	mem 14543MB
[2023-10-13 19:53:29 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2527 (0.2520)	loss 0.3448 (0.3588)	grad_norm 55371.0078 (inf)	mem 14543MB
[2023-10-13 19:55:38 simmim_pretrain](main_simmim.py 218): INFO Train: [186/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2582 (0.2524)	loss 0.3413 (0.3588)	grad_norm 63087.7148 (inf)	mem 14543MB
[2023-10-13 19:56:52 simmim_pretrain](main_simmim.py 228): INFO EPOCH 186 training takes 0:28:35
[2023-10-13 19:56:54 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][0/6787]	eta 2:46:52 lr 0.000200	time 1.4753 (1.4753)	loss 0.3656 (0.3656)	grad_norm 76636.9141 (76636.9141)	mem 14543MB
[2023-10-13 19:59:01 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][500/6787]	eta 0:26:49 lr 0.000200	time 0.2531 (0.2561)	loss 0.3592 (0.3586)	grad_norm 88129.7109 (82246.4219)	mem 14543MB
[2023-10-13 20:01:08 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][1000/6787]	eta 0:24:40 lr 0.000200	time 0.2597 (0.2559)	loss 0.3422 (0.3589)	grad_norm 49909.4648 (87997.9141)	mem 14543MB
[2023-10-13 20:03:18 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][1500/6787]	eta 0:22:38 lr 0.000200	time 0.2594 (0.2570)	loss 0.3563 (0.3585)	grad_norm 94033.5625 (91824.0156)	mem 14543MB
[2023-10-13 20:05:28 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][2000/6787]	eta 0:20:33 lr 0.000200	time 0.2597 (0.2576)	loss 0.3535 (0.3582)	grad_norm 272624.5625 (105814.9453)	mem 14543MB
[2023-10-13 20:07:37 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][2500/6787]	eta 0:18:25 lr 0.000200	time 0.2598 (0.2579)	loss 0.3467 (0.3580)	grad_norm 93059.9844 (115807.8359)	mem 14543MB
[2023-10-13 20:09:47 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][3000/6787]	eta 0:16:17 lr 0.000200	time 0.2595 (0.2581)	loss 0.3531 (0.3578)	grad_norm 241058.3750 (124323.6406)	mem 14543MB
[2023-10-13 20:11:56 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][3500/6787]	eta 0:14:08 lr 0.000200	time 0.2598 (0.2583)	loss 0.3767 (0.3577)	grad_norm 165201.0469 (133047.0938)	mem 14543MB
[2023-10-13 20:14:06 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][4000/6787]	eta 0:12:00 lr 0.000200	time 0.2593 (0.2584)	loss 0.3584 (0.3574)	grad_norm 199413.0781 (156939.2969)	mem 14543MB
[2023-10-13 20:16:15 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][4500/6787]	eta 0:09:50 lr 0.000200	time 0.2562 (0.2584)	loss 0.3548 (0.3572)	grad_norm 185677.5312 (167241.2500)	mem 14543MB
[2023-10-13 20:18:25 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][5000/6787]	eta 0:07:41 lr 0.000200	time 0.2588 (0.2585)	loss 0.3616 (0.3570)	grad_norm 582537.6875 (183261.5938)	mem 14543MB
[2023-10-13 20:20:34 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][5500/6787]	eta 0:05:32 lr 0.000200	time 0.2594 (0.2585)	loss 0.3577 (0.3568)	grad_norm 305145.8125 (inf)	mem 14543MB
[2023-10-13 20:22:43 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][6000/6787]	eta 0:03:23 lr 0.000200	time 0.2545 (0.2585)	loss 0.3639 (0.3567)	grad_norm 464761.6875 (inf)	mem 14543MB
[2023-10-13 20:24:53 simmim_pretrain](main_simmim.py 218): INFO Train: [187/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2593 (0.2585)	loss 0.3832 (0.3566)	grad_norm 529095.9375 (inf)	mem 14543MB
[2023-10-13 20:26:07 simmim_pretrain](main_simmim.py 228): INFO EPOCH 187 training takes 0:29:14
[2023-10-13 20:26:09 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][0/6787]	eta 2:54:05 lr 0.000200	time 1.5391 (1.5391)	loss 0.3391 (0.3391)	grad_norm 273062.9375 (273062.9375)	mem 14543MB
[2023-10-13 20:28:14 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][500/6787]	eta 0:26:28 lr 0.000200	time 0.2464 (0.2527)	loss 0.3780 (0.3552)	grad_norm 419497.4688 (370591.6875)	mem 14543MB
[2023-10-13 20:30:19 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][1000/6787]	eta 0:24:17 lr 0.000200	time 0.2523 (0.2519)	loss 0.3454 (0.3552)	grad_norm 464307.2188 (inf)	mem 14543MB
[2023-10-13 20:32:25 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][1500/6787]	eta 0:22:10 lr 0.000200	time 0.2525 (0.2517)	loss 0.3534 (0.3554)	grad_norm 277651.9062 (inf)	mem 14543MB
[2023-10-13 20:34:31 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][2000/6787]	eta 0:20:04 lr 0.000200	time 0.2511 (0.2515)	loss 0.3667 (0.3554)	grad_norm 487617.0000 (inf)	mem 14543MB
[2023-10-13 20:36:36 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2559 (0.2515)	loss 0.3490 (0.3554)	grad_norm 323333.7500 (inf)	mem 14543MB
[2023-10-13 20:38:42 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2493 (0.2516)	loss 0.3668 (0.3551)	grad_norm 201557.6719 (inf)	mem 14543MB
[2023-10-13 20:40:48 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][3500/6787]	eta 0:13:47 lr 0.000200	time 0.2510 (0.2516)	loss 0.3528 (0.3555)	grad_norm 288090.2500 (inf)	mem 14543MB
[2023-10-13 20:42:55 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][4000/6787]	eta 0:11:41 lr 0.000200	time 0.2502 (0.2518)	loss 0.3497 (0.3556)	grad_norm 362685.1250 (inf)	mem 14543MB
[2023-10-13 20:45:01 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2475 (0.2519)	loss 0.3604 (0.3561)	grad_norm 236826.0781 (inf)	mem 14543MB
[2023-10-13 20:47:07 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2497 (0.2520)	loss 0.3697 (0.3564)	grad_norm 159493.6719 (inf)	mem 14543MB
[2023-10-13 20:49:14 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2567 (0.2521)	loss 0.3813 (0.3566)	grad_norm 121574.4219 (inf)	mem 14543MB
[2023-10-13 20:51:24 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2604 (0.2528)	loss 0.3527 (0.3568)	grad_norm 137406.7500 (inf)	mem 14543MB
[2023-10-13 20:53:34 simmim_pretrain](main_simmim.py 218): INFO Train: [188/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2609 (0.2533)	loss 0.3362 (0.3569)	grad_norm 158516.0938 (inf)	mem 14543MB
[2023-10-13 20:54:49 simmim_pretrain](main_simmim.py 228): INFO EPOCH 188 training takes 0:28:42
[2023-10-13 20:54:51 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][0/6787]	eta 2:55:21 lr 0.000200	time 1.5502 (1.5502)	loss 0.3753 (0.3753)	grad_norm 213029.8750 (213029.8750)	mem 14543MB
[2023-10-13 20:56:57 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][500/6787]	eta 0:26:40 lr 0.000200	time 0.2498 (0.2545)	loss 0.3873 (0.3582)	grad_norm 196106.9375 (164673.0625)	mem 14543MB
[2023-10-13 20:59:03 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][1000/6787]	eta 0:24:26 lr 0.000200	time 0.2503 (0.2535)	loss 0.3613 (0.3573)	grad_norm 101362.5469 (167330.4062)	mem 14543MB
[2023-10-13 21:01:09 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][1500/6787]	eta 0:22:18 lr 0.000200	time 0.2533 (0.2531)	loss 0.3648 (0.3570)	grad_norm 204668.3750 (182612.4219)	mem 14543MB
[2023-10-13 21:03:15 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][2000/6787]	eta 0:20:10 lr 0.000200	time 0.2559 (0.2529)	loss 0.3515 (0.3564)	grad_norm 213556.3750 (220901.6406)	mem 14543MB
[2023-10-13 21:05:21 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][2500/6787]	eta 0:18:03 lr 0.000200	time 0.2458 (0.2527)	loss 0.3596 (0.3565)	grad_norm 338358.3125 (237615.6719)	mem 14543MB
[2023-10-13 21:07:27 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][3000/6787]	eta 0:15:56 lr 0.000200	time 0.2518 (0.2526)	loss 0.3719 (0.3564)	grad_norm 306506.5000 (253917.4375)	mem 14543MB
[2023-10-13 21:09:33 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][3500/6787]	eta 0:13:49 lr 0.000200	time 0.2520 (0.2524)	loss 0.3631 (0.3562)	grad_norm 173564.6406 (inf)	mem 14543MB
[2023-10-13 21:11:39 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][4000/6787]	eta 0:11:43 lr 0.000200	time 0.2589 (0.2523)	loss 0.3540 (0.3560)	grad_norm 248149.7188 (inf)	mem 14543MB
[2023-10-13 21:13:45 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2499 (0.2522)	loss 0.3646 (0.3561)	grad_norm 147302.4688 (inf)	mem 14543MB
[2023-10-13 21:15:50 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2498 (0.2521)	loss 0.3300 (0.3562)	grad_norm 201229.4688 (inf)	mem 14543MB
[2023-10-13 21:17:56 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2473 (0.2520)	loss 0.3655 (0.3562)	grad_norm 155365.4062 (inf)	mem 14543MB
[2023-10-13 21:20:02 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2486 (0.2520)	loss 0.3461 (0.3562)	grad_norm 219934.7344 (inf)	mem 14543MB
[2023-10-13 21:22:08 simmim_pretrain](main_simmim.py 218): INFO Train: [189/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2486 (0.2520)	loss 0.3544 (0.3562)	grad_norm 340285.9375 (inf)	mem 14543MB
[2023-10-13 21:23:21 simmim_pretrain](main_simmim.py 228): INFO EPOCH 189 training takes 0:28:31
[2023-10-13 21:23:22 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][0/6787]	eta 2:47:47 lr 0.000200	time 1.4833 (1.4833)	loss 0.3549 (0.3549)	grad_norm 461040.5938 (461040.5938)	mem 14543MB
[2023-10-13 21:25:28 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][500/6787]	eta 0:26:40 lr 0.000200	time 0.2508 (0.2545)	loss 0.3486 (0.3555)	grad_norm 215064.6562 (430273.7812)	mem 14543MB
[2023-10-13 21:27:35 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][1000/6787]	eta 0:24:30 lr 0.000200	time 0.2550 (0.2541)	loss 0.3626 (0.3554)	grad_norm 332880.7812 (382086.2812)	mem 14543MB
[2023-10-13 21:29:43 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][1500/6787]	eta 0:22:27 lr 0.000200	time 0.2614 (0.2548)	loss 0.3505 (0.3559)	grad_norm 192371.3438 (inf)	mem 14543MB
[2023-10-13 21:31:53 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][2000/6787]	eta 0:20:26 lr 0.000200	time 0.2606 (0.2561)	loss 0.3514 (0.3561)	grad_norm 161280.6250 (inf)	mem 14543MB
[2023-10-13 21:34:03 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][2500/6787]	eta 0:18:21 lr 0.000200	time 0.2607 (0.2570)	loss 0.3565 (0.3562)	grad_norm 227372.6562 (inf)	mem 14543MB
[2023-10-13 21:36:13 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][3000/6787]	eta 0:16:15 lr 0.000200	time 0.2610 (0.2575)	loss 0.3653 (0.3564)	grad_norm 254291.0469 (inf)	mem 14543MB
[2023-10-13 21:38:23 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][3500/6787]	eta 0:14:06 lr 0.000200	time 0.2578 (0.2576)	loss 0.3707 (0.3563)	grad_norm 338453.4062 (inf)	mem 14543MB
[2023-10-13 21:40:31 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][4000/6787]	eta 0:11:57 lr 0.000200	time 0.2583 (0.2576)	loss 0.3496 (0.3561)	grad_norm 501778.2188 (inf)	mem 14543MB
[2023-10-13 21:42:39 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][4500/6787]	eta 0:09:48 lr 0.000200	time 0.2537 (0.2575)	loss 0.3437 (0.3560)	grad_norm 259197.0156 (inf)	mem 14543MB
[2023-10-13 21:44:47 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][5000/6787]	eta 0:07:39 lr 0.000200	time 0.2534 (0.2572)	loss 0.3572 (0.3561)	grad_norm 269465.2188 (inf)	mem 14543MB
[2023-10-13 21:46:54 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][5500/6787]	eta 0:05:30 lr 0.000200	time 0.2550 (0.2568)	loss 0.3593 (0.3563)	grad_norm 215768.2656 (inf)	mem 14543MB
[2023-10-13 21:49:02 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2560 (0.2568)	loss 0.3516 (0.3563)	grad_norm 355818.0000 (inf)	mem 14543MB
[2023-10-13 21:51:11 simmim_pretrain](main_simmim.py 218): INFO Train: [190/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2606 (0.2570)	loss 0.3378 (0.3563)	grad_norm 325573.3750 (inf)	mem 14543MB
[2023-10-13 21:52:26 simmim_pretrain](main_simmim.py 228): INFO EPOCH 190 training takes 0:29:05
[2023-10-13 21:52:28 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][0/6787]	eta 2:49:50 lr 0.000200	time 1.5015 (1.5015)	loss 0.3556 (0.3556)	grad_norm 149541.4844 (149541.4844)	mem 14543MB
[2023-10-13 21:54:34 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][500/6787]	eta 0:26:38 lr 0.000200	time 0.2570 (0.2542)	loss 0.3558 (0.3555)	grad_norm 366313.5625 (309579.9375)	mem 14543MB
[2023-10-13 21:56:40 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][1000/6787]	eta 0:24:24 lr 0.000200	time 0.2556 (0.2531)	loss 0.3511 (0.3556)	grad_norm 473457.6875 (352328.5938)	mem 14543MB
[2023-10-13 21:58:45 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][1500/6787]	eta 0:22:15 lr 0.000200	time 0.2529 (0.2526)	loss 0.3497 (0.3557)	grad_norm 276720.4375 (360801.7500)	mem 14543MB
[2023-10-13 22:00:51 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][2000/6787]	eta 0:20:08 lr 0.000200	time 0.2532 (0.2524)	loss 0.3606 (0.3557)	grad_norm 346433.0312 (379431.5625)	mem 14543MB
[2023-10-13 22:02:57 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][2500/6787]	eta 0:18:00 lr 0.000200	time 0.2505 (0.2521)	loss 0.3647 (0.3556)	grad_norm 614310.3750 (inf)	mem 14543MB
[2023-10-13 22:05:03 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][3000/6787]	eta 0:15:54 lr 0.000200	time 0.2525 (0.2521)	loss 0.3710 (0.3556)	grad_norm 207754.6562 (inf)	mem 14543MB
[2023-10-13 22:07:09 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][3500/6787]	eta 0:13:48 lr 0.000200	time 0.2523 (0.2521)	loss 0.3568 (0.3553)	grad_norm 350684.7812 (inf)	mem 14543MB
[2023-10-13 22:09:15 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2524 (0.2520)	loss 0.3558 (0.3553)	grad_norm 399651.0625 (inf)	mem 14543MB
[2023-10-13 22:11:21 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2531 (0.2520)	loss 0.3522 (0.3552)	grad_norm 431535.2188 (inf)	mem 14543MB
[2023-10-13 22:13:27 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2496 (0.2521)	loss 0.3541 (0.3552)	grad_norm 548871.8125 (inf)	mem 14543MB
[2023-10-13 22:15:33 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2545 (0.2522)	loss 0.3605 (0.3552)	grad_norm 521067.8750 (inf)	mem 14543MB
[2023-10-13 22:17:40 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2591 (0.2523)	loss 0.3404 (0.3551)	grad_norm 401392.2812 (inf)	mem 14543MB
[2023-10-13 22:19:49 simmim_pretrain](main_simmim.py 218): INFO Train: [191/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2488 (0.2527)	loss 0.3548 (0.3552)	grad_norm 521799.0625 (inf)	mem 14543MB
[2023-10-13 22:21:03 simmim_pretrain](main_simmim.py 228): INFO EPOCH 191 training takes 0:28:36
[2023-10-13 22:21:04 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][0/6787]	eta 2:47:37 lr 0.000200	time 1.4819 (1.4819)	loss 0.3454 (0.3454)	grad_norm 344808.4062 (344808.4062)	mem 14543MB
[2023-10-13 22:23:11 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][500/6787]	eta 0:26:49 lr 0.000200	time 0.2547 (0.2559)	loss 0.3241 (0.3555)	grad_norm 376958.5000 (nan)	mem 14543MB
[2023-10-13 22:25:18 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][1000/6787]	eta 0:24:35 lr 0.000200	time 0.2554 (0.2550)	loss 0.3508 (0.3562)	grad_norm 382849.2500 (nan)	mem 14543MB
[2023-10-13 22:27:26 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][1500/6787]	eta 0:22:29 lr 0.000200	time 0.2555 (0.2553)	loss 0.3584 (0.3565)	grad_norm 196838.1719 (nan)	mem 14543MB
[2023-10-13 22:29:34 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][2000/6787]	eta 0:20:22 lr 0.000200	time 0.2591 (0.2555)	loss 0.3198 (0.3567)	grad_norm 351823.6875 (nan)	mem 14543MB
[2023-10-13 22:31:42 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][2500/6787]	eta 0:18:14 lr 0.000200	time 0.2484 (0.2554)	loss 0.3607 (0.3567)	grad_norm 386591.3125 (nan)	mem 14543MB
[2023-10-13 22:33:48 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][3000/6787]	eta 0:16:05 lr 0.000200	time 0.2525 (0.2549)	loss 0.3527 (0.3570)	grad_norm 348804.7812 (nan)	mem 14543MB
[2023-10-13 22:35:55 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][3500/6787]	eta 0:13:57 lr 0.000200	time 0.2525 (0.2548)	loss 0.3692 (0.3570)	grad_norm 431138.1875 (nan)	mem 14543MB
[2023-10-13 22:38:02 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][4000/6787]	eta 0:11:50 lr 0.000200	time 0.2527 (0.2548)	loss 0.3463 (0.3574)	grad_norm 212839.6562 (nan)	mem 14543MB
[2023-10-13 22:40:10 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][4500/6787]	eta 0:09:42 lr 0.000200	time 0.2592 (0.2548)	loss 0.3679 (0.3576)	grad_norm 129881.5234 (nan)	mem 14543MB
[2023-10-13 22:42:17 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][5000/6787]	eta 0:07:35 lr 0.000200	time 0.2544 (0.2547)	loss 0.3476 (0.3578)	grad_norm 98268.8984 (nan)	mem 14543MB
[2023-10-13 22:44:24 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][5500/6787]	eta 0:05:27 lr 0.000200	time 0.2532 (0.2546)	loss 0.3521 (0.3579)	grad_norm 127697.8984 (nan)	mem 14543MB
[2023-10-13 22:46:30 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][6000/6787]	eta 0:03:20 lr 0.000200	time 0.2520 (0.2545)	loss 0.3685 (0.3580)	grad_norm 287933.2812 (nan)	mem 14543MB
[2023-10-13 22:48:37 simmim_pretrain](main_simmim.py 218): INFO Train: [192/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2670 (0.2545)	loss 0.3481 (0.3579)	grad_norm 139591.9688 (nan)	mem 14543MB
[2023-10-13 22:49:51 simmim_pretrain](main_simmim.py 228): INFO EPOCH 192 training takes 0:28:47
[2023-10-13 22:49:52 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][0/6787]	eta 2:59:08 lr 0.000200	time 1.5836 (1.5836)	loss 0.3680 (0.3680)	grad_norm 275102.9375 (275102.9375)	mem 14543MB
[2023-10-13 22:51:58 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][500/6787]	eta 0:26:32 lr 0.000200	time 0.2488 (0.2534)	loss 0.3592 (0.3567)	grad_norm 83196.3984 (220798.6875)	mem 14543MB
[2023-10-13 22:54:03 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][1000/6787]	eta 0:24:20 lr 0.000200	time 0.2491 (0.2523)	loss 0.3747 (0.3567)	grad_norm 225868.1094 (inf)	mem 14543MB
[2023-10-13 22:56:09 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][1500/6787]	eta 0:22:14 lr 0.000200	time 0.2587 (0.2523)	loss 0.3597 (0.3566)	grad_norm 255076.7656 (inf)	mem 14543MB
[2023-10-13 22:58:16 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][2000/6787]	eta 0:20:08 lr 0.000200	time 0.2533 (0.2524)	loss 0.3727 (0.3567)	grad_norm 349562.0625 (inf)	mem 14543MB
[2023-10-13 23:00:22 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][2500/6787]	eta 0:18:02 lr 0.000200	time 0.2521 (0.2525)	loss 0.3688 (0.3566)	grad_norm 237473.4375 (inf)	mem 14543MB
[2023-10-13 23:02:29 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][3000/6787]	eta 0:15:56 lr 0.000200	time 0.2535 (0.2526)	loss 0.3460 (0.3567)	grad_norm 256213.2969 (inf)	mem 14543MB
[2023-10-13 23:04:35 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][3500/6787]	eta 0:13:50 lr 0.000200	time 0.2523 (0.2526)	loss 0.3469 (0.3566)	grad_norm 325910.7500 (inf)	mem 14543MB
[2023-10-13 23:06:42 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][4000/6787]	eta 0:11:44 lr 0.000200	time 0.2497 (0.2528)	loss 0.3539 (0.3566)	grad_norm 326580.2500 (inf)	mem 14543MB
[2023-10-13 23:08:49 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][4500/6787]	eta 0:09:38 lr 0.000200	time 0.2595 (0.2529)	loss 0.3620 (0.3567)	grad_norm 511985.5938 (inf)	mem 14543MB
[2023-10-13 23:10:56 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][5000/6787]	eta 0:07:32 lr 0.000200	time 0.2581 (0.2530)	loss 0.3690 (0.3566)	grad_norm 230771.1406 (inf)	mem 14543MB
[2023-10-13 23:13:06 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][5500/6787]	eta 0:05:26 lr 0.000200	time 0.2574 (0.2536)	loss 0.3772 (0.3566)	grad_norm 206221.6406 (inf)	mem 14543MB
[2023-10-13 23:15:16 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][6000/6787]	eta 0:03:20 lr 0.000200	time 0.2594 (0.2542)	loss 0.3603 (0.3566)	grad_norm 444114.5625 (inf)	mem 14543MB
[2023-10-13 23:17:26 simmim_pretrain](main_simmim.py 218): INFO Train: [193/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2514 (0.2546)	loss 0.3502 (0.3566)	grad_norm 208559.3594 (inf)	mem 14543MB
[2023-10-13 23:18:41 simmim_pretrain](main_simmim.py 228): INFO EPOCH 193 training takes 0:28:50
[2023-10-13 23:18:43 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][0/6787]	eta 2:55:35 lr 0.000200	time 1.5523 (1.5523)	loss 0.3652 (0.3652)	grad_norm 205349.2188 (205349.2188)	mem 14543MB
[2023-10-13 23:20:48 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][500/6787]	eta 0:26:37 lr 0.000200	time 0.2505 (0.2540)	loss 0.3431 (0.3554)	grad_norm 492198.5000 (405991.1250)	mem 14543MB
[2023-10-13 23:22:54 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][1000/6787]	eta 0:24:22 lr 0.000200	time 0.2566 (0.2528)	loss 0.3482 (0.3545)	grad_norm 363155.5625 (inf)	mem 14543MB
[2023-10-13 23:25:00 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][1500/6787]	eta 0:22:15 lr 0.000200	time 0.2500 (0.2526)	loss 0.3323 (0.3549)	grad_norm 292055.9375 (inf)	mem 14543MB
[2023-10-13 23:27:06 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][2000/6787]	eta 0:20:08 lr 0.000200	time 0.2534 (0.2525)	loss 0.3583 (0.3561)	grad_norm 162312.2188 (inf)	mem 14543MB
[2023-10-13 23:29:12 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][2500/6787]	eta 0:18:01 lr 0.000200	time 0.2545 (0.2524)	loss 0.3259 (0.3568)	grad_norm 81559.5859 (inf)	mem 14543MB
[2023-10-13 23:31:18 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][3000/6787]	eta 0:15:55 lr 0.000200	time 0.2588 (0.2523)	loss 0.3535 (0.3572)	grad_norm 146313.4688 (inf)	mem 14543MB
[2023-10-13 23:33:24 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][3500/6787]	eta 0:13:48 lr 0.000200	time 0.2511 (0.2522)	loss 0.3351 (0.3575)	grad_norm 96472.0469 (inf)	mem 14543MB
[2023-10-13 23:35:30 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][4000/6787]	eta 0:11:42 lr 0.000200	time 0.2548 (0.2521)	loss 0.3509 (0.3578)	grad_norm 187762.5469 (inf)	mem 14543MB
[2023-10-13 23:37:36 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][4500/6787]	eta 0:09:36 lr 0.000200	time 0.2474 (0.2521)	loss 0.3610 (0.3576)	grad_norm 105905.7109 (inf)	mem 14543MB
[2023-10-13 23:39:42 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][5000/6787]	eta 0:07:30 lr 0.000200	time 0.2551 (0.2520)	loss 0.3624 (0.3575)	grad_norm 294943.5938 (inf)	mem 14543MB
[2023-10-13 23:41:48 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2506 (0.2521)	loss 0.3491 (0.3575)	grad_norm 188075.0781 (inf)	mem 14543MB
[2023-10-13 23:43:54 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2591 (0.2522)	loss 0.3640 (0.3573)	grad_norm 393169.8125 (inf)	mem 14543MB
[2023-10-13 23:46:01 simmim_pretrain](main_simmim.py 218): INFO Train: [194/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2490 (0.2522)	loss 0.3753 (0.3572)	grad_norm 255751.1562 (inf)	mem 14543MB
[2023-10-13 23:47:14 simmim_pretrain](main_simmim.py 228): INFO EPOCH 194 training takes 0:28:32
[2023-10-13 23:47:15 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][0/6787]	eta 2:56:02 lr 0.000200	time 1.5563 (1.5563)	loss 0.3615 (0.3615)	grad_norm 336096.2188 (336096.2188)	mem 14543MB
[2023-10-13 23:49:22 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][500/6787]	eta 0:26:43 lr 0.000200	time 0.2523 (0.2551)	loss 0.3388 (0.3559)	grad_norm 507365.3750 (378207.1875)	mem 14543MB
[2023-10-13 23:51:28 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][1000/6787]	eta 0:24:29 lr 0.000200	time 0.2502 (0.2539)	loss 0.3607 (0.3554)	grad_norm 544352.3750 (inf)	mem 14543MB
[2023-10-13 23:53:36 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][1500/6787]	eta 0:22:27 lr 0.000200	time 0.2593 (0.2548)	loss 0.3520 (0.3558)	grad_norm 189888.5469 (inf)	mem 14543MB
[2023-10-13 23:55:46 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][2000/6787]	eta 0:20:26 lr 0.000200	time 0.2595 (0.2562)	loss 0.3638 (0.3560)	grad_norm 131617.6719 (inf)	mem 14543MB
[2023-10-13 23:57:56 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][2500/6787]	eta 0:18:21 lr 0.000200	time 0.2497 (0.2569)	loss 0.3335 (0.3562)	grad_norm 218092.7656 (inf)	mem 14543MB
[2023-10-14 00:00:03 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][3000/6787]	eta 0:16:11 lr 0.000200	time 0.2558 (0.2565)	loss 0.3648 (0.3563)	grad_norm 384229.4375 (inf)	mem 14543MB
[2023-10-14 00:02:13 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][3500/6787]	eta 0:14:04 lr 0.000200	time 0.2517 (0.2568)	loss 0.3614 (0.3562)	grad_norm 301729.7500 (inf)	mem 14543MB
[2023-10-14 00:04:23 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][4000/6787]	eta 0:11:56 lr 0.000200	time 0.2609 (0.2572)	loss 0.3640 (0.3561)	grad_norm 209223.8438 (inf)	mem 14543MB
[2023-10-14 00:06:33 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][4500/6787]	eta 0:09:48 lr 0.000200	time 0.2608 (0.2575)	loss 0.3540 (0.3561)	grad_norm 596011.0625 (inf)	mem 14543MB
[2023-10-14 00:08:43 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][5000/6787]	eta 0:07:40 lr 0.000200	time 0.2611 (0.2578)	loss 0.3551 (0.3560)	grad_norm 545414.4375 (inf)	mem 14543MB
[2023-10-14 00:10:53 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][5500/6787]	eta 0:05:32 lr 0.000200	time 0.2615 (0.2580)	loss 0.3380 (0.3559)	grad_norm 416826.4062 (inf)	mem 14543MB
[2023-10-14 00:13:03 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][6000/6787]	eta 0:03:23 lr 0.000200	time 0.2591 (0.2581)	loss 0.3781 (0.3558)	grad_norm 364557.1875 (inf)	mem 14543MB
[2023-10-14 00:15:13 simmim_pretrain](main_simmim.py 218): INFO Train: [195/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2579 (0.2583)	loss 0.3529 (0.3559)	grad_norm 206967.9531 (inf)	mem 14543MB
[2023-10-14 00:16:28 simmim_pretrain](main_simmim.py 228): INFO EPOCH 195 training takes 0:29:14
[2023-10-14 00:16:29 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][0/6787]	eta 2:50:55 lr 0.000200	time 1.5110 (1.5110)	loss 0.3571 (0.3571)	grad_norm 364913.9062 (364913.9062)	mem 14543MB
[2023-10-14 00:18:35 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][500/6787]	eta 0:26:27 lr 0.000200	time 0.2475 (0.2525)	loss 0.3715 (0.3576)	grad_norm 316566.9688 (248606.1875)	mem 14543MB
[2023-10-14 00:20:40 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][1000/6787]	eta 0:24:18 lr 0.000200	time 0.2529 (0.2520)	loss 0.3543 (0.3572)	grad_norm 158194.5000 (245907.6250)	mem 14543MB
[2023-10-14 00:22:46 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][1500/6787]	eta 0:22:12 lr 0.000200	time 0.2578 (0.2521)	loss 0.3476 (0.3565)	grad_norm 320833.1250 (268958.8438)	mem 14543MB
[2023-10-14 00:24:54 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][2000/6787]	eta 0:20:10 lr 0.000200	time 0.2567 (0.2529)	loss 0.3673 (0.3561)	grad_norm 323179.0938 (nan)	mem 14543MB
[2023-10-14 00:27:02 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][2500/6787]	eta 0:18:07 lr 0.000200	time 0.2552 (0.2536)	loss 0.3812 (0.3567)	grad_norm 241881.3281 (nan)	mem 14543MB
[2023-10-14 00:29:11 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][3000/6787]	eta 0:16:02 lr 0.000200	time 0.2585 (0.2542)	loss 0.3568 (0.3573)	grad_norm 111176.3828 (nan)	mem 14543MB
[2023-10-14 00:31:20 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][3500/6787]	eta 0:13:57 lr 0.000200	time 0.2568 (0.2547)	loss 0.3646 (0.3576)	grad_norm 116309.4922 (nan)	mem 14543MB
[2023-10-14 00:33:29 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][4000/6787]	eta 0:11:50 lr 0.000200	time 0.2616 (0.2551)	loss 0.3513 (0.3579)	grad_norm 99959.5625 (nan)	mem 14543MB
[2023-10-14 00:35:37 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][4500/6787]	eta 0:09:43 lr 0.000200	time 0.2496 (0.2553)	loss 0.3656 (0.3581)	grad_norm 207295.3438 (nan)	mem 14543MB
[2023-10-14 00:37:46 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][5000/6787]	eta 0:07:36 lr 0.000200	time 0.2599 (0.2555)	loss 0.3639 (0.3582)	grad_norm 158706.2656 (nan)	mem 14543MB
[2023-10-14 00:39:54 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][5500/6787]	eta 0:05:28 lr 0.000200	time 0.2604 (0.2556)	loss 0.3473 (0.3583)	grad_norm 168193.1250 (nan)	mem 14543MB
[2023-10-14 00:42:02 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][6000/6787]	eta 0:03:21 lr 0.000200	time 0.2597 (0.2557)	loss 0.3799 (0.3584)	grad_norm 149597.2656 (nan)	mem 14543MB
[2023-10-14 00:44:10 simmim_pretrain](main_simmim.py 218): INFO Train: [196/200][6500/6787]	eta 0:01:13 lr 0.000200	time 0.2588 (0.2557)	loss 0.3681 (0.3584)	grad_norm 88202.3984 (nan)	mem 14543MB
[2023-10-14 00:45:24 simmim_pretrain](main_simmim.py 228): INFO EPOCH 196 training takes 0:28:56
[2023-10-14 00:45:25 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][0/6787]	eta 2:38:22 lr 0.000200	time 1.4001 (1.4001)	loss 0.3577 (0.3577)	grad_norm 115283.4844 (115283.4844)	mem 14543MB
[2023-10-14 00:47:32 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][500/6787]	eta 0:26:41 lr 0.000200	time 0.2516 (0.2547)	loss 0.3674 (0.3577)	grad_norm 270207.6875 (156907.6094)	mem 14543MB
[2023-10-14 00:49:38 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][1000/6787]	eta 0:24:25 lr 0.000200	time 0.2525 (0.2533)	loss 0.3573 (0.3577)	grad_norm 345715.2500 (170754.7500)	mem 14543MB
[2023-10-14 00:51:43 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][1500/6787]	eta 0:22:14 lr 0.000200	time 0.2466 (0.2524)	loss 0.3511 (0.3572)	grad_norm 145732.6094 (180641.3438)	mem 14543MB
[2023-10-14 00:53:48 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][2000/6787]	eta 0:20:06 lr 0.000200	time 0.2483 (0.2520)	loss 0.3650 (0.3571)	grad_norm 194416.2344 (191247.9375)	mem 14543MB
[2023-10-14 00:55:53 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][2500/6787]	eta 0:17:58 lr 0.000200	time 0.2588 (0.2517)	loss 0.3533 (0.3570)	grad_norm 440575.4062 (216641.0312)	mem 14543MB
[2023-10-14 00:57:59 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][3000/6787]	eta 0:15:52 lr 0.000200	time 0.2589 (0.2515)	loss 0.3496 (0.3568)	grad_norm 375312.9688 (234518.9531)	mem 14543MB
[2023-10-14 01:00:04 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][3500/6787]	eta 0:13:45 lr 0.000200	time 0.2517 (0.2513)	loss 0.3484 (0.3565)	grad_norm 427771.4688 (252147.2969)	mem 14543MB
[2023-10-14 01:02:09 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][4000/6787]	eta 0:11:39 lr 0.000200	time 0.2457 (0.2511)	loss 0.3504 (0.3564)	grad_norm 629555.3750 (272102.0000)	mem 14543MB
[2023-10-14 01:04:14 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][4500/6787]	eta 0:09:34 lr 0.000200	time 0.2477 (0.2510)	loss 0.3545 (0.3562)	grad_norm 263213.4688 (inf)	mem 14543MB
[2023-10-14 01:06:19 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][5000/6787]	eta 0:07:28 lr 0.000200	time 0.2599 (0.2509)	loss 0.3531 (0.3561)	grad_norm 403320.0625 (inf)	mem 14543MB
[2023-10-14 01:08:24 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][5500/6787]	eta 0:05:22 lr 0.000200	time 0.2526 (0.2509)	loss 0.3437 (0.3561)	grad_norm 232945.0156 (inf)	mem 14543MB
[2023-10-14 01:10:30 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][6000/6787]	eta 0:03:17 lr 0.000200	time 0.2561 (0.2510)	loss 0.3618 (0.3562)	grad_norm 292770.2500 (inf)	mem 14543MB
[2023-10-14 01:12:36 simmim_pretrain](main_simmim.py 218): INFO Train: [197/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2545 (0.2510)	loss 0.3767 (0.3564)	grad_norm 321448.1250 (inf)	mem 14543MB
[2023-10-14 01:13:49 simmim_pretrain](main_simmim.py 228): INFO EPOCH 197 training takes 0:28:24
[2023-10-14 01:13:50 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][0/6787]	eta 2:44:17 lr 0.000200	time 1.4524 (1.4524)	loss 0.3634 (0.3634)	grad_norm 302900.5000 (302900.5000)	mem 14543MB
[2023-10-14 01:15:56 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][500/6787]	eta 0:26:39 lr 0.000200	time 0.2513 (0.2544)	loss 0.3636 (0.3584)	grad_norm 142350.5781 (inf)	mem 14543MB
[2023-10-14 01:18:03 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][1000/6787]	eta 0:24:27 lr 0.000200	time 0.2539 (0.2536)	loss 0.3589 (0.3592)	grad_norm 130047.0938 (inf)	mem 14543MB
[2023-10-14 01:20:09 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][1500/6787]	eta 0:22:20 lr 0.000200	time 0.2552 (0.2535)	loss 0.3624 (0.3596)	grad_norm 149347.1875 (inf)	mem 14543MB
[2023-10-14 01:22:17 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][2000/6787]	eta 0:20:15 lr 0.000200	time 0.2616 (0.2538)	loss 0.3522 (0.3607)	grad_norm 79951.1406 (inf)	mem 14543MB
[2023-10-14 01:24:27 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][2500/6787]	eta 0:18:13 lr 0.000200	time 0.2607 (0.2550)	loss 0.3635 (0.3611)	grad_norm 51467.3008 (inf)	mem 14543MB
[2023-10-14 01:26:37 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][3000/6787]	eta 0:16:09 lr 0.000200	time 0.2605 (0.2559)	loss 0.3345 (0.3611)	grad_norm 24979.0566 (inf)	mem 14543MB
[2023-10-14 01:28:47 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][3500/6787]	eta 0:14:02 lr 0.000200	time 0.2604 (0.2565)	loss 0.3515 (0.3613)	grad_norm 68689.3516 (inf)	mem 14543MB
[2023-10-14 01:30:57 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][4000/6787]	eta 0:11:55 lr 0.000200	time 0.2608 (0.2569)	loss 0.3564 (0.3611)	grad_norm 133474.7812 (inf)	mem 14543MB
[2023-10-14 01:33:07 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][4500/6787]	eta 0:09:48 lr 0.000200	time 0.2603 (0.2572)	loss 0.3701 (0.3609)	grad_norm 66461.5703 (inf)	mem 14543MB
[2023-10-14 01:35:17 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][5000/6787]	eta 0:07:40 lr 0.000200	time 0.2607 (0.2575)	loss 0.3963 (0.3606)	grad_norm 152168.8750 (inf)	mem 14543MB
[2023-10-14 01:37:26 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][5500/6787]	eta 0:05:31 lr 0.000200	time 0.2612 (0.2577)	loss 0.3558 (0.3605)	grad_norm 103547.5781 (inf)	mem 14543MB
[2023-10-14 01:39:36 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][6000/6787]	eta 0:03:22 lr 0.000200	time 0.2605 (0.2579)	loss 0.3301 (0.3603)	grad_norm 133191.2656 (inf)	mem 14543MB
[2023-10-14 01:41:46 simmim_pretrain](main_simmim.py 218): INFO Train: [198/200][6500/6787]	eta 0:01:14 lr 0.000200	time 0.2598 (0.2580)	loss 0.3534 (0.3600)	grad_norm 236418.2812 (inf)	mem 14543MB
[2023-10-14 01:43:01 simmim_pretrain](main_simmim.py 228): INFO EPOCH 198 training takes 0:29:12
[2023-10-14 01:43:03 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][0/6787]	eta 3:05:32 lr 0.000200	time 1.6403 (1.6403)	loss 0.3670 (0.3670)	grad_norm 124683.3828 (124683.3828)	mem 14543MB
[2023-10-14 01:45:08 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][500/6787]	eta 0:26:26 lr 0.000200	time 0.2516 (0.2524)	loss 0.3567 (0.3573)	grad_norm 139540.4375 (181335.5781)	mem 14543MB
[2023-10-14 01:47:13 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][1000/6787]	eta 0:24:15 lr 0.000200	time 0.2451 (0.2514)	loss 0.3620 (0.3570)	grad_norm 190056.2344 (182440.2812)	mem 14543MB
[2023-10-14 01:49:18 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][1500/6787]	eta 0:22:07 lr 0.000200	time 0.2587 (0.2511)	loss 0.3333 (0.3563)	grad_norm 268888.2812 (202905.9062)	mem 14543MB
[2023-10-14 01:51:24 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][2000/6787]	eta 0:20:02 lr 0.000200	time 0.2496 (0.2511)	loss 0.3661 (0.3561)	grad_norm 511422.1250 (223033.3906)	mem 14543MB
[2023-10-14 01:53:29 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][2500/6787]	eta 0:17:56 lr 0.000200	time 0.2463 (0.2511)	loss 0.3614 (0.3558)	grad_norm 254368.5312 (243853.5938)	mem 14543MB
[2023-10-14 01:55:35 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][3000/6787]	eta 0:15:51 lr 0.000200	time 0.2571 (0.2512)	loss 0.3416 (0.3557)	grad_norm 422309.1250 (264830.0312)	mem 14543MB
[2023-10-14 01:57:41 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][3500/6787]	eta 0:13:46 lr 0.000200	time 0.2486 (0.2514)	loss 0.3685 (0.3556)	grad_norm 418466.9688 (inf)	mem 14543MB
[2023-10-14 01:59:47 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][4000/6787]	eta 0:11:40 lr 0.000200	time 0.2596 (0.2515)	loss 0.3498 (0.3556)	grad_norm 545823.3750 (inf)	mem 14543MB
[2023-10-14 02:01:54 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][4500/6787]	eta 0:09:35 lr 0.000200	time 0.2592 (0.2516)	loss 0.3615 (0.3554)	grad_norm 556156.5625 (inf)	mem 14543MB
[2023-10-14 02:04:00 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][5000/6787]	eta 0:07:29 lr 0.000200	time 0.2543 (0.2517)	loss 0.3322 (0.3553)	grad_norm 203762.3125 (nan)	mem 14543MB
[2023-10-14 02:06:06 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][5500/6787]	eta 0:05:24 lr 0.000200	time 0.2561 (0.2518)	loss 0.3517 (0.3554)	grad_norm 353202.0312 (nan)	mem 14543MB
[2023-10-14 02:08:15 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][6000/6787]	eta 0:03:18 lr 0.000200	time 0.2598 (0.2522)	loss 0.3787 (0.3556)	grad_norm 189523.1719 (nan)	mem 14543MB
[2023-10-14 02:10:24 simmim_pretrain](main_simmim.py 218): INFO Train: [199/200][6500/6787]	eta 0:01:12 lr 0.000200	time 0.2597 (0.2528)	loss 0.3604 (0.3558)	grad_norm 114084.1875 (nan)	mem 14543MB
[2023-10-14 02:11:39 simmim_pretrain](main_simmim.py 228): INFO EPOCH 199 training takes 0:28:38
[2023-10-14 02:11:39 simmim_pretrain](utils.py 62): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_199.pth saving......
[2023-10-14 02:11:40 simmim_pretrain](utils.py 64): INFO /root/autodl-tmp/LSQ-simmim/checkpoint/simmim_pretrain/vit_simmim/ckpt_epoch_199.pth saved !!!
[2023-10-14 02:11:40 simmim_pretrain](main_simmim.py 156): INFO Training time 3 days, 23:07:37
